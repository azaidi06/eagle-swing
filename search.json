[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "about",
    "section": "",
    "text": "Helping you improve your swing â€“ your way"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "eagle-swing",
    "section": "",
    "text": "Forays into Vision Models\n\n\n\nDeep Learning\n\n\n\nNow that weâ€™ve explored the traditional machine learning route, lets see how a more robust vision based approach might work\n\n\n\n\n\nDec 14, 2025\n\n\nAli Zaidi\n\n\n\n\n\n\n\n\n\n\n\n\nFinal Swing Data Review\n\n\n\n\n\nA final review of our data before modeling\n\n\n\n\n\nDec 10, 2025\n\n\nAli Zaidi\n\n\n\n\n\n\n\n\n\n\n\n\nFind Swing Landmarks\n\n\n\nData Engineering\n\nAutomated Annotation\n\n\n\nWe need a more reliable way to index into the swing â€“ looking for the start, top of backswing and finish\n\n\n\n\n\nDec 8, 2025\n\n\nAli Zaidi\n\n\n\n\n\n\n\n\n\n\n\n\nDecision Trees\n\n\n\nTime Series\n\nDecision Trees\n\nXGBoost\n\n\n\nLets try some simple and traditional machine learning approaches, like random forests, gradient boosted trees and some souped up linear regression methods\n\n\n\n\n\nDec 3, 2025\n\n\nAli Zaidi\n\n\n\n\n\n\n\n\n\n\n\n\nAuto Detect Score Hand\n\n\n\nData Engineering\n\nAutomated Annotation\n\nExploratory Data Analysis\n\n\n\nWatching every swing to find the score is a bit tedious, lets get some functionality to find the frames where the score is provided\n\n\n\n\n\nDec 1, 2025\n\n\nAli Zaidi\n\n\n\n\n\n\n\n\n\n\n\n\nTemporal Evolution\n\n\n\nData Engineering\n\n\n\nAll of that is useful but since weâ€™re working with sequence data of a video, we canâ€™t leave out changes over time of how these keypoints evolve in the swing\n\n\n\n\n\nNov 27, 2025\n\n\nAli Zaidi\n\n\n\n\n\n\n\n\n\n\n\n\nAuto Clipper Redux\n\n\n\nData Engineering\n\nAutomated Annotation\n\n\n\nNow that we have new data coming in lets clip every swing and find our labels\n\n\n\n\n\nNov 26, 2025\n\n\nAli Zaidi\n\n\n\n\n\n\n\n\n\n\n\n\nKeypoint Visualizer\n\n\n\nData Visualization\n\n\n\nOnce we have the resources to extract keypoints and normalize them, lets see how they look side by side\n\n\n\n\n\nNov 19, 2025\n\n\nAli Zaidi\n\n\n\n\n\n\n\n\n\n\n\n\nSwing Normalization\n\n\n\nData Engineering\n\n\n\nNow that we have an appropriate dataclass for our swings lets work on normalizing swings so that we can handle camera perturbations\n\n\n\n\n\nNov 18, 2025\n\n\nAli Zaidi\n\n\n\n\n\n\n\n\n\n\n\n\nSwing DataClass\n\n\n\nData Engineering\n\n\n\nNow that we have the resources to find the clipping indexes for a videos, lets expand the capacity by introducing a dataclass that can handle and organize alot of this inforamtion\n\n\n\n\n\nNov 17, 2025\n\n\nAli Zaidi\n\n\n\n\n\n\n\n\n\n\n\n\nKinematic Analysis\n\n\n\nData Visualization\n\n\n\nNow that we have our labeled clips, lets run some preliminary analysis over each of their keypoints and see what we can extract\n\n\n\n\n\nNov 15, 2025\n\n\nAli Zaidi\n\n\n\n\n\n\n\n\n\n\n\n\nAuto Clipping\n\n\n\nData Engineering\n\n\n\nEnd to end clipping and saving of multiswing videos to their component clips\n\n\n\n\n\nNov 13, 2025\n\n\nAli Zaidi\n\n\n\n\n\n\n\n\n\n\n\n\nInitial forays into auto-detect function of longer videos\n\n\n\nData Engineering\n\n\n\nFleshing out a way to find a consistent point in the swing to use for autodetection of swings\n\n\n\n\n\nNov 10, 2025\n\n\nAli Zaidi\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Clipping\n\n\n\nData Engineering\n\n\n\nA manual approach to hand labeling clipping videos\n\n\n\n\n\nSep 25, 2025\n\n\nAli Zaidi\n\n\n\n\n\n\n\n\n\n\n\n\nInitial Video Analysis\n\n\n\nEDA\n\n\n\n\n\n\n\n\n\nSep 22, 2025\n\n\nAli Zaidi\n\n\n\n\n\n\n\n\n\n\n\n\nEagle Swing Takes Off\n\n\n\nnews\n\n\n\n\n\n\n\n\n\nSep 19, 2025\n\n\nAli Zaidi\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/keypoint_visualizer/index.html",
    "href": "posts/keypoint_visualizer/index.html",
    "title": "Keypoint Visualizer",
    "section": "",
    "text": "Code\ndef animate_keypoints(keypoint_sequences, dark_mode=False, \n                      labels=None, vertical=False, fps=60,):\n    \"\"\"\n    Animates 1 to 3 keypoint sequences.\n    \n    Args:\n        keypoint_sequences: List of arrays (Frames, KPs, 2).\n        dark_mode (bool): Black background with lime elements if True.\n        vertical (bool): If True, stacks plots vertically. If False, places them side-by-side.\n        fps (int): Frames per second.\n        skeleton (list): Connection indices.\n    \"\"\"\n    skeleton = [\n        (0, 1), (0, 2), (1, 3), (2, 4),  # Face\n        (5, 6), (5, 7), (7, 9),          # Left Arm\n        (6, 8), (8, 10),                 # Right Arm\n        (5, 11), (6, 12),                # Torso\n        (11, 12),                        # Hips\n        (11, 13), (13, 15),              # Left Leg\n        (12, 14), (14, 16)               # Right Leg\n    ]    # 1. Input Normalization\n    if not isinstance(keypoint_sequences, list):\n        keypoint_sequences = [keypoint_sequences]\n    \n    if len(keypoint_sequences) &gt; 3:\n        print(\"Warning: Limiting visualization to first 3 sequences.\")\n        keypoint_sequences = keypoint_sequences[:3]\n        \n    num_plots = len(keypoint_sequences)\n    \n    # Validate labels\n    if labels and len(labels) != num_plots:\n        print(f\"Warning: Provided {len(labels)} labels for {num_plots} plots. Labels may not match.\")\n    \n    # 2. Style Configuration\n    if dark_mode:\n        bg_color = 'black'\n        line_color = 'lime'\n        joint_color = 'white'\n        text_color = 'white'\n    else:\n        bg_color = 'white'\n        line_color = 'black'\n        joint_color = 'red'\n        text_color = 'black'\n\n    # 3. Figure & Subplot Setup\n    if vertical:\n        nrows, ncols = num_plots, 1\n        figsize = (2, 2 * num_plots)\n    else:\n        nrows, ncols = 1, num_plots\n        figsize = (2 * num_plots, 2)\n\n    fig, axes = plt.subplots(nrows, ncols, figsize=figsize)\n    fig.patch.set_facecolor(bg_color)\n    \n    if num_plots == 1:\n        axes = [axes]\n        \n    plot_objects = []\n\n    # Loop through axes, data, and optionally labels\n    for i, (ax, data) in enumerate(zip(axes, keypoint_sequences)):\n        if data.shape[-1] == 3:\n            data = data[..., :2]\n            \n        ax.set_facecolor(bg_color)\n        ax.axis('off')\n        ax.set_aspect('equal')\n\n        # --- Add Label if provided ---\n        if labels and i &lt; len(labels):\n            ax.set_title(labels[i], color=text_color, fontsize=8, pad=8)\n        \n        # --- LIMITS CONFIGURATION ---\n        all_x = data[..., 0].flatten()\n        all_y = data[..., 1].flatten()\n        valid_mask = (all_x &gt; 0.1) & (all_y &gt; 0.1)\n\n        if valid_mask.any():\n            vx, vy = all_x[valid_mask], all_y[valid_mask]\n            pad = 50\n            ax.set_xlim(vx.min() - pad, vx.max() + pad)\n            # Pass (MAX, MIN) to put max values (feet) at the bottom\n            ax.set_ylim(vy.max() + pad, vy.min() - pad)\n        else:\n            ax.set_xlim(0, 640)\n            ax.set_ylim(480, 0)\n\n        # Create graphics objects\n        scat = ax.scatter([], [], s=30, c=joint_color, zorder=2)\n        lines = [ax.plot([], [], color=line_color, lw=2)[0] for _ in skeleton]\n        \n        plot_objects.append({'scat': scat, 'lines': lines, 'data': data, 'ax': ax})\n\n    # 4. Animation Logic\n    def init():\n        all_artists = []\n        for obj in plot_objects:\n            obj['scat'].set_offsets(np.empty((0, 2)))\n            for line in obj['lines']:\n                line.set_data([], [])\n            all_artists.append(obj['scat'])\n            all_artists.extend(obj['lines'])\n        return all_artists\n\n    def update(frame_idx):\n        all_artists = []\n        for obj in plot_objects:\n            data = obj['data']\n            idx = min(frame_idx, len(data) - 1)\n            current_frame = data[idx]\n            \n            mask = (current_frame[:, 0] &gt; 0.1) & (current_frame[:, 1] &gt; 0.1) & ~np.isnan(current_frame[:, 0])\n            \n            obj['scat'].set_offsets(current_frame[mask])\n            all_artists.append(obj['scat'])\n            \n            for line, (start, end) in zip(obj['lines'], skeleton):\n                if mask[start] and mask[end]:\n                    line.set_data(\n                        [current_frame[start, 0], current_frame[end, 0]],\n                        [current_frame[start, 1], current_frame[end, 1]]\n                    )\n                else:\n                    line.set_data([], [])\n                all_artists.append(line)\n                \n        return all_artists\n\n    max_frames = max(len(d) for d in keypoint_sequences)\n\n    anim = FuncAnimation(\n        fig, \n        update, \n        frames=max_frames, \n        init_func=init, \n        blit=True, \n        interval=1000/fps\n    )\n    \n    plt.close()\n    return anim\n\n\n\n\nCode\nfrom eagle_swing.data_class import *\nfrom fastai.vision.all import *\n\nbase_path = '../../../data/full_videos/ymirza'\nswing_days = ['jun8', 'aug9', 'sep14']\nparent_dir = f'{base_path}/{swing_days[-1]}'\nfiles = [file for file in get_files(parent_dir, extensions='.pkl') if file.name[:3] == 'IMG']\n\npost_proc = [interpolate_and_filter_pandas,]# normalize_by_average_torso,]\n\n\n\n\nCode\ndef animate_keypoints(keypoint_sequences, dark_mode=False, \n                      labels=None, vertical=False, fps=60):\n    \"\"\"\n    Animates 1 to 9 keypoint sequences.\n    \n    Args:\n        keypoint_sequences: List of arrays (Frames, KPs, 2).\n        dark_mode (bool): Black background with lime elements if True.\n        vertical (bool): If True and &lt;=3 sequences, stacks plots vertically. \n                        Ignored for &gt;3 sequences.\n        fps (int): Frames per second.\n        labels (list): Optional labels for each sequence.\n    \"\"\"\n    import math\n    \n    skeleton = [\n        (0, 1), (0, 2), (1, 3), (2, 4),  # Face\n        (5, 6), (5, 7), (7, 9),          # Left Arm\n        (6, 8), (8, 10),                 # Right Arm\n        (5, 11), (6, 12),                # Torso\n        (11, 12),                        # Hips\n        (11, 13), (13, 15),              # Left Leg\n        (12, 14), (14, 16)               # Right Leg\n    ]\n    \n    # 1. Input Normalization\n    if not isinstance(keypoint_sequences, list):\n        keypoint_sequences = [keypoint_sequences]\n    \n    # Updated Limit: 9 videos max\n    if len(keypoint_sequences) &gt; 9:\n        print(\"Warning: Limiting visualization to first 9 sequences.\")\n        keypoint_sequences = keypoint_sequences[:9]\n        \n    num_plots = len(keypoint_sequences)\n    \n    # Validate labels\n    if labels and len(labels) != num_plots:\n        print(f\"Warning: Provided {len(labels)} labels for {num_plots} plots. Labels may not match.\")\n    \n    # 2. Style Configuration\n    if dark_mode:\n        bg_color = 'black'\n        line_color = 'lime'\n        joint_color = 'white'\n        text_color = 'white'\n    else:\n        bg_color = 'white'\n        line_color = 'black'\n        joint_color = 'red'\n        text_color = 'black'\n\n    # 3. Figure & Subplot Setup with 2/3 column logic\n    if num_plots &lt;= 3:\n        # Original behavior for 1-3 plots\n        if vertical:\n            nrows, ncols = num_plots, 1\n            figsize = (2, 2 * num_plots)\n        else:\n            nrows, ncols = 1, num_plots\n            figsize = (2 * num_plots, 2)\n    else:\n        # Dynamic Grid Logic\n        if num_plots == 4:\n            ncols = 2  # Use 2 columns for exactly 4 plots (2x2)\n        else:\n            ncols = 3  # Use 3 columns for 5+ plots (up to 3x3)\n            \n        nrows = math.ceil(num_plots / ncols)\n        # Reduced size: 1.5 inches per subplot\n        figsize = (1.5 * ncols, 1.5 * nrows)\n\n    fig, axes = plt.subplots(nrows, ncols, figsize=figsize)\n    fig.patch.set_facecolor(bg_color)\n    \n    # Flatten axes array for consistent indexing\n    if num_plots == 1:\n        axes = [axes]\n    else:\n        axes = axes.flatten() if hasattr(axes, 'flatten') else axes\n    \n    # Hide extra subplots (e.g., if you have 5 plots in a 3x2=6 grid)\n    for idx in range(num_plots, len(axes)):\n        axes[idx].set_visible(False)\n        \n    plot_objects = []\n\n    # Loop through axes, data, and optionally labels\n    for i, (ax, data) in enumerate(zip(axes[:num_plots], keypoint_sequences)):\n        if data.shape[-1] == 3:\n            data = data[..., :2]\n            \n        ax.set_facecolor(bg_color)\n        ax.axis('off')\n        ax.set_aspect('equal')\n\n        # --- Add Label if provided ---\n        if labels and i &lt; len(labels):\n            # Smaller font for grid layouts\n            fontsize = 6 if num_plots &gt; 3 else 8\n            ax.set_title(labels[i], color=text_color, fontsize=fontsize, pad=4)\n        \n        # --- LIMITS CONFIGURATION ---\n        all_x = data[..., 0].flatten()\n        all_y = data[..., 1].flatten()\n        valid_mask = (all_x &gt; 0.1) & (all_y &gt; 0.1)\n\n        if valid_mask.any():\n            vx, vy = all_x[valid_mask], all_y[valid_mask]\n            pad = 50\n            ax.set_xlim(vx.min() - pad, vx.max() + pad)\n            ax.set_ylim(vy.max() + pad, vy.min() - pad)\n        else:\n            ax.set_xlim(0, 640)\n            ax.set_ylim(480, 0)\n\n        # Create graphics objects (scaled down for grid views)\n        point_size = 15 if num_plots &gt; 3 else 30\n        line_width = 1 if num_plots &gt; 3 else 2\n        \n        scat = ax.scatter([], [], s=point_size, c=joint_color, zorder=2)\n        lines = [ax.plot([], [], color=line_color, lw=line_width)[0] for _ in skeleton]\n        \n        plot_objects.append({'scat': scat, 'lines': lines, 'data': data, 'ax': ax})\n\n    if num_plots &gt; 3:\n        plt.tight_layout(pad=0.5)\n\n    # 4. Animation Logic\n    def init():\n        all_artists = []\n        for obj in plot_objects:\n            obj['scat'].set_offsets(np.empty((0, 2)))\n            for line in obj['lines']:\n                line.set_data([], [])\n            all_artists.append(obj['scat'])\n            all_artists.extend(obj['lines'])\n        return all_artists\n\n    def update(frame_idx):\n        all_artists = []\n        for obj in plot_objects:\n            data = obj['data']\n            idx = min(frame_idx, len(data) - 1)\n            current_frame = data[idx]\n            \n            mask = (current_frame[:, 0] &gt; 0.1) & (current_frame[:, 1] &gt; 0.1) & ~np.isnan(current_frame[:, 0])\n            \n            obj['scat'].set_offsets(current_frame[mask])\n            all_artists.append(obj['scat'])\n            \n            for line, (start, end) in zip(obj['lines'], skeleton):\n                if mask[start] and mask[end]:\n                    line.set_data(\n                        [current_frame[start, 0], current_frame[end, 0]],\n                        [current_frame[start, 1], current_frame[end, 1]]\n                    )\n                else:\n                    line.set_data([], [])\n                all_artists.append(line)\n                \n        return all_artists\n\n    max_frames = max(len(d) for d in keypoint_sequences)\n\n    anim = FuncAnimation(\n        fig, \n        update, \n        frames=max_frames, \n        init_func=init, \n        blit=True, \n        interval=1000/fps\n    )\n    \n    plt.close()\n    return anim\n\n\n\n\nCode\n# kps = [KpExtractor(file_name=files[x], get_swing_idx=True,\n#                         post_processors=post_proc, trim_to_swing=True,\n#                         acceleration_based_addressing=True) for x in range(10)]\n# lbls = [x.swing_idx for x in kps]\n# test_kps = [x.kps for x in kps]\n# [x.shape for x in test_kps]\n\n\n\n\nCode\n# animator = animate_keypoints(test_kps, vertical=True,\n#                               dark_mode=True, labels=lbls)\n# display(HTML(animator.to_jshtml()))\n\n\n\n\nCode\nkps = [KpExtractor(file_name=files[x], get_swing_idx=True,\n                        post_processors=post_proc, trim_to_swing=True,\n                        #acceleration_based_addressing=false,\n                  ) for x in range(10)]\nlbls = [x.swing_idx for x in kps]\ntest_kps = [x.kps for x in kps]\n[x.shape for x in test_kps]\n\n\n[(164, 17, 3),\n (180, 17, 3),\n (141, 17, 3),\n (135, 17, 3),\n (130, 17, 3),\n (137, 17, 3),\n (151, 17, 3),\n (159, 17, 3),\n (136, 17, 3),\n (160, 17, 3)]\n\n\n\n\nCode\nanimator = animate_keypoints(test_kps, vertical=True,\n                              dark_mode=True, labels=lbls)\ndisplay(HTML(animator.to_jshtml()))\n\n\nWarning: Limiting visualization to first 9 sequences.\nWarning: Provided 10 labels for 9 plots. Labels may not match.\n\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/vision_model/index.html",
    "href": "posts/vision_model/index.html",
    "title": "Forays into Vision Models",
    "section": "",
    "text": "Going to try to use PoseC3D\nhttps://arxiv.org/pdf/2104.13586\nWhich relies on a 3D heatmap volume instead of a graph sequence as the base representation of human skeletons. Compared to GCN-based methods, PoseConv3D is more effective in learning spatiotemporal features, more robust against pose estimation noises, and generalizes better in cross-dataset settings.\n\n\nCode\nbase_path = '../../../data/full_videos/ymirza'\n#day_path = f\"{base_path}/sep14\"\n#cleaned_df_paths = [file for file in get_files(day_path, extensions='.csv') if file.name == 'clean_lbls.csv']\ncleaned_df_paths = [file for file in get_files(base_path, extensions='.csv') if file.name == 'clean_lbls.csv']\ndf_holder = []\nfor df_path in cleaned_df_paths:\n    df_holder.append(pd.read_csv(df_path))\ncleaned_df = pd.concat(df_holder).reset_index(drop=True)\n#cleaned_df['swing_day'] = cleaned_df.pkl_path.map(lambda x: x.split('/')[0])\ncleaned_df['pkl_path'] = cleaned_df.pkl_path.map(lambda x: f'{base_path}/{x}')\nbefore_increment = 60\nafter_increment = 60\ncleaned_df['start_idx'] = cleaned_df['first_higher_wrists_backswing_frame'] - before_increment\ncleaned_df['end_idx'] = cleaned_df['first_higher_wrists_backswing_frame'] + after_increment\ndf5 = cleaned_df[cleaned_df.score.map(lambda x: x == 5)]\ndf1 = cleaned_df[cleaned_df.score.map(lambda x: x == 1)]\ntest_df = pd.concat([df5.iloc[:3], df1.iloc[:3]]).reset_index(drop=True)\nrand_idxs = np.random.randint(0, len(cleaned_df), 6)\ntest_df = cleaned_df.iloc[rand_idxs]\n\nSwExt_list = []\nfor idx, row in test_df.iterrows():\n    SwExt_list.append(SwingExtractor(row))\nclip_names = [SwExt_list[x].clip_name for x in range(len(SwExt_list))]\nprint(clip_names)\n\n\n['IMG_1272_swing_5_score_2', 'IMG_1019_swing_6_score_5', 'IMG_1183_swing_3_score_1', 'IMG_1274_swing_1_score_2', 'IMG_1273_swing_10_score_5', 'IMG_1015_swing_4_score_2']\n\n\n\n\nCode\nframes, _ = get_frames(f\"{test_df.iloc[0].pkl_path[:-3]}mp4\", resize_dim=None)\nframes.shape\n\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00&lt;00:00, 155.38it/s]\n\n\n(10, 1920, 1080, 3)\n\n\n\n\nCode\nkps_holder = []\nfor idx, row in test_df.iloc[:4].iterrows():\n    kps_holder.append(KpExtractor(row.pkl_path).kps[row.start_idx:row.end_idx])\nlen(kps_holder), [x.shape for x in kps_holder]\n\n\n(4, [(120, 17, 3), (120, 17, 3), (120, 17, 3), (120, 17, 3)])\n\n\n\n\nCode\ndebug_heatmap_values(kps_holder[0], image_shape=(1920, 1080))\n\n\n--- KEYPOINT DIAGNOSTIC REPORT ---\nInput Shape: (120, 17, 3)\nOriginal X Range: [375.88, 653.82]\nOriginal Y Range: [751.39, 1423.40]\nConfidence Score Range: [0.36, 1.10]\n\nScaled X Range: [19.49, 33.90] (Target: [0, 56])\nScaled Y Range: [21.92, 41.52] (Target: [0, 56])\nOut of Bounds Points: 0 / 2040\nDetected PIXEL keypoints. Scaled down to heatmap size.\n\nMax Value in a Sample Heatmap: 0.921026\n\n--- ANALYSIS ---\nðŸŸ¢ INFO: Data looks fine. The issue might be in the animation `vmax` parameter.\n\n\n\n\nCode\nheatmap = generate_heatmap_robust(kps_holder[0], (1920, 1080))\nheatmap.shape\n\n\nDetected PIXEL keypoints. Scaled down to heatmap size.\n\n\n(120, 17, 56, 56)\n\n\n\n\nCode\nshow_heatmap_animation(heatmap)\n\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n\nCode\ndef show_heatmap_animation(heatmap_volume):\n    T, K, H, W = heatmap_volume.shape\n    \n    # Collapse Keypoints: (T, K, H, W) -&gt; (T, H, W)\n    collapsed_video = np.max(heatmap_volume, axis=1)\n    \n    fig, ax = plt.subplots(figsize=(5, 5))\n    ax.axis('off')\n    \n    # Create the initial image object\n    # vmin/vmax ensure the colors don't flicker as intensities change\n    img = ax.imshow(collapsed_video[0], cmap='inferno', vmin=0, vmax=1)\n    title = ax.set_title(f\"Frame 0/{T}\")\n    \n    def update(frame):\n        img.set_array(collapsed_video[frame])\n        title.set_text(f\"Frame {frame}/{T}\")\n        return img, title\n    \n    ani = animation.FuncAnimation(\n        fig, \n        update, \n        frames=T, \n        interval=50, \n        blit=True\n    )\n    \n    # CRITICAL STEP: Convert to HTML5 video to display in notebook\n    plt.close() # Prevents the static \"Frame 0\" ghost image\n    return HTML(ani.to_jshtml())\n\n\ndef generate_heatmap_robust(keypoints, image_shape=(1080, 1920), output_shape=(56, 56), sigma=1.0):\n    \"\"\"\n    Robustly generates PoseC3D heatmaps by auto-detecting keypoint scale.\n    \n    Args:\n        keypoints (np.ndarray): Shape (T, K, C). \n                                If max value &lt;= 1.0, assumes normalized (0-1).\n                                If max value &gt; 1.0, assumes pixel coordinates.\n        image_shape (tuple): (H, W) original resolution (only used if keypoints are pixels).\n        output_shape (tuple): (h, w) target heatmap size (default 56x56).\n    \"\"\"\n    T, K, C = keypoints.shape\n    h, w = output_shape\n    H, W = image_shape\n    \n    xs = keypoints[:, :, 0]\n    ys = keypoints[:, :, 1]\n    \n    # --- AUTO-DETECTION LOGIC ---\n    max_val = np.max(keypoints[:, :, :2])\n    \n    if max_val &lt;= 1.0:\n        # CASE A: Normalized Coordinates (0.0 - 1.0)\n        # Simply multiply by heatmap dimensions\n        xs = xs * w\n        ys = ys * h\n        print(\"Detected NORMALIZED keypoints (0-1). Scaled to heatmap size.\")\n        \n    elif max_val &lt;= max(h, w) * 1.5:\n         # CASE B: Already Heatmap-Scaled (e.g., 0-56)\n        # Do nothing\n        print(\"Detected HEATMAP-SCALED keypoints. No scaling applied.\")\n        \n    else:\n        # CASE C: Original Pixel Coordinates (e.g., 0-1920)\n        # Scale down: (x / W) * w\n        xs = xs * (w / W)\n        ys = ys * (h / H)\n        print(\"Detected PIXEL keypoints. Scaled down to heatmap size.\")\n    \n    # Use confidence if available\n    scores = keypoints[:, :, 2] if C &gt; 2 else np.ones((T, K))\n\n    # --- GENERATE HEATMAPS ---\n    # Create grid (h, w)\n    xx, yy = np.meshgrid(np.arange(w), np.arange(h)) # (h, w)\n    \n    # Reshape for broadcasting\n    # Grid: (1, 1, h, w)\n    xx = xx[None, None, :, :]\n    yy = yy[None, None, :, :]\n    \n    # Keypoints: (T, K, 1, 1)\n    xs = xs[:, :, None, None]\n    ys = ys[:, :, None, None]\n    scores = scores[:, :, None, None]\n    \n    # Gaussian distance\n    d2 = (xx - xs)**2 + (yy - ys)**2\n    heatmap = np.exp(-d2 / (2.0 * sigma**2))\n    \n    # Apply scores\n    heatmap = heatmap * scores\n    \n    return heatmap.astype(np.float32)\n\n\n\n\nCode\ndef debug_heatmap_values(keypoints, image_shape=(1080, 1920)):\n    \"\"\"\n    Prints a diagnostic report of the keypoint data to find issues.\n    \"\"\"\n    if keypoints is None or keypoints.size == 0:\n        print(\"Error: keypoints array is empty!\")\n        return\n\n    # --- 1. Check Input Data ---\n    T, K, C = keypoints.shape\n    h, w = 56, 56  # Standard PoseC3D heatmap size\n    H, W = image_shape\n    \n    xs = keypoints[:, :, 0]\n    ys = keypoints[:, :, 1]\n    scores = keypoints[:, :, 2] if C &gt; 2 else np.ones((T, K))\n\n    print(\"--- KEYPOINT DIAGNOSTIC REPORT ---\")\n    print(f\"Input Shape: {keypoints.shape}\")\n    print(f\"Original X Range: [{xs.min():.2f}, {xs.max():.2f}]\")\n    print(f\"Original Y Range: [{ys.min():.2f}, {ys.max():.2f}]\")\n    print(f\"Confidence Score Range: [{scores.min():.2f}, {scores.max():.2f}]\")\n    \n    # --- 2. Check Scaling ---\n    if xs.max() &gt; 1.0: # Pixel mode\n        xs_scaled = xs * (w / W)\n        ys_scaled = ys * (h / H)\n    else: # Normalized mode\n        xs_scaled = xs * w\n        ys_scaled = ys * h\n    \n    print(f\"\\nScaled X Range: [{xs_scaled.min():.2f}, {xs_scaled.max():.2f}] (Target: [0, {w}])\")\n    print(f\"Scaled Y Range: [{ys_scaled.min():.2f}, {ys_scaled.max():.2f}] (Target: [0, {h}])\")\n    \n    # --- 3. Check for Out-of-Bounds Points ---\n    oob_x = np.sum((xs_scaled &lt; 0) | (xs_scaled &gt;= w))\n    oob_y = np.sum((ys_scaled &lt; 0) | (ys_scaled &gt;= h))\n    total_pts = xs.size\n    print(f\"Out of Bounds Points: {max(oob_x, oob_y)} / {total_pts}\")\n\n    # --- 4. Generate & Check a SINGLE Heatmap ---\n    # Use the robust generator\n    single_heatmap = generate_heatmap_robust(keypoints[T//2:T//2+1]) # Middle frame\n    print(f\"\\nMax Value in a Sample Heatmap: {single_heatmap.max():.6f}\")\n    \n    print(\"\\n--- ANALYSIS ---\")\n    if scores.max() &lt; 0.01:\n        print(\"ðŸ”´ CRITICAL: Confidence scores are all near zero. This is the most likely cause.\")\n    if max(oob_x, oob_y) &gt; 0:\n        print(\"ðŸ”´ CRITICAL: Keypoints are out of bounds. Check your `image_shape` parameter.\")\n    if single_heatmap.max() &lt; 1e-5:\n        print(\"ðŸŸ¡ WARNING: Max heatmap value is tiny. The plot will look black. Check sigma or scores.\")\n    if scores.max() &gt; 0.01 and max(oob_x, oob_y) == 0:\n        print(\"ðŸŸ¢ INFO: Data looks fine. The issue might be in the animation `vmax` parameter.\")"
  },
  {
    "objectID": "posts/smooth_movement/smooth.html",
    "href": "posts/smooth_movement/smooth.html",
    "title": "Final Swing Data Review",
    "section": "",
    "text": "Code\nfrom fastai.vision.all import *\nfrom eagle_swing.data_class import *\nfrom eagle_swing.video_utils import *\nfrom eagle_swing.find_landmarks import *\nfrom eagle_swing.animate import *\nfrom tqdm import tqdm\n\n\n\n\nCode\nbase_path = '../../../data/full_videos/ymirza'\n\n\n\n\nCode\nbase_path = '../../../data/full_videos/ymirza'\ndf = pd.read_csv(f'{base_path}/ymirza_lbls.csv')\ndf_nov16 = pd.read_csv(f'{base_path}/nov16/lbls.csv')\ndf = pd.concat([df, df_nov16]).reset_index(drop=True)\ndf = df[df.video_name.map(lambda x: x.split('_')[1][:2] != '08')].reset_index(drop=True)\ndf['pkl_path'] = df.pkl_path.map(lambda x: f'{base_path}/{x}')\ndf.shape\n\n\n(145, 5)\n\n\n\n\nCode\npkl_files = get_files(base_path, extensions='.pkl')\nmp4_files = [f\"{str(x)[:-3]}mp4\" for x in pkl_files]\n\n\n\n\nCode\nfirst_higher_list = []\n# for idx, row in tqdm(df.iterrows()):\nfor idx in tqdm(range(len(df))):\n    row = df.iloc[idx]\n    kps = KpExtractor(row.pkl_path).kps\n    first_higher_wrist = find_each_first_higher_wrist(find_all_higher_wrist_idxs(kps))\n    first_higher_list.append(first_higher_wrist[row.swing_index])\n\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 145/145 [01:38&lt;00:00,  1.48it/s]\n\n\n\n\nCode\n#df[df.clip_name == 'IMG_1091_swing_0_score_2'].pkl_path.item()\nkp_ext = KpExtractor(df[df.clip_name == 'IMG_1091_swing_0_score_2'].pkl_path.item())\nall_higher_wrists = find_all_higher_wrist_idxs(kp_ext.kps)\nlen(all_higher_wrists)\n\n\n612\n\n\n\n\nCode\ndf[df.video_name == 'IMG_1091']\n\n\n\n\n\n\n\n\n\nclip_name\nvideo_name\nswing_index\nscore\npkl_path\nfirst_highest_wrist_idx\nstart_idx\nend_idx\n\n\n\n\n92\nIMG_1091_swing_0_score_2\nIMG_1091\n0\n2\n../../../data/full_videos/ymirza/sep14/IMG_1091/keypoints/IMG_1091.pkl\n149\n119\n209\n\n\n93\nIMG_1091_swing_1_score_2\nIMG_1091\n1\n2\n../../../data/full_videos/ymirza/sep14/IMG_1091/keypoints/IMG_1091.pkl\n1477\n1447\n1537\n\n\n94\nIMG_1091_swing_2_score_5\nIMG_1091\n2\n5\n../../../data/full_videos/ymirza/sep14/IMG_1091/keypoints/IMG_1091.pkl\n2295\n2265\n2355\n\n\n95\nIMG_1091_swing_3_score_2\nIMG_1091\n3\n2\n../../../data/full_videos/ymirza/sep14/IMG_1091/keypoints/IMG_1091.pkl\n4100\n4070\n4160\n\n\n96\nIMG_1091_swing_4_score_4\nIMG_1091\n4\n4\n../../../data/full_videos/ymirza/sep14/IMG_1091/keypoints/IMG_1091.pkl\n6041\n6011\n6101\n\n\n97\nIMG_1091_swing_5_score_1\nIMG_1091\n5\n1\n../../../data/full_videos/ymirza/sep14/IMG_1091/keypoints/IMG_1091.pkl\n7459\n7429\n7519\n\n\n\n\n\n\n\n\n\nCode\nfind_each_first_higher_wrist(all_higher_wrists)\n\n\n[149, 1477, 2295, 4100, 6041, 7459, 8471, 10131, 12653, 13302]\n\n\n\n\nCode\nfind_each_first_higher_wrist??\n\n\n\nSignature: find_each_first_higher_wrist(higher_wrist_idxs, skip_frames=600)\nDocstring: &lt;no docstring&gt;\nSource:   \ndef find_each_first_higher_wrist(higher_wrist_idxs, \n                                 skip_frames=600, #60fps * 10 seconds\n                                ):\n    last_higher_idx = higher_wrist_idxs[0]\n    highest_idxs = [last_higher_idx,] #holder for our highest frames\n    while True:\n        next_higher_idxs = np.where((higher_wrist_idxs - last_higher_idx) &gt; skip_frames)[0]\n        if len(next_higher_idxs) == 0:\n            return highest_idxs\n        last_higher_idx = higher_wrist_idxs[next_higher_idxs[0]]\n        highest_idxs.append(last_higher_idx)\nFile:      ~/Desktop/golf/eagle-swing/eagleswing/eagle_swing/find_landmarks.py\nType:      function\n\n\n\n\n\nCode\ndf['first_highest_wrist_idx'] = first_higher_list\nbefore_increment = 30\nafter_increment = 60\ndf['start_idx'] = df.first_highest_wrist_idx - before_increment\ndf['end_idx'] = df.first_highest_wrist_idx + after_increment\n\n\n\n\nCode\nrandom_idxs = np.random.randint(0, len(df), 12)\n\n\n\n\nCode\nrandom_df = df.iloc[random_idxs].reset_index(drop=True)\nrandom_df['video_path'] = random_df.pkl_path.map(lambda x: f\"{x[:-3]}mp4\")\nrandom_df.head(2)\n\n\n\n\n\n\n\n\n\nclip_name\nvideo_name\nswing_index\nscore\npkl_path\nfirst_highest_wrist_idx\nstart_idx\nend_idx\nvideo_path\n\n\n\n\n0\nIMG_1273_swing_3_score_3\nIMG_1273\n3\n3\n../../../data/full_videos/ymirza/nov16/IMG_1273/keypoints/IMG_1273.pkl\n4204\n4174\n4264\n../../../data/full_videos/ymirza/nov16/IMG_1273/keypoints/IMG_1273.mp4\n\n\n1\nIMG_1091_swing_0_score_2\nIMG_1091\n0\n2\n../../../data/full_videos/ymirza/sep14/IMG_1091/keypoints/IMG_1091.pkl\n149\n119\n209\n../../../data/full_videos/ymirza/sep14/IMG_1091/keypoints/IMG_1091.mp4\n\n\n\n\n\n\n\n\n\nCode\nvideo_names = df.video_name.unique()\nlen(video_names), video_names[:5]\n\n\n(17,\n array(['IMG_1015', 'IMG_1016', 'IMG_1017', 'IMG_1018', 'IMG_1019'],\n       dtype=object))\n\n\n\n\nCode\nbad_df = df[df.video_name == 'IMG_1091'].reset_index(drop=True)\nbad_df['video_path'] = bad_df.pkl_path.map(lambda x: f\"{x[:-3]}mp4\")\nbad_df.shape\n\n\n(6, 9)\n\n\n\n\nCode\nbad_df\n\n\n\n\n\n\n\n\n\nclip_name\nvideo_name\nswing_index\nscore\npkl_path\nfirst_highest_wrist_idx\nstart_idx\nend_idx\nvideo_path\n\n\n\n\n0\nIMG_1091_swing_0_score_2\nIMG_1091\n0\n2\n../../../data/full_videos/ymirza/sep14/IMG_1091/keypoints/IMG_1091.pkl\n149\n119\n209\n../../../data/full_videos/ymirza/sep14/IMG_1091/keypoints/IMG_1091.mp4\n\n\n1\nIMG_1091_swing_1_score_2\nIMG_1091\n1\n2\n../../../data/full_videos/ymirza/sep14/IMG_1091/keypoints/IMG_1091.pkl\n1477\n1447\n1537\n../../../data/full_videos/ymirza/sep14/IMG_1091/keypoints/IMG_1091.mp4\n\n\n2\nIMG_1091_swing_2_score_5\nIMG_1091\n2\n5\n../../../data/full_videos/ymirza/sep14/IMG_1091/keypoints/IMG_1091.pkl\n2295\n2265\n2355\n../../../data/full_videos/ymirza/sep14/IMG_1091/keypoints/IMG_1091.mp4\n\n\n3\nIMG_1091_swing_3_score_2\nIMG_1091\n3\n2\n../../../data/full_videos/ymirza/sep14/IMG_1091/keypoints/IMG_1091.pkl\n4100\n4070\n4160\n../../../data/full_videos/ymirza/sep14/IMG_1091/keypoints/IMG_1091.mp4\n\n\n4\nIMG_1091_swing_4_score_4\nIMG_1091\n4\n4\n../../../data/full_videos/ymirza/sep14/IMG_1091/keypoints/IMG_1091.pkl\n6041\n6011\n6101\n../../../data/full_videos/ymirza/sep14/IMG_1091/keypoints/IMG_1091.mp4\n\n\n5\nIMG_1091_swing_5_score_1\nIMG_1091\n5\n1\n../../../data/full_videos/ymirza/sep14/IMG_1091/keypoints/IMG_1091.pkl\n7459\n7429\n7519\n../../../data/full_videos/ymirza/sep14/IMG_1091/keypoints/IMG_1091.mp4\n\n\n\n\n\n\n\n\n\nCode\nfull_video, fps = get_frames(f\"{bad_df.pkl_path[0][:-3]}mp4\", num_frames=None)\n\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13466/13466 [00:23&lt;00:00, 561.74it/s]\n\n\n\n\nCode\nview_videos(full_video)\n\n\n\n\n\n\n\nCode\nframes_holder = []\nfor idx, row in bad_df.iterrows():\n    kp_extracted = KpExtractor(row.pkl_path)\n    one_kps = kp_extracted.kps[row.start_idx:row.end_idx]\n    one_frames, fps = get_frames(row.video_path, \n                                 start_idx = row.start_idx, \n                                 num_frames = int(row.end_idx - row.start_idx))\n    frames_holder.append(one_frames)\n    print(row.clip_name)\n    animator = animate_keypoints(one_kps, dark_mode=True)\n    display(HTML(animator.to_jshtml()))\n\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:00&lt;00:00, 481.36it/s]\n\n\nIMG_1091_swing_0_score_2\n\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:00&lt;00:00, 457.23it/s]\n\n\nIMG_1091_swing_1_score_2\n\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:00&lt;00:00, 470.41it/s]\n\n\nIMG_1091_swing_2_score_5\n\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:00&lt;00:00, 483.92it/s]\n\n\nIMG_1091_swing_3_score_2\n\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:00&lt;00:00, 407.86it/s]\n\n\nIMG_1091_swing_4_score_4\n\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:00&lt;00:00, 451.77it/s]\n\n\nIMG_1091_swing_5_score_1\n\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n\nCode\nframes_holder = []\nfor idx, row in random_df.iterrows():\n    kp_extracted = KpExtractor(row.pkl_path)\n    \n    one_kps = kp_extracted.kps[row.start_idx:row.end_idx]\n    one_frames, fps = get_frames(row.video_path, \n                                 start_idx = row.start_idx, \n                                 num_frames = int(row.end_idx - row.start_idx))\n    frames_holder.append(one_frames)\n    print(row.clip_name)\n    animator = animate_keypoints(one_kps, dark_mode=True)\n    display(HTML(animator.to_jshtml()))\n\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:00&lt;00:00, 483.73it/s]\n\n\nIMG_1273_swing_3_score_3\n\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:00&lt;00:00, 470.59it/s]\n\n\nIMG_1091_swing_0_score_2\n\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:00&lt;00:00, 100.63it/s]\n\n\nIMG_1023_swing_0_score_1\n\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:00&lt;00:00, 97.28it/s]\n\n\nIMG_1023_swing_12_score_1\n\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:00&lt;00:00, 465.53it/s]\n\n\nIMG_1091_swing_0_score_2\n\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:00&lt;00:00, 446.27it/s]\n\n\nIMG_1089_swing_2_score_3\n\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:00&lt;00:00, 477.40it/s]\n\n\nIMG_1016_swing_6_score_5\n\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:00&lt;00:00, 494.26it/s]\n\n\nIMG_1092_swing_5_score_1\n\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:00&lt;00:00, 430.13it/s]\n\n\nIMG_1273_swing_9_score_4\n\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:00&lt;00:00, 469.93it/s]\n\n\nIMG_1087_swing_1_score_5\n\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:00&lt;00:00, 472.41it/s]\n\n\nIMG_1092_swing_3_score_1\n\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:00&lt;00:00, 98.35it/s]\n\n\nIMG_1018_swing_4_score_4\n\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/init_auto_swing_extraction/init_exploration.html",
    "href": "posts/init_auto_swing_extraction/init_exploration.html",
    "title": "Initial forays into auto-detect function of longer videos",
    "section": "",
    "text": "1) 2d keypoints of a full video\n2) Find the most relevant frames that correspond to a swing\n3) Crop and extract a corresponding video for each swing\n\n\n\n\n\nThe start times of every swing in IMG_1090.MOV are:\n ['0:28', '0:53', '1:27', '1:54', '2:25', '3:01']\n\n\n\n\n\n\nCode\nprint(f'Grabbing a clip from {files[0].name}')\nframes, fps = get_frames(files[0], \n                         per_second=False, # only grab every fps frame\n                         start_idx=600, # start 10 seconds in\n                         #start_idx=1200, # start 20 seconds in\n                         num_frames=1500, # only pull down 25 seconds of video\n                         #num_frames=250, # only pull down 4ish seconds of video)\n                         resize_dim=(256,256),\n                         show_progress=True\n                        )\nsave_frames(frames=frames, fps=fps, fname='useless_frames.mp4')\n\n\nGrabbing a clip from IMG_1090.MOV\n\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1500/1500 [02:34&lt;00:00,  9.68it/s]\n\n\n\n\n\n\n\n\nFirst 10 seconds are useless and not included\nOnly about 3 seconds of the first 35 seconds is relevant\nThe full video has 6 swings and is over 3 minutes long!\n\n\n\n\n\nI tried a few different approaches that did not work very consistently or well at all\nAfter a few days lets see if a simple approach will get the job done\nWe only want a close approximation of something in the middle of the swing frames themselves, once we have it, we can just pull 1-2 seconds before and after this middle frame\n\n\nusing our existing physics code to normalize the swings around the peak of the backswing like weâ€™ve already fleshed out (shown to work)\n\n\n\n\n\n\nThe simple extraction method will be to use a filter on 2d keypoints and say yes to any frame where both hands are above the shoulder\n\nIf both hands are above the shoulders, we know weâ€™re inside of a swing frames\nWhen giving the score, one hand is above the shoulder, so we need BOTH above\n\n\n\n\nCode\n# logger = MMLogger.get_instance('mmpose')\n# logger.setLevel('ERROR')  # or 'ERROR' for even less output\n# labeler = get_labeler('vit');\n# generate_labels(labeler, 'useless_frames.mp4', out_dir='keypoints');\n\n\n\n\n\n\n\nFirst\nOnly\nThe\n\n\n\nCode\nfrom swing_data import *\nkps = KpExtractor('keypoints/useless_frames.pkl').keypoint_data.kps\nkps.shape, kps[0,9]\n\n\n\n\nCode\nl_shoulder = kps[:, 5, 1] # Left Wrist KP\nr_shoulder = kps[:, 6, 1] # Right Wrist KP\nl_elbow = kps[:, 7, 1] # Left Elbow KP\nr_elbow = kps[:, 8, 1] # Right Elbow KP\nl_wrist = kps[:, 9, 1] # Left Wrist KP\nr_wrist = kps[:, 10, 1] # Right Wrist KP\n# less than is above\nleft_wrist_above_elbow = l_wrist &lt; l_elbow\nright_wrist_above_elbow = r_wrist &lt; r_elbow\nleft_wrist_above_sh = l_wrist &lt; l_shoulder\nright_wrist_above_sh = r_wrist &lt; r_shoulder\n\n\n\n\nCode\ncombined_true = left_wrist_above_elbow & right_wrist_above_elbow & left_wrist_above_sh & right_wrist_above_sh\nhigher_idxs = np.where(combined_true)[0]\nprint(f'There are {len(higher_idxs)} frames with the wrists above the elbow and shoulders')\n\n\nThere are 77 frames with the wrists above the elbow and shoulders\n\n\n\n\nCode\nhigher_frames = np.stack([frames[idx] for idx in higher_idxs])\nsave_frames(fname='higher_frames.mp4', frames=higher_frames)\nhigher_frames.shape\n\n\n(77, 256, 256, 3)\n\n\n\n\n\n\n\nâ€¦\n\n\n\nCode\nfirst_high_idx = higher_idxs[0]\nfirst_high_idx\n\n\n1150\n\n\n\n\nCode\n# get 1.5 seconds before and after first high index\ninit_idx = first_high_idx - 90\nfinal_idx = first_high_idx + 90\ninit_idx, final_idx\n\n\n(1060, 1240)\n\n\n\n\n\n\n\nâ€¦\n\nFirst 90 seconds of video\n\nâ€¦\nFirst 90 seconds of video clipped!\n\nâ€¦"
  },
  {
    "objectID": "posts/init_auto_swing_extraction/init_exploration.html#ive-been-hand-labeling-the-videos-and-then-extracting-clips-from-my-own-labels-this-is-not-feasible-to-do-in-a-timely-manner-and-requires-alot-of-manual-labor.-lets-find-a-way-to",
    "href": "posts/init_auto_swing_extraction/init_exploration.html#ive-been-hand-labeling-the-videos-and-then-extracting-clips-from-my-own-labels-this-is-not-feasible-to-do-in-a-timely-manner-and-requires-alot-of-manual-labor.-lets-find-a-way-to",
    "title": "Initial forays into auto-detect function of longer videos",
    "section": "",
    "text": "1) 2d keypoints of a full video\n2) Find the most relevant frames that correspond to a swing\n3) Crop and extract a corresponding video for each swing\n\n\n\n\n\nThe start times of every swing in IMG_1090.MOV are:\n ['0:28', '0:53', '1:27', '1:54', '2:25', '3:01']\n\n\n\n\n\n\nCode\nprint(f'Grabbing a clip from {files[0].name}')\nframes, fps = get_frames(files[0], \n                         per_second=False, # only grab every fps frame\n                         start_idx=600, # start 10 seconds in\n                         #start_idx=1200, # start 20 seconds in\n                         num_frames=1500, # only pull down 25 seconds of video\n                         #num_frames=250, # only pull down 4ish seconds of video)\n                         resize_dim=(256,256),\n                         show_progress=True\n                        )\nsave_frames(frames=frames, fps=fps, fname='useless_frames.mp4')\n\n\nGrabbing a clip from IMG_1090.MOV\n\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1500/1500 [02:34&lt;00:00,  9.68it/s]\n\n\n\n\n\n\n\n\nFirst 10 seconds are useless and not included\nOnly about 3 seconds of the first 35 seconds is relevant\nThe full video has 6 swings and is over 3 minutes long!\n\n\n\n\n\nI tried a few different approaches that did not work very consistently or well at all\nAfter a few days lets see if a simple approach will get the job done\nWe only want a close approximation of something in the middle of the swing frames themselves, once we have it, we can just pull 1-2 seconds before and after this middle frame\n\n\nusing our existing physics code to normalize the swings around the peak of the backswing like weâ€™ve already fleshed out (shown to work)\n\n\n\n\n\n\nThe simple extraction method will be to use a filter on 2d keypoints and say yes to any frame where both hands are above the shoulder\n\nIf both hands are above the shoulders, we know weâ€™re inside of a swing frames\nWhen giving the score, one hand is above the shoulder, so we need BOTH above\n\n\n\n\nCode\n# logger = MMLogger.get_instance('mmpose')\n# logger.setLevel('ERROR')  # or 'ERROR' for even less output\n# labeler = get_labeler('vit');\n# generate_labels(labeler, 'useless_frames.mp4', out_dir='keypoints');\n\n\n\n\n\n\n\nFirst\nOnly\nThe\n\n\n\nCode\nfrom swing_data import *\nkps = KpExtractor('keypoints/useless_frames.pkl').keypoint_data.kps\nkps.shape, kps[0,9]\n\n\n\n\nCode\nl_shoulder = kps[:, 5, 1] # Left Wrist KP\nr_shoulder = kps[:, 6, 1] # Right Wrist KP\nl_elbow = kps[:, 7, 1] # Left Elbow KP\nr_elbow = kps[:, 8, 1] # Right Elbow KP\nl_wrist = kps[:, 9, 1] # Left Wrist KP\nr_wrist = kps[:, 10, 1] # Right Wrist KP\n# less than is above\nleft_wrist_above_elbow = l_wrist &lt; l_elbow\nright_wrist_above_elbow = r_wrist &lt; r_elbow\nleft_wrist_above_sh = l_wrist &lt; l_shoulder\nright_wrist_above_sh = r_wrist &lt; r_shoulder\n\n\n\n\nCode\ncombined_true = left_wrist_above_elbow & right_wrist_above_elbow & left_wrist_above_sh & right_wrist_above_sh\nhigher_idxs = np.where(combined_true)[0]\nprint(f'There are {len(higher_idxs)} frames with the wrists above the elbow and shoulders')\n\n\nThere are 77 frames with the wrists above the elbow and shoulders\n\n\n\n\nCode\nhigher_frames = np.stack([frames[idx] for idx in higher_idxs])\nsave_frames(fname='higher_frames.mp4', frames=higher_frames)\nhigher_frames.shape\n\n\n(77, 256, 256, 3)\n\n\n\n\n\n\n\nâ€¦\n\n\n\nCode\nfirst_high_idx = higher_idxs[0]\nfirst_high_idx\n\n\n1150\n\n\n\n\nCode\n# get 1.5 seconds before and after first high index\ninit_idx = first_high_idx - 90\nfinal_idx = first_high_idx + 90\ninit_idx, final_idx\n\n\n(1060, 1240)\n\n\n\n\n\n\n\nâ€¦\n\nFirst 90 seconds of video\n\nâ€¦\nFirst 90 seconds of video clipped!\n\nâ€¦"
  },
  {
    "objectID": "posts/temporal_evolution/index.html",
    "href": "posts/temporal_evolution/index.html",
    "title": "Temporal Evolution",
    "section": "",
    "text": "Key Technical Notes for Golf Analysis  1. Noise & Smoothing: Raw pose estimation outputs (like MMPose/YOLO) usually contain high-frequency jitter. Taking the derivative (Â np.gradientÂ ) amplifies this noise. It is highly recommended to apply a Savitzky-Golay filter or a Butterworth low-pass filter to the raw keypoints before passing them to this function.  2. Vector Projection vs.Â Derivative:  - Derivative Method (Used above): . Simple and robust for general separation analysis.  - Projection Method: . This projects the relative velocity vector onto the line connecting the two points. It is mathematically equivalent but requires calculating velocity vectors first, which adds complexity.  3. Interpretation: In a golf swing, this metric is useful for â€œX-Factorâ€ analysis (separation between hips and shoulders) or measuring how quickly the hands move away from the body center during the downswing (radius extension).\n\nVelocity of angle\n\nAngular speed of a joint â€“ is the right elbow hitting 90 degrees faster on a 5 swing that a 1 swing?\n\nAcceleration of distance and angle:\n\nthe second derivative tells you the rate of change of velocity, could be useful at transition points and much more  â€“&gt; https://www.perplexity.ai/search/58255efe-03e6-48b0-87c3-0ffdc6c75edf\n\n\n\n\nCode\ndf = pd.read_csv('../../posts/new_golfer/stef_lbls.csv').reset_index(drop=True)\nbefore_increment = 45\nafter_increment = 45\ndf['start_idx'] = df.first_highest_wrist_idx - before_increment\ndf['end_idx'] = df.first_highest_wrist_idx + after_increment\n\n\n\n\nCode\ndf5 = df[df.score == 5].reset_index(drop=True)\ndf1 = df[df.score == 1].reset_index(drop=True)\ndf_low_high = pd.concat([df1, df5], ignore_index=True)\ndf_low_high.head(2)\n\n\n\n\n\n\n\n\n\nclip_name\nvideo_name\nswing_idx\nscore\npkl_path\nfirst_highest_wrist_idx\nstart_idx\nend_idx\n\n\n\n\n0\nIMG_1170_swing_0_score_1\nIMG_1170\n0\n1\n../../../data/full_videos/saugusta/IMG_1170/keypoints/IMG_1170.pkl\n1525\n1480\n1570\n\n\n1\nIMG_1173_swing_4_score_1\nIMG_1173\n4\n1\n../../../data/full_videos/saugusta/IMG_1173/keypoints/IMG_1173.pkl\n7212\n7167\n7257\n\n\n\n\n\n\n\n\n\nCode\nbefore_increment = 45\nafter_increment = 45\ndf_low_high['start_idx'] = df_low_high.first_highest_wrist_idx - before_increment\ndf_low_high['end_idx'] = df_low_high.first_highest_wrist_idx + after_increment\n\n\n\n\nCode\nrows = []\n#for idx, row in df_low_high.iterrows():\nfor idx, row in df.iterrows():\n    rows.append(row)\nscores = [x.score for x in rows]\n\n\n\n\nCode\nkps_holder = [KpExtractor(row.pkl_path).kps[row.start_idx: row.end_idx+30] for row in rows]# if row.video_name == 'IMG_1167']\n\n\n\n\nCode\n#rows[3].video_name\n\n\n\n\nCode\nframes, fps = get_frames(f\"{rows[3].pkl_path[:-3]}mp4\", num_frames=None)\nframes.shape\n\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7261/7261 [00:13&lt;00:00, 549.44it/s]\n\n\n(7261, 256, 256, 3)\n\n\n\n\nCode\nanimate_keypoints_interactive(kps_holder[:], vertical=False,\n                              dark_mode=True, )\n\n\nWarning: Limiting visualization to first 9 sequences.\n\n\n\n\n\n\n\nCode\n# top of downswing\ntop_of_swing_idx = [find_last_frame_before_downswing(kps) for kps in kps_holder]\n#top_of_swing_idx\n\n\n\n\nCode\n# after contact as swing finishes\nfinish_downswing_idx = [find_last_frame_wrist_is_right(kps) for kps in kps_holder]\n#finish_downswing_idx\n\n\n\n\nCode\ndownswing_frames = np.array(finish_downswing_idx) - np.array(top_of_swing_idx)\n#downswing_frames\n\n\n\n\nCode\n#scores\n\n\n\n\nCode\nspeed_df = pd.DataFrame([scores, downswing_frames], index=['score', 'number_of_frames']).T\nspeed_df.shape\n\n\n(35, 2)\n\n\n\n\nCode\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# 1. Recreating your dataframe\n\n# 2. Setup the plot style\nsns.set_theme(style=\"whitegrid\")\nplt.figure(figsize=(8, 6))\n\n# 3. Create a Box Plot (shows the summary stats)\nax = sns.boxplot(\n    x=\"score\", \n    y=\"number_of_frames\", \n    data=speed_df, \n    showfliers=False,  # Hide outliers from boxplot (points will show them)\n    width=0.5,\n    palette=\"vlag\"\n)\n\n# 4. Overlay a Strip Plot (shows the raw data points with jitter)\nsns.stripplot(\n    x=\"score\", \n    y=\"number_of_frames\", \n    data=speed_df, \n    size=8, \n    color=\".3\", \n    linewidth=0, \n    alpha=0.7,\n    jitter=True  # Spreads points out so they don't overlap\n)\n\n# 5. Final formatting\nplt.title('Distribution of Swing Duration by Score', fontsize=14)\nplt.xlabel('Swing Score', fontsize=12)\nplt.ylabel('Number of Frames', fontsize=12)\nplt.show()\n\n\n/tmp/ipykernel_14019/1142253455.py:12: FutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  ax = sns.boxplot(\n\n\n\n\n\n\n\nCode\n%matplotlib inline\nspeed_df.hist()\n\n\narray([[&lt;Axes: title={'center': 'score'}&gt;,\n        &lt;Axes: title={'center': 'number_of_frames'}&gt;]], dtype=object)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n[find_crossing_frames(kps) for kps in kps_holder]\n\n\n\n---------------------------------------------------------------------------\nIndexError                                Traceback (most recent call last)\nCell In[18], line 1\n----&gt; 1 [find_crossing_frames(kps) for kps in kps_holder]\n\nCell In[18], line 1, in &lt;listcomp&gt;(.0)\n----&gt; 1 [find_crossing_frames(kps) for kps in kps_holder]\n\nFile ~/Desktop/golf/eagle-swing/eagleswing/eagle_swing/temporal.py:206, in find_crossing_frames(keypoints)\n    195         events['left_hand_crosses_right_body'].append(t + 1)\n    197     # # --- Check 2: Left Hand crossing Right Body Line (Right -&gt; Left) ---\n    198     # dist_curr_r = get_signed_distance(kp_curr[R_HAND], kp_curr[R_SHOULDER], kp_curr[R_HIP])\n    199     # dist_next_r = get_signed_distance(kp_next[R_HAND], kp_next[R_SHOULDER], kp_next[R_HIP])\n   (...)\n    203     #     events['left_hand_crosses_right_body'].append(t + 1)\n    204     #     holder.append(t)\n--&gt; 206 events['time_between_crossing'] = holder[1] - holder[0]\n    208 return events\n\nIndexError: list index out of range\n\n\n\n\n\nCode\ndef get_signed_distance(p_hand, p_shoulder, p_hip):\n    \"\"\"\n    Returns &gt; 0 if hand is to the RIGHT of the shoulder-hip line.\n    Returns &lt; 0 if hand is to the LEFT of the shoulder-hip line.\n    Uses a vertical boundary when the hand is above the shoulder.\n    \"\"\"\n    x_h, y_h = p_hand[:2]\n    x_s, y_s = p_shoulder[:2]\n    x_hip, y_hip = p_hip[:2]\n    \n    # 1. Vertical Projection Fix:\n    # If hand is above the shoulder (y_h &lt; y_s in image coords), \n    # use the shoulder's X as the vertical boundary.\n    if y_h &lt; y_s:\n        return x_h - x_s\n\n    # 2. Standard Line Projection (Below Shoulder):\n    # Avoid division by zero\n    if abs(y_hip - y_s) &lt; 1e-6: \n        return x_h - x_s \n        \n    # Calculate x of the body line at the hand's y-coordinate\n    slope_inv = (x_hip - x_s) / (y_hip - y_s)\n    x_line_at_hand_y = x_s + (y_h - y_s) * slope_inv\n    \n    return x_h - x_line_at_hand_y\n\ndef find_crossing_frames(keypoints):\n    \"\"\"\n    Identifies frames where hands cross body lines in a specific direction (Right -&gt; Left).\n    \n    Args:\n        keypoints: Numpy array of shape (num_frames, num_kps, 2)\n    \n    Returns:\n        dict: Lists of frame indices where the crossing event completes.\n    \"\"\"\n    # COCO Indices\n    L_SHOULDER, L_HIP = 5, 11\n    R_SHOULDER, R_HIP = 6, 12\n    L_HAND, R_HAND = 9, 10  # Using Wrists as proxies for Hands\n\n    events = {\n        'right_hand_crosses_left_body': [], # Right Hand crossing Left Body Line\n        'left_hand_crosses_right_body': []  # Left Hand crossing Right Body Line\n    } \n    holder = []\n    # Iterate through frames\n    for t in range(len(keypoints) - 1):\n        kp_curr = keypoints[t]\n        kp_next = keypoints[t+1]\n\n        # --- Check 1: Right Hand crossing Left Body Line (Right -&gt; Left) ---\n        dist_curr = get_signed_distance(kp_curr[R_HAND], kp_curr[L_SHOULDER], kp_curr[L_HIP])\n        dist_next = get_signed_distance(kp_next[R_HAND], kp_next[L_SHOULDER], kp_next[L_HIP])\n        \n        # Check for transition from Positive (Right) to Negative (Left)\n        if dist_curr &gt; 0 and dist_next &lt;= 0:\n            events['right_hand_crosses_left_body'].append(t + 1)\n            holder.append(t)\n\n        # --- Check 2: Left Hand crossing Right Body Line (Right -&gt; Left) ---\n        dist_curr_l = get_signed_distance(kp_curr[L_HAND], kp_curr[R_SHOULDER], kp_curr[R_HIP])\n        dist_next_l = get_signed_distance(kp_next[L_HAND], kp_next[R_SHOULDER], kp_next[R_HIP])\n        \n        # Check for transition from Positive (Right) to Negative (Left)\n        if dist_curr_l &gt; 0 and dist_next_l &lt;= 0:\n            events['left_hand_crosses_right_body'].append(t + 1)\n\n    events['time_between_crossing'] = holder[-1] - holder[-2]\n\n    return events"
  },
  {
    "objectID": "posts/manual_clipping/00a_data_clipping.html",
    "href": "posts/manual_clipping/00a_data_clipping.html",
    "title": "Video Clipping",
    "section": "",
    "text": "1) csv with the appropriate information about original videos, swings\n2) ffmpeg commands that will dictate how the video is decoded/encoded to generate the clips\n     - Since videos are from an iphone --&gt; there are some peculiarities to consider: \n         - https://www.perplexity.ai/search/8176d69e-475a-4e7f-ba07-0b762adb7c65\nWe'll then create an appropriate clipped folder within folder holding all the full videos from a specific date\n\n\nCode\nbase_path = '../../../data/full_videos'\nswing_days = ['jun8', 'aug9', 'sep14']\nfiles = get_files(f'{base_path}/{swing_days[0]}', extensions='.MOV')\nlen(files), files[0]\n\n\n(13, Path('../../../data/full_videos/jun8/IMG_0851.MOV'))\n\n\n\n\nCode\ndf_jun8 = pd.read_csv(f'{base_path}/{swing_days[0]}/cleaned.csv').reset_index(drop=True)\ndf_aug9 = pd.read_csv(f'{base_path}/{swing_days[1]}/cleaned.csv').reset_index(drop=True)\ndf_sep14 = pd.read_csv(f'{base_path}/{swing_days[2]}/cleaned.csv').reset_index(drop=True)\ndf_jun8.head(1)\n\n\n\n\n\n\n\n\n\ninput_file\nswing_index\nscore\nstart\nend\noutput_file\n\n\n\n\n0\nIMG_0848.MOV\n0\n2\n00:20\n00:23\nIMG_0848_swing_0_score_2.mp4\n\n\n\n\n\n\n\n\n\nCode\n# just checking that the dataframe columns are the same\nassert((df_aug9.columns == df_jun8.columns).sum() == len(df_aug9.columns))\nassert((df_aug9.columns == df_sep14.columns).sum() == len(df_aug9.columns))\n\n\n\n\nCode\n## All the necessary code to take a dataframe and clip the videos however we need\n\ndef clip_videos(df, \n                input_path, \n                crf='18',\n                video_encoder='copy',\n                debug=False):\n    output_folder_path = f'{input_path}/crf_{crf}_vcodec_{video_encoder}'\n    for idx in range(len(df)):\n        make_clip(input_folder_path=input_path, \n                  output_folder_path=output_folder_path,\n                  row=df.iloc[idx],\n                 crf=crf,\n                 vcodec=video_encoder)\n        if debug: break\n    assert(len(os.listdir(output_folder_path)) == len(df))\n\ndef make_output_filename(row):\n    return f'{row.input_file.split(\".\")[0]}_swing_{row.swing_index}_score_{row.score}.mp4'\n\ndef make_clip(input_folder_path, \n              output_folder_path,\n              row, \n              time='0:03',\n              crf='18',\n              vcodec='copy'):\n    input_file_name = row.input_file\n    output_file_name = make_output_filename(row)\n    start = row.start\n    input_file_path = f'{input_folder_path}/{input_file_name}'\n    output_file_path = f'{output_folder_path}/{output_file_name}'\n    if os.path.isdir(output_folder_path) is False:\n        os.mkdir(output_folder_path)\n    ffmpeg.input(input_file_path, \n                 ss=start)\\\n        .output(output_file_path, \n                t=time, \n                vcodec=vcodec,\n                crf=crf, \n                acodec='aac',\n                y=None) \\\n        .global_args('-movflags', '+faststart') \\\n        .run()\n\n\n\n\nCode\n#clip_videos(df_sep14, input_path=f'{base_path}/{swing_days[2]}', video_encoder='libx264', crf=0)\n\n\n\n\nCode\n## clip_videos(df_aug9, input_path=f'{base_path}/{swing_days[1]}', video_encoder='libx264', crf=0)\n\n\n\n\nCode\n! python\n\n\nPython 3.10.11 (main, May 16 2023, 00:28:57) [GCC 11.2.0] on linux\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n&gt;&gt;&gt; \nTraceback (most recent call last):\n  File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\nKeyboardInterrupt\n&gt;&gt;&gt; \n\n\n\n\nCode\n#clip_videos(df_aug9, input_path=f'{base_path}/{swing_days[1]}')\n\n\n\n\nCode\n#clip_videos(df_sep14, input_path=f'{base_path}/{swing_days[2]}')"
  },
  {
    "objectID": "posts/manual_clipping/00a_data_clipping.html#lets-work-on-creating-a-programmatic-way-to-receive-clip-full-videos-into-clips-of-individual-swings",
    "href": "posts/manual_clipping/00a_data_clipping.html#lets-work-on-creating-a-programmatic-way-to-receive-clip-full-videos-into-clips-of-individual-swings",
    "title": "Video Clipping",
    "section": "",
    "text": "1) csv with the appropriate information about original videos, swings\n2) ffmpeg commands that will dictate how the video is decoded/encoded to generate the clips\n     - Since videos are from an iphone --&gt; there are some peculiarities to consider: \n         - https://www.perplexity.ai/search/8176d69e-475a-4e7f-ba07-0b762adb7c65\nWe'll then create an appropriate clipped folder within folder holding all the full videos from a specific date\n\n\nCode\nbase_path = '../../../data/full_videos'\nswing_days = ['jun8', 'aug9', 'sep14']\nfiles = get_files(f'{base_path}/{swing_days[0]}', extensions='.MOV')\nlen(files), files[0]\n\n\n(13, Path('../../../data/full_videos/jun8/IMG_0851.MOV'))\n\n\n\n\nCode\ndf_jun8 = pd.read_csv(f'{base_path}/{swing_days[0]}/cleaned.csv').reset_index(drop=True)\ndf_aug9 = pd.read_csv(f'{base_path}/{swing_days[1]}/cleaned.csv').reset_index(drop=True)\ndf_sep14 = pd.read_csv(f'{base_path}/{swing_days[2]}/cleaned.csv').reset_index(drop=True)\ndf_jun8.head(1)\n\n\n\n\n\n\n\n\n\ninput_file\nswing_index\nscore\nstart\nend\noutput_file\n\n\n\n\n0\nIMG_0848.MOV\n0\n2\n00:20\n00:23\nIMG_0848_swing_0_score_2.mp4\n\n\n\n\n\n\n\n\n\nCode\n# just checking that the dataframe columns are the same\nassert((df_aug9.columns == df_jun8.columns).sum() == len(df_aug9.columns))\nassert((df_aug9.columns == df_sep14.columns).sum() == len(df_aug9.columns))\n\n\n\n\nCode\n## All the necessary code to take a dataframe and clip the videos however we need\n\ndef clip_videos(df, \n                input_path, \n                crf='18',\n                video_encoder='copy',\n                debug=False):\n    output_folder_path = f'{input_path}/crf_{crf}_vcodec_{video_encoder}'\n    for idx in range(len(df)):\n        make_clip(input_folder_path=input_path, \n                  output_folder_path=output_folder_path,\n                  row=df.iloc[idx],\n                 crf=crf,\n                 vcodec=video_encoder)\n        if debug: break\n    assert(len(os.listdir(output_folder_path)) == len(df))\n\ndef make_output_filename(row):\n    return f'{row.input_file.split(\".\")[0]}_swing_{row.swing_index}_score_{row.score}.mp4'\n\ndef make_clip(input_folder_path, \n              output_folder_path,\n              row, \n              time='0:03',\n              crf='18',\n              vcodec='copy'):\n    input_file_name = row.input_file\n    output_file_name = make_output_filename(row)\n    start = row.start\n    input_file_path = f'{input_folder_path}/{input_file_name}'\n    output_file_path = f'{output_folder_path}/{output_file_name}'\n    if os.path.isdir(output_folder_path) is False:\n        os.mkdir(output_folder_path)\n    ffmpeg.input(input_file_path, \n                 ss=start)\\\n        .output(output_file_path, \n                t=time, \n                vcodec=vcodec,\n                crf=crf, \n                acodec='aac',\n                y=None) \\\n        .global_args('-movflags', '+faststart') \\\n        .run()\n\n\n\n\nCode\n#clip_videos(df_sep14, input_path=f'{base_path}/{swing_days[2]}', video_encoder='libx264', crf=0)\n\n\n\n\nCode\n## clip_videos(df_aug9, input_path=f'{base_path}/{swing_days[1]}', video_encoder='libx264', crf=0)\n\n\n\n\nCode\n! python\n\n\nPython 3.10.11 (main, May 16 2023, 00:28:57) [GCC 11.2.0] on linux\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n&gt;&gt;&gt; \nTraceback (most recent call last):\n  File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\nKeyboardInterrupt\n&gt;&gt;&gt; \n\n\n\n\nCode\n#clip_videos(df_aug9, input_path=f'{base_path}/{swing_days[1]}')\n\n\n\n\nCode\n#clip_videos(df_sep14, input_path=f'{base_path}/{swing_days[2]}')"
  },
  {
    "objectID": "posts/manual_clipping/00a_data_clipping.html#now-some-code-to-pull-down-the-frames",
    "href": "posts/manual_clipping/00a_data_clipping.html#now-some-code-to-pull-down-the-frames",
    "title": "Video Clipping",
    "section": "Now some code to pull down the frames",
    "text": "Now some code to pull down the frames\n\n\nCode\ndef get_frames(swing_path, \n               resize=True, \n               width=256, \n               height=256,\n               debug=False):\n    capture = cv2.VideoCapture(swing_path)\n    frame_count = int(capture.get(cv2.CAP_PROP_FRAME_COUNT))\n    frame_width = int(capture.get(cv2.CAP_PROP_FRAME_WIDTH))\n    frame_height = int(capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n    video_array = np.empty((frame_count, frame_height, frame_width, 3), dtype=np.uint8)\n    idx = 0\n    while idx &lt; frame_count:\n        ret, frame = capture.read()\n        if not ret:\n            break\n        video_array[idx] = frame\n        idx += 1\n\n    capture.release()\n    if debug:\n        print(video_array.shape)\n    video_array = [convert_rgb(frame) for frame in video_array]\n    if resize:\n        video_array = np.array([resize_frame(frame, width, height) for frame in video_array])\n    return video_array\n\ndef resize_frame(frame, width=256, height=256):\n    return cv2.resize(frame, (width, height))\n\ndef convert_rgb(frame):\n    return cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n\ndef plot_three(image1, image2, image3=None):\n    # Create figure with 1 row, 3 columns of subplots\n    if image3 is None:\n        fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n    else:\n        fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n\n    # Plot each image on its respective axis\n    axes[0].imshow(image1)\n    axes[0].set_title('Frame 1')\n    axes[0].axis('off')  # Remove axis ticks and labels\n\n    axes[1].imshow(image2)\n    axes[1].set_title('Frame 2')\n    axes[1].axis('off')\n\n    if image3 is not None:\n        axes[2].imshow(image3)\n        axes[2].set_title('Frame 3 or Diff')\n        axes[2].axis('off')\n\n    plt.tight_layout()  # Adjust spacing between subplots\n    plt.show()\n\n\n\n\nCode\njun8_files = get_files(f'{base_path}/jun8/crf_18_vcodec_copy')\naug19_files = get_files(f'{base_path}/aug9/crf_18_vcodec_copy')\nsep14_files = get_files(f'{base_path}/sep14/crf_18_vcodec_copy')\nlen(jun8_files), len(aug19_files), len(sep14_files)\n\n\n(85, 78, 46)\n\n\n\n\nCode\njun_files_18 = get_files(f'{base_path}/jun8/crf_18_vcodec_copy')\njun_files_0 = get_files(f'{base_path}/jun8/crf_0_vcodec_libx264')\n\n\n\n\nCode\njun_files_18[0], jun_files_0[0]\n\n\n(Path('../../../data/full_videos/jun8/crf_18_vcodec_copy/IMG_0848_swing_0_score_2.mp4'),\n Path('../../../data/full_videos/jun8/crf_0_vcodec_libx264/IMG_0848_swing_0_score_2.mp4'))\n\n\n\n\nCode\naug19_files\n\n\n(#78) [Path('../../../data/full_videos/aug9/crf_18_vcodec_copy/IMG_1014_swing_10_score_1.mp4'),Path('../../../data/full_videos/aug9/crf_18_vcodec_copy/IMG_1023_swing_4_score_5.mp4'),Path('../../../data/full_videos/aug9/crf_18_vcodec_copy/IMG_1015_swing_10_score_4.mp4'),Path('../../../data/full_videos/aug9/crf_18_vcodec_copy/IMG_1015_swing_6_score_1.mp4'),Path('../../../data/full_videos/aug9/crf_18_vcodec_copy/IMG_1018_swing_0_score_4.mp4'),Path('../../../data/full_videos/aug9/crf_18_vcodec_copy/IMG_1023_swing_0_score_1.mp4'),Path('../../../data/full_videos/aug9/crf_18_vcodec_copy/IMG_1023_swing_13_score_3.mp4'),Path('../../../data/full_videos/aug9/crf_18_vcodec_copy/IMG_1017_swing_2_score_4.mp4'),Path('../../../data/full_videos/aug9/crf_18_vcodec_copy/IMG_1014_swing_5_score_3.mp4'),Path('../../../data/full_videos/aug9/crf_18_vcodec_copy/IMG_1023_swing_12_score_1.mp4'),Path('../../../data/full_videos/aug9/crf_18_vcodec_copy/IMG_1019_swing_7_score_1.mp4'),Path('../../../data/full_videos/aug9/crf_18_vcodec_copy/IMG_1014_swing_6_score_2.mp4'),Path('../../../data/full_videos/aug9/crf_18_vcodec_copy/IMG_1015_swing_1_score_1.mp4'),Path('../../../data/full_videos/aug9/crf_18_vcodec_copy/IMG_1018_swing_3_score_2.mp4'),Path('../../../data/full_videos/aug9/crf_18_vcodec_copy/IMG_1023_swing_5_score_5.mp4'),Path('../../../data/full_videos/aug9/crf_18_vcodec_copy/IMG_1015_swing_8_score_1.mp4'),Path('../../../data/full_videos/aug9/crf_18_vcodec_copy/IMG_1018_swing_9_score_5.mp4'),Path('../../../data/full_videos/aug9/crf_18_vcodec_copy/IMG_1014_swing_13_score_3.mp4'),Path('../../../data/full_videos/aug9/crf_18_vcodec_copy/IMG_1017_swing_4_score_5.mp4'),Path('../../../data/full_videos/aug9/crf_18_vcodec_copy/IMG_1016_swing_0_score_4.mp4')...]\n\n\n\n\nCode\nVideo(aug19_files[0], width=200, height=300)\n\n\n\n      Your browser does not support the video element.\n    \n\n\n\n\nCode\nVideo(jun8_files[0], width=200, height=300)\n\n\n\n      Your browser does not support the video element.\n    \n\n\n\n\nCode\n#Video??"
  },
  {
    "objectID": "posts/swing_dataclass/index.html",
    "href": "posts/swing_dataclass/index.html",
    "title": "Swing DataClass",
    "section": "",
    "text": "We need functionality that stores the keypoints of a swing and computes/stores various components of interest, having these functions stored into a dataclass can help with modeling and plotting things quickly in order to extract useful information of how components evolve as the swing progresses\n- The angle of the hips and shoulders\n- The angle of joints (wrist, elbow + hand)\n- Club head information\n\nBy using abstract functions, we can compute the distance and angles between components and try to extract meaningful information fromm their relationship as the swing progresses\n\n\nCode\nfrom typing import TypeVar, Generic, List, Optional, Callable\nfrom dataclasses import dataclass, field\nimport numpy as np\nimport pickle\nimport cv2\n\n\n\n\nCode\nclass SwingMetaData:\n    \"\"\"Data Container for a swings video metadata\n    \"\"\"\n    def __init__(self,\n                 path: str,\n                 get_swing_idx=False,\n                 get_score=False,\n                 ):\n        \"\"\"\n        Initialize the swing data and associated metadata\n        \n        Args:\n            path: file_path to data\n        \"\"\"\n        self.path = path\n        self.str_path = self.get_str_path()\n        self.video_path = f'{self.str_path.split(\".\")[-2]}.mp4'\n        self.file_name = self.str_path.split('/')[-1].split('.')[0]\n        if get_swing_idx:\n            self.swing_idx = int(self.file_name.split('_')[-3])\n        if get_score:\n            self.score = self.file_name.split('_')[-1].split('.')[0]\n\n    def get_str_path(self):\n        # Just making sure the path being used is a str + not path object\n        return str(self.path)\n\n    def get_video_name(self):\n        video = '_'.join(self.str_path.split('/')[1].split('_')[:2])\n        return video\n\n\n\n\nOur meta class can store useful information like the filename \n ---&gt; IMG_1093_swing_6_score_None\nAlso the swing index \n ---&gt; 6\nAnd the score (when added) \n ---&gt; None\nFor plotting and output purposes, a path to our labeled video is also available\n\n\n\n\nCode\nclass SwingKeypointData(SwingMetaData):\n    \"\"\"\n    Class to handle keypoint data\n    Will take a videos metadata and pull down keypoint values and scores\n    \"\"\"\n    \n    def __init__(self, video_path):\n        super().__init__(video_path)\n        #self.metadata = metadata\n        self.kp_dicts = self.get_kp_dicts()\n        self.key_points = self.get_keypoints()\n        self.scores = self.get_scores()\n        self.kps = np.concatenate([self.key_points, np.expand_dims(self.scores, -1)], axis=2)\n\n\n    def get_kp_dicts(self):\n        # Get the frame by frame output dicts from pose estimation models\n        with open(self.str_path, 'rb') as f:\n            loaded_dicts = pickle.load(f)\n        return loaded_dicts\n\n        \n    def get_keypoints(self):\n        kp_dicts = self.kp_dicts\n        return np.stack([self.kp_dicts[key]['keypoints'] for key in kp_dicts.keys()])\n        \n        \n    def get_scores(self):\n        kp_dicts = self.kp_dicts\n        return np.stack([self.kp_dicts[key]['keypoint_scores'] for key in kp_dicts.keys()])\n\n\n    def get_frame(self, idx):\n        ''' Just grabs a single frames keypoints and scores\n        '''\n        kps = self.key_points[idx]\n        scores = self.scores[idx]\n        return np.column_stack((kps, scores))\n\n    \n    def get_frames(self, indexes):\n        '''\n        num_idxs = len(Indexes)\n        Takes a list of indexes and returns an array wof [num_idxs, 17, 3]\n        [1] 17 keypoint markers\n        [2] 3 keypoint values/certaintainty (X, Y, Score)\n        '''\n        return np.stack([self.get_frame(idx) for idx in indexes])\n\n    \n    def __len__(self):\n        return len(self.key_points)\n\n\n\n\nwith our SwingKeyPointData class, we can store the raw keypoint values\nA swings full keypoints/confidence array would have shape: (180, 17, 3)\nIf we want to access just the keypoints we can we can access \n    the \"key_points\" attribute: (180, 17, 2)\nIf we are interested in seeing just confidence values we can access \n    the \"scores\" attribute: (180, 17)\n\n\n\n\n\nNow we are in a position to create a superclass that inherits these components and stores a more rich representation of our data\n\n\nCode\nclass KpExtractor(SwingMetaData):\n    def __init__(self, \n                 file_name,\n                 get_swing_idx=False,\n                 get_score=False,\n                 score_threshold=None):\n        super().__init__(file_name, \n                         get_swing_idx, \n                         get_score)\n        self.keypoint_data = SwingKeypointData(file_name)\n        self.score_threshold = score_threshold\n        self.kps = self.threshold_score(self.keypoint_data, score_threshold)\n\n        self.coco_idxs = {\"L_SH\":5, \"R_SH\":6, \"L_EL\":7, \"R_EL\":8, \n             \"L_WR\":9, \"R_WR\":10, \"L_HI\":11, \"R_HI\":12, #HIP\n             \"L_KN\":13, \"R_KN\":14, \"L_ANK\":15, \"R_ANK\":16}\n        \n        # Dynamically create attributes using setattr\n        for attr_name, coco_key in self.coco_idxs.items():\n            kp_val = self.kps[:, coco_key, :].astype(float).copy()\n            setattr(self, attr_name.lower(), kp_val)  # Lowercase only\n    \n    def threshold_score(self, kps, threshold_value=0.5):\n        if threshold_value is None: \n            return self.keypoint_data.kps.astype(float).copy()\n        # punch up score values to a threshold\n        kps = self.keypoint_data.kps.astype(float).copy()\n        mask = kps[..., 2] &lt; threshold_value\n        kps[mask, 2] = threshold_value\n        return kps\n\n    # helper function to index specific joints\n    def __getattr__(self, name):\n        # Convert requested attribute to lowercase and try to find it\n        lower_name = name.lower()\n        try:\n            return object.__getattribute__(self, lower_name)\n        except AttributeError:\n            raise AttributeError(f\"'{type(self).__name__}' object has no attribute '{name}'\")\n\n\n\n\nWith our KpExtractor class, we can interrogate our data more effectively\nA swings full keypoints/confidence can still be found with \".kp\" paradigm \n    --&gt; here is the shape of the keypoints:(180, 17, 3)\nIf we want to access just keypoints of a single point -- can access this\n    w/ \".X_YY\" paradigm, here is the array shape of the left shoulder: (180, 3)\n    where \"X\" represents left or right and \n    \"YY\" corresponds to a keypoint \"L_WR--&gt; left wrist\n\n\n\n\nCode\nl_sh = kp_0.l_sh\nr_sh = kp_0.r_sh\nl_wr = kp_0.l_wr\nr_wr = kp_0.r_wr\n\n\n\n\nCode\nl_sh.shape, l_sh[:, 0].shape\n\n\n((180, 3), (180,))"
  },
  {
    "objectID": "posts/normalize_swings/index.html",
    "href": "posts/normalize_swings/index.html",
    "title": "Swing Normalization",
    "section": "",
    "text": "Code\nl_sh = kp_0.l_sh\nr_sh = kp_0.r_sh\nl_wr = kp_0.l_wr\nr_wr = kp_0.r_wr\nCode\nl_sh.shape, l_sh[:, 0].shape\n\n\n((180, 3), (180,))"
  },
  {
    "objectID": "posts/normalize_swings/index.html#lets-flesh-out-some-functions-to-derive-useful-distance-and-degree-relationships",
    "href": "posts/normalize_swings/index.html#lets-flesh-out-some-functions-to-derive-useful-distance-and-degree-relationships",
    "title": "Swing Normalization",
    "section": "Lets flesh out some functions to derive useful distance and degree relationships",
    "text": "Lets flesh out some functions to derive useful distance and degree relationships\n*** must keep in mind the following: - x increases to the right â†’ same as normal. - y usually increases downwards, opposite of standard Cartesian. - If we want â€œupwardsâ€ to be positive angle (like in usual math diagrams), Â  arctan2 angles will be flipped vertically compared to that intuition. - If we want a more â€œmath-likeâ€ angle where up is positive y â€“&gt; negate dy\n\n\nCode\ndef get_kp_xy_components(kps):\n    # [0] index is horizontal value (x) and [1] is vertical (y)\n    x_component = kps[:, 0]\n    y_component = kps[:, 1]\n    return x_component, y_component\n    \ndef get_angle_degree(first_kps, second_kps):\n    first_x_arr, first_y_arr = get_kp_xy_components(first_kps)\n    second_x_arr, second_y_arr = get_kp_xy_components(second_kps)\n    dx = first_x_arr - second_x_arr\n    dy = first_y_arr - second_y_arr\n    angle_radians = np.arctan2(dy, dx)\n    angle_degree = np.degrees(angle_radians)\n    return angle_degree\n\ndef get_kps_distance(first_kps, second_kps):\n    first_x_arr, first_y_arr = get_kp_xy_components(first_kps)\n    second_x_arr, second_y_arr = get_kp_xy_components(second_kps)\n    dx = first_x_arr - second_x_arr\n    dy = first_y_arr - second_y_arr\n    distance = np.sqrt(dx**2 + dy**2)\n    return distance\n\n\nFrom Claude:  ** Image Coordinate System **  â€“&gt; In video/image coordinates, the y-axis increases downward (not upward like mathematical convention). This means:  â€¢ An angle of 0Â° points right  â€¢ An angle of 90Â° points down (not up)  â€¢ An angle of -90Â° points up (not down) \n** Angle Range **  â€“&gt; The function returns angles in [-180, 180], where negative angles represent clockwise rotation from the positive x-axis and positive angles represent counter-clockwise rotation.\n\nWe need to account for potential perturbations â€“ such as from the camera orientation and also potenital shake in the camera itself, a simple way to manage this is to normalize the coordinates relative to something within the body\n- This way absolute position values won't matter --&gt; if the camera moves up, the height values of the feet will have shifted in the frame, but the player did not move up in the vertical dimension\n- Can be done by dividing all keypoint values by a refernce distance that remains anatomically stable frame by frame\n- These people tried out a bunch of different normalization techniques and a bunch worked well:\n    - https://www.mdpi.com/1424-8220/22/11/4245\n    - Look at the points separated in their own space once normalized on right!\n\n\n\nWhy is this important?\n\nCamera distance, focal length, and resolution create different pixel-space scales for the same physical movements. Normalization converts absolute pixel distances into scale-invariant relative proportions, making measurements comparable across videos. For example, torso-based normalization maintains consistent body proportions while allowing limb movements to vary naturally"
  },
  {
    "objectID": "posts/normalize_swings/index.html#after-normalization-our-get_distance-returns-values-like-0.99-99-of-torso-length-instead-of-158-pixels",
    "href": "posts/normalize_swings/index.html#after-normalization-our-get_distance-returns-values-like-0.99-99-of-torso-length-instead-of-158-pixels",
    "title": "Swing Normalization",
    "section": "After normalization, our get_distance() returns values like 0.99 (99% of torso length) instead of 158 pixels",
    "text": "After normalization, our get_distance() returns values like 0.99 (99% of torso length) instead of 158 pixels\n\nEnabling direct comparison between different recording setups\n\n\nCode\n# Use one diagonal to normalize\ndef normalize_by_torso_diagonal(kps, l_sh_to_r_hip=True):\n    if l_sh_to_r_hip: #left shoulder to right hip\n        shoulder = kps.l_sh\n        hip = kps.r_hi\n    else:\n        shoulder = kps.r_sh\n        hip = kps.l_hi\n    \n    torso_diagonal = np.sqrt(np.sum((shoulder - hip)**2, axis=1))\n    normalized_kps = kps.kps / torso_diagonal[:, np.newaxis, np.newaxis]\n    \n    return normalized_kps\n\n# Use BOTH diagonals to normalize\ndef normalize_by_average_torso(kps):\n    left_shoulder = kps.l_sh\n    right_shoulder = kps.r_sh\n    left_hip = kps.l_hi\n    right_hip = kps.r_hi\n    \n    diagonal1 = np.sqrt(np.sum((left_shoulder - right_hip)**2, axis=1))\n    diagonal2 = np.sqrt(np.sum((right_shoulder - left_hip)**2, axis=1))\n    avg_torso = (diagonal1 + diagonal2) / 2.0\n    return kps.kps / avg_torso[:, np.newaxis, np.newaxis]\n\n#normalize_by_average_torso(kp_0).shape\n\n\n\n\nOne more normalization techniqueâ€¦..\nImagine you took a picture of your friend, but you held the camera crooked. Now your friend looks like they are leaning sideways, even though they were standing straight.\nIf you wanted to measure how tall they are or where their hands are, itâ€™s hard to do because everything is tilted.\nThis code fixes the picture.\nThe Pin (Anchor Point): First, it takes a pin and sticks it through a specific spot on the photo (like their hip or the center of their chest) and pins it to the wall.\nThe Shoulders: Then, it looks at their left shoulder and their right shoulder. It draws a line between them.\nThe Spin: It grabs the picture and spins it on the wall until that shoulder line is perfectly flat (horizontal).\nThe Result: Now, no matter how crooked the camera was originally, your friend is standing perfectly straight up and down in the data. This makes it much easier for the computer to compare this swing to the next swing.\n\n\nCode\ndef align_to_body_frame(keypoints, left_shoulder, right_shoulder, anchor_point=None):\n    \"\"\"Rotate so shoulders are horizontal. Creates rotation + translation invariance.\n    \n    Returns keypoints in body-centric frame where:\n    - X-axis: along shoulder line\n    - Y-axis: perpendicular to shoulders\n    \"\"\"\n    if anchor_point is not None:\n        keypoints = make_relative_to_anchor(keypoints, anchor_point)\n        left_shoulder = left_shoulder - anchor_point\n        right_shoulder = right_shoulder - anchor_point\n    \n    shoulder_vec = left_shoulder - right_shoulder\n    angle = np.arctan2(shoulder_vec[..., 1], shoulder_vec[..., 0])\n    \n    cos_a = np.cos(-angle)\n    sin_a = np.sin(-angle)\n    \n    if keypoints.ndim == 2:\n        rotation_matrix = np.array([[cos_a, -sin_a], [sin_a, cos_a]])\n        return keypoints @ rotation_matrix.T\n    else:\n        rotation_matrices = np.array([[cos_a, -sin_a], [sin_a, cos_a]])\n        if rotation_matrices.ndim == 3:\n            rotation_matrices = np.transpose(rotation_matrices, (2, 0, 1))\n        return np.einsum('...ij,...jk-&gt;...ik', keypoints, rotation_matrices)\n\n\n\n\nOk so we have some distance and angle functionality and we also have a way to normalize our keypoints so lets add the potential for some additional geometric relationships\n\n[1] Vector level features between two points with a unit vector\n\ntells you where second point is relative to the first  ** Independent of distance\n\n\n\nCode\ndef get_unit_vector(first_kps, second_kps):\n    \"\"\"\n    Calculates unit vector from A to B.\n    Shape: Inputs (N, 2) -&gt; Output (N, 2)\n    \"\"\"\n    vec = second_kps[...,:2] - first_kps[...,:2]\n    \n    # Manual norm is faster than np.linalg.norm\n    norm = np.sqrt(vec[..., 0]**2 + vec[..., 1]**2)\n    \n    # Avoid division by zero safely\n    norm = np.where(norm == 0, 1, norm)\n    \n    # Reshape norm to (N, 1) to allow broadcasting\n    return vec / norm[..., None]\n\nprint(f'\"get_unit_vector()\" function is useful becuase models often like \\\nseparate  unit vectors in the x and y dimension rather than a single \\\nvalue')\n#get_unit_vector(kp_0.l_sh, kp_0.l_el).shape\n\n\n\"get_unit_vector()\" function is useful becuase models often like separate  unit vectors in the x and y dimension rather than a single value\n\n\n\n\n[2] Angle between segments â€“&gt; use joint angles ABC to find angle @ B\n\nelbow angle (shoulder, elbow, wrist)\nwrist cock (forearm - club shaft angle)\nspine angle (hip - shoulder - head)\n\n\n\nCode\ndef get_angle_fast(A, B, C):\n    \"\"\"\n    Vectorized function to calculate angle at point B given A, B, C.\n    Inputs A, B, C can be shape (2,) or (N, 2).\n    Returns angle in degrees (0-180).\n    \"\"\"\n    # Create vectors BA and BC\n    ba = A - B\n    bc = C - B\n\n    # Calculate angle using arctan2 (returns radians between -pi and pi)\n    # arctan2(y, x) handles the quadrants correctly\n    ang_ba = np.arctan2(ba[..., 1], ba[..., 0])\n    ang_bc = np.arctan2(bc[..., 1], bc[..., 0])\n\n    # Calculate relative angle and convert to degrees\n    angle = np.abs(np.degrees(ang_ba - ang_bc))\n    \n    # Normalize to 0-180 (inner angle)\n    # E.g., if angle is 270, inner angle is 90.\n    angle = np.where(angle &gt; 180, 360 - angle, angle)\n    \n    return angle\n\n#get_angle_fast(kp_0.l_sh, kp_0.l_el, kp_0.l_wr).shape\n\n\n\n\nCode\ndef elbow_angle(shoulder, elbow, wrist):\n    '''elbow angle (shoulder, elbow, wrist) '''\n    return get_angle_fast(shoulder, elbow, wrist)\n\n# def wrist_cock_angle(elbow, wrist, club_end):\n#     '''wrist cock (forearm - club shaft angle)'''\n#     return get_angle_fast(elbow, wrist, club_end)\n\ndef spine_angle(hip, shoulder, head):\n    '''spine angle (hip - shoulder - head)'''\n    return get_angle_fast(hip, shoulder, head)\n\n\n\n\n[3] Pose relative / frame-relative geormetry\n\nInstead of absolute coordianates, make everything relative to some anchor \n\nsubtract pelvis/hip center from all key points \nOPTIONALLY: rotate coordinates so shoulders define a horizontal â€œbody x-axisâ€   * Gives us features that are:  \ntranslation-invariant (location in frame irrelevant)\ncloser to â€œtrueâ€ body pose, especially if the camera jitters \n\n\n\n\nCode\ndef normalize_keypoints(kps, \n                        hip_idxs=(11, 12), \n                        shoulder_idxs=(5, 6), \n                        align_shoulders=False):\n    \"\"\"\n    Normalizes pose keypoints to be translation and (optionally) rotation invariant.\n    \n    Args:\n        kps (np.ndarray): Input keypoints of shape (Frames, K, 2) or (Frames, K, 3).\n                          Expects [x, y] or [x, y, confidence].\n        hip_idxs (tuple): Indices for (Left Hip, Right Hip). Default COCO: (11, 12).\n        shoulder_idxs (tuple): Indices for (Left Shoulder, Right Shoulder). Default COCO: (5, 6).\n        align_shoulders (bool): If True, rotates poses so the shoulder line is horizontal.\n        \n    Returns:\n        np.ndarray: Normalized keypoints of the same shape as input.\n    \"\"\"\n    # Copy to avoid modifying original data\n    norm_kps = kps.copy()\n    \n    # 1. CENTERING: Subtract Pelvis/Hip Center\n    # Average of Left and Right Hip (x, y)\n    # Shape: (Frames, 2)\n    hip_centers = (kps[:, hip_idxs[0], :2] + kps[:, hip_idxs[1], :2]) / 2.0\n    \n    # Broadcast subtraction across all keypoints (N, K, 2) - (N, 1, 2)\n    norm_kps[:, :, :2] -= hip_centers[:, None, :]\n\n    if not align_shoulders:\n        return norm_kps\n\n    # 2. ROTATION: Align Shoulders to Horizontal Axis\n    # Vector from Left Shoulder to Right Shoulder\n    # We use the *centered* coordinates to compute this, though vectors are translation-invariant anyway.\n    left_s = norm_kps[:, shoulder_idxs[0], :2]\n    right_s = norm_kps[:, shoulder_idxs[1], :2]\n    \n    shoulder_vecs = right_s - left_s  # Shape: (Frames, 2)\n    \n    # Calculate angle of shoulder vector relative to global X-axis\n    # theta is the angle we need to rotate *by* to get back to 0 (horizontal)\n    thetas = np.arctan2(shoulder_vecs[:, 1], shoulder_vecs[:, 0])\n    \n    # We want to rotate by -theta to flatten the line.\n    # Rotation matrix for counter-clockwise rotation by alpha:\n    # [[cos(alpha), -sin(alpha)],\n    #  [sin(alpha),  cos(alpha)]]\n    # Here alpha = -theta.\n    # cos(-t) = cos(t), sin(-t) = -sin(t)\n    c, s = np.cos(thetas), np.sin(thetas)\n    \n    # Construct rotation matrices: (Frames, 2, 2)\n    # R = [[c, s], [-s, c]] represents rotation by -theta\n    R = np.stack([\n        np.stack([c, s], axis=-1),\n        np.stack([-s, c], axis=-1)\n    ], axis=-2)\n    \n    # Apply rotation to all keypoints: x_new = R @ x_old\n    # Einsum explanation:\n    # n: frames, k: keypoints, i: old coords (x,y), j: new coords (x,y)\n    # We multiply the rotation matrix (n, j, i) by the keypoint vector (n, k, i)\n    # Transpose R to match standard multiplication or just map indices correctly.\n    # Correct mapping for \"matrix R applied to vector v\": v_new = R @ v\n    # kps shape is (N, K, 2). We want (N, K, 2).\n    # R shape is (N, 2, 2).\n    norm_kps[:, :, :2] = np.einsum('nij,nkj-&gt;nki', R, norm_kps[:, :, :2])\n    \n    return norm_kps\n\n\n\n\n[4] Signed area / â€œrotationâ€ type features (points ABC)\nSigned area + cross product tells us: - How â€œcurvedâ€ or rotated the triplet is - On which side one point lies relative to a line â€“&gt; ** Will help when detecting: ** - open vs closed shoulders/hips - left vs right tilt etc\n\n\nCode\ndef get_signed_area(p1, p2, p3):\n    \"\"\"\n    Calculates the signed area of the triangle formed by triplets (p1, p2, p3).\n    This serves as a proxy for 'rotation' or curvature.\n    \n    Mathematical Property:\n        - Positive (+): p3 is to the LEFT of the line p1-&gt;p2 (Counter-Clockwise)\n        - Negative (-): p3 is to the RIGHT of the line p1-&gt;p2 (Clockwise)\n        - Zero (0): Points are collinear\n    \n    Args:\n        p1, p2, p3 (np.ndarray): Arrays of shape (N, 2) representing (x, y) coordinates.\n                                 Can also handle shape (2,) for single points.\n\n    Returns:\n        np.ndarray: Signed area values.\n    \"\"\"\n    # Ensure inputs are numpy arrays\n    p1, p2, p3 = map(np.array, (p1, p2, p3))\n\n    # Vector A: p1 -&gt; p2\n    vec_a = p2 - p1\n    \n    # Vector B: p1 -&gt; p3\n    vec_b = p3 - p1\n    \n    # 2D Cross Product (Determinant): x1*y2 - x2*y1\n    # This calculates the z-component of the cross product in 3D space\n    cross_prod = vec_a[..., 0] * vec_b[..., 1] - vec_a[..., 1] * vec_b[..., 0]\n    \n    # Signed Area is 0.5 * Cross Product\n    return 0.5 * cross_prod\n\n\nELI5 from gemini: Imagine you are holding a clock.  The â€œsigned areaâ€ (or cross product) tells you which way the clock hands are moving and how big the clock is.  We have three points: A, B, and C.  A is the center of the clock.  B is the number 12.  C is where the hour hand is pointing.  The math checks where C is, compared to the line from A to B.\n\nThe â€œWhich Wayâ€ (Sign)\n\n\nPositive (+): The hand moved backwards (Counter-Clockwise). Point C is to the Left.\nNegative (-): The hand moved forwards (Clockwise). Point C is to the Right.\nZero (0): The hand is pointing straight at 12 (or 6). All three points are in a straight line.\n\n\nThe â€œHow Bigâ€ (Number)\n\n\nSmall Number: The hand is very close to the 12. Itâ€™s barely a triangle; itâ€™s almost a straight line.\nBig Number: The hand is far away (like at 3 oâ€™clock or 9 oâ€™clock). The triangle is big and â€œopen.â€\n\nâ€“&gt; Why is this useful for bodies?  Imagine A and B are your shoulders (making a line).  If C (your hip) is directly underneath them, the number is Zero. You are standing straight.  If you twist your hips forward, the number becomes Positive.\nIf you twist your hips backward, the number becomes Negative.\nIt gives you a single number that tells you how much you twisted and which direction you twisted"
  },
  {
    "objectID": "eagleswing/data_class_testing.html",
    "href": "eagleswing/data_class_testing.html",
    "title": "eagle-swing",
    "section": "",
    "text": "from fastai.vision.all import *\n\n\nfrom eagle_swing.data_class import *\nfrom eagle_swing.normalization import *\n\n\nkp0 = KpExtractor(file_name=files[0],\n                  threshold_value=0.4,\n                  swing_score=2,\n                  get_swing_score=True,\n                  get_swing_idx=True)\nkp0.str_path\n\n'../../data/full_videos/ymirza/sep14/IMG_1093/keypoints/IMG_1093_swing_6_score_None.pkl'\n\n\n\nkp0.swing_score, kp0.swing_idx, kp0.kps.shape\n\n('None', '6', (180, 17, 3))\n\n\n\npost_proc = [interpolate_and_filter_pandas,\n             #normalize_by_torso_diagonal, #not needed now\n             normalize_by_average_torso, # more robust\n             ]\n\n\nkp1 = KpExtractor(file_name=files[0],\n                  threshold_value=0.4,\n                  swing_score=2,\n                  get_swing_score=True,\n                  get_swing_idx=True,\n                  post_processors=post_proc)\n\n\n(kp0.kps[...,:2] == kp1.kps[...,:2]).sum()\n\n0\n\n\n\n# post_processors = [\n#     interpolate_and_filter_pandas, # 1. Fix bad data\n#     align_to_body_frame_static,    # 2. Center at (0,0) and fix camera tilt\n#     normalize_by_average_torso     # 3. Scale to unit size\n# ]"
  },
  {
    "objectID": "posts/analyze/analysis.html",
    "href": "posts/analyze/analysis.html",
    "title": "Kinematic Analysis",
    "section": "",
    "text": "We have 47 total swings from sep14\n\n\n\n\nCode\ndef get_kps(folder):\n    all_files = get_files(folder, extensions='.pkl')\n    clip_files = [file for file in all_files if file.name[:3] == 'IMG']\n    return clip_files\n\n\ndef flatten_stacked_list(nonflat_list):\n    flattened_list = list(chain.from_iterable(nonflat_list))\n    return flattened_list\n\n\ndef get_all_swings_df(flat_kp_path_list):\n    path_list_series =  pd.Series(flat_kp_path_list)\n    kp_fname = path_list_series.map(lambda x: str(x).split('/')[-1])\n    video_name = kp_fname.map(lambda x: '_'.join(str(x).split('_')[:2]))\n    swing_idx = kp_fname.map(lambda x: str(x).split('_')[3])\n    df = pd.DataFrame([video_name, swing_idx, \n                       kp_fname, path_list_series],\n                      index=['video_name','swing_idx', \n                             'kp_fname', 'kp_fpath']\n                      ).T\n    return df\n\n\n\n\nCode\nall_swings_df = get_all_swings_df(flat_kp_file_list)\nall_swings_df.head(3)\n\n\n\n\n\n\n\n\n\nvideo_name\nswing_idx\nkp_fname\nkp_fpath\n\n\n\n\n0\nIMG_1093\n6\nIMG_1093_swing_6_score_None.pkl\n../../../data/full_videos/ymirza/sep14/IMG_1093/keypoints/IMG_1093_swing_6_score_None.pkl\n\n\n1\nIMG_1093\n5\nIMG_1093_swing_5_score_None.pkl\n../../../data/full_videos/ymirza/sep14/IMG_1093/keypoints/IMG_1093_swing_5_score_None.pkl\n\n\n2\nIMG_1093\n4\nIMG_1093_swing_4_score_None.pkl\n../../../data/full_videos/ymirza/sep14/IMG_1093/keypoints/IMG_1093_swing_4_score_None.pkl\n\n\n\n\n\n\n\n\n\nCode\n### 99 â€”&gt; prctice swing w/o score\nsep14_scores = {\n    \"IMG_1086\" : [2, 1, 1, 5, 5], #5\n    \"IMG_1087\" : [4, 5, 2, 1, 2],# 5\n    \"IMG_1088\" : [1, 1, 3, 3, 2],# 5\n    \"IMG_1089\" : [4, 3, 3, 4, 3, 4, 3], #7\n    \"IMG_1090\" : [4, 1, 4, 1, 1, 1], #6\n    \"IMG_1091\" : [2, 2, 5, 2, 4, 1], \n                #6 - 7 w/practice --&gt; start 30 seconds in\n    \"IMG_1092\" : [4, 1, 4, 1, 1, 1,], # 6\n    \"IMG_1093\" : [1, 3, 1, 2, 1, 99, 2],\n    # 6 - 7 w/practice --&gt; just drop second to last clip\n    }\n\n\n\nThere are two instances of practice swings without hitting the ball and without a score, they are marked below,\n\nIMG_1091 there is a practice swing at start of video\n- Easily taken care of by starting the autodetect function 30 seconds into the video -- no longer accounted for in the 47 total\n\n\nIMG_1093 there is a practice swing on the second to last swing\n- this doesn't interfere with autodetect finding last swting, so we can just ignore that second to last swing in our anaylsis (swing_idx 5)\n- therefore only 46 swings\n\n\n\nThis could maybe be easily tackled by also checking for a score hand (right hand up left hand below shoulder and then checking backwards towards a swing, if thereâ€™s no swing in between that next hand and this swing, you know this is not a practice swing)\n\n\nCode\nlist(range(1,6,1))\n\n\n[1, 2, 3, 4]\n\n\n\n\nMost of the swings on this day were scored 1\nscores\n1     17\n2      9\n4      9\n3      7\n5      4\n99     1\nName: count, dtype: int64\n\n\n\n\nCode\ntop_idxs = [get_frame_plot(x[30:])[0] + 30 for x in test_kps]\nlowest_frame_count = np.array([kp.shape[0] for kp in test_kps]).min()\nhighest_peak_frame = np.array(top_idxs).max()\ndiff = lowest_frame_count - highest_peak_frame\nstart_idx = highest_peak_frame - diff\nend_idx = highest_peak_frame + diff\nprint(f'The frame index where the straight arm is found \\\nin the backswing are: {top_idxs}')\nprint(f'The highest peak frame where this is found is: {highest_peak_frame}')\nprint(f'The lowest frame count in any of our clips is: {lowest_frame_count}')\nprint(f'We have a difference of {diff} frames between where this happens')\nprint(f'The indexes we will use to index all these videos are:\\n \\\nstart:{start_idx} and end:{end_idx}')\n\n\nThe frame index where the straight arm is found in the backswing are: [131, 138, 136, 133, 136, 141]\nThe highest peak frame where this is found is: 141\nThe lowest frame count in any of our clips is: 180\nWe have a difference of 39 frames between where this happens\nThe indexes we will use to index all these videos are:\n start:102 and end:180\n\n\n\n\nCode\n# code-fold:True\nfig, axes = plot_upper_body_comparison(\n    kps_list=[x[...,:2][10:45] for x in test_kps],\n    scores_list=[x[...,2][10:45] for x in test_kps],\n    labels=plot_lbls,\n    params=UpperPlotParams(handedness=\"right\", smooth_win=5, fps=60.0),\n    title=\"Swing Comparison - Upper Body\"\n)\n\n\n\n\n\n\n\n\n\n\n\nCode\nfig, axes = plot_lower_body_detailed(\n    kps_list=[x[...,:2][10:45] for x in test_kps],\n    scores_list=[x[...,2][10:45] for x in test_kps],\n    labels=plot_lbls,\n    params=PlotParams(handedness=\"right\", smooth_win=5, fps=60.0),\n    title=\"Swing Comparison - Lower Body\"\n)"
  },
  {
    "objectID": "posts/new_golfer/index.html",
    "href": "posts/new_golfer/index.html",
    "title": "Auto Clipper Redux",
    "section": "",
    "text": "Code\nplt.style.use('dark_background');\n\n\n\n\nCode\n# video_names = [file.name.split('.')[0] for file in pkl_files]\n# fname2path = dict(zip(video_names, pkl_files))\n# print(video_names)\n\n\n\n\nCode\n# stef_scores = {}\n# stef_scores[video_names[0]] = [3, 5, 4, 3, 4]\n# stef_scores[video_names[1]] = [1, 3, 4, 5, 3]\n# stef_scores[video_names[2]] = [4, 4, 2, 4, 1, 3]\n# stef_scores[video_names[3]] = [4, 5, 3, 5]\n# stef_scores[video_names[4]] = [5, 2, 5, 3, 4, 4]\n# stef_scores[video_names[5]] = [5, 5, 3, 4, 1]\n# stef_scores[video_names[6]] = [1, 4, 3, 5]\n\n\nHello, Sierra. I am in unit 723 and trying to get clarification on how I move my end of lease date back â€“ can you provide this information?\nI was told that I could move my end date for my month month to month term once the new team arrived â€“ but I have not been able to connect with a human for weeks. Last week I was told that I could do it within the app but I do not see that option.\nAdditionally, when I look at my cost for this month, I see I was charged $6000+ for my $2600 1-bedroom apartment, it looks like I was charged $2600 on 11/28/2025 and a month to month charge of $20 and then again I got charged $2600 on 12/1/2025 along with a $300 month to month charge. Can you let me know when this will be fixed in the system? I was told that alot of residents are facing issues with the billing in the portal and that we should wait a few days for it to be corrected, I just dont wanâ€™t to get hit with a late fee so I have been trying to find out all week how to handle this. Thanks for your help!\n\n\nCode\n# import itertools\n\n# clip_holder = []\n# scores_series = pd.Series(stef_scores.values()).map(lambda x: [f'swing_{idx}_score_{score}' for idx, score in enumerate(x)])\n# init_df = pd.DataFrame([video_names, scores_series], index=['video_name','swing_info']).T\n# for _, row in init_df.iterrows():\n#     vname = row['video_name']\n#     for item in row['swing_info']:\n#         clip_holder.append(f'{vname}_{item}')\n\n\n# final_df = pd.DataFrame(clip_holder, columns=['clip_name'])\n# final_df['video_name'] = final_df.clip_name.map(lambda x: '_'.join(x.split('_')[:2]))\n# final_df['swing_idx'] = final_df.clip_name.map(lambda x: x.split('_')[3])\n# final_df['score'] = final_df.clip_name.map(lambda x: x.split('_')[-1])\n# highest_wrists_list = [get_highest_wrist_only(file) for file in pkl_files]\n# flat_wrist_list = list(itertools.chain.from_iterable(highest_wrists_list))\n# final_df['pkl_path'] = final_df.video_name.map(lambda x: fname2path[x])\n# final_df['first_highest_wrist_idx'] = flat_wrist_list\n# final_df.head(2)\n###\n### df.to_csv('stef_lbls.csv', index=False) ##\n###\n\n\n\n\nCode\ndf = pd.read_csv('stef_lbls.csv').reset_index(drop=True)\ndf5 = df[df.score == 5].reset_index(drop=True)\ndf1 = df[df.score == 1].reset_index(drop=True)\ndf_low_high = pd.concat([df1, df5], ignore_index=True)\ndf_low_high.head(2)\n\n\n\n\n\n\n\n\n\nclip_name\nvideo_name\nswing_idx\nscore\npkl_path\nfirst_highest_wrist_idx\n\n\n\n\n0\nIMG_1170_swing_0_score_1\nIMG_1170\n0\n1\n../../../data/full_videos/saugusta/IMG_1170/keypoints/IMG_1170.pkl\n1525\n\n\n1\nIMG_1173_swing_4_score_1\nIMG_1173\n4\n1\n../../../data/full_videos/saugusta/IMG_1173/keypoints/IMG_1173.pkl\n7212\n\n\n\n\n\n\n\n\n\nCode\nbefore_increment = 45\nafter_increment = 45\ndf_low_high['start_idx'] = df_low_high.first_highest_wrist_idx - before_increment\ndf_low_high['end_idx'] = df_low_high.first_highest_wrist_idx + after_increment\n\n\n\n\nCode\nangle_metrics = [\n    \"right_arm_angle\", \n    #\"left_arm_angle\",\n    \"shoulder_angle\",\n    \"hip_angle\",\n    \"right_leg_angle\",\n    \"left_leg_angle\",\n]\nmisc_metrics = [\n    \"x_factor\",\n    \"x_torque\",\n    \"right_side_bend\",\n    \"left_side_bend\",\n    ]\n\nderive_metrics = [\n    \"x_factor\", \n    \"right_arm_angle\", \n    \"vertical_extension\",\n    \"shoulder_angle\" # Rate of tilt\n    ]\nvel_metrics = [f'{x}_vel' for x in derive_metrics]\nacc_metrics = [f'{x}_acc' for x in derive_metrics]\n\n\n\n\nCode\nfind_crossing_frame\n\n\n\n\nCode\n# Assuming you have a list of SwingExtractor instances\nswing_objects = [SwingExtractor(row, processors=[get_interpolator(window_length=5),\n                                                ]) for idx, row in df_low_high.iterrows()]\nclip_names = [x.clip_name for x in swing_objects]\nhighlight_idx = [x.row.first_highest_wrist_idx - x.row.start_idx for x in swing_objects]\n\n\n\n\nCode\nmetrics_to_plot = angle_metrics\nplot_swing_metrics(swing_objects[1:7], \n                   metrics_to_plot, \n                   labels=clip_names[1:7], \n                   highlight_frame=45)\n\n\n\n\n\n\n\n\n\n\n\nCode\nmetrics_to_plot = misc_metrics\nplot_swing_metrics(swing_objects[1:7], \n                   metrics_to_plot, \n                   labels=clip_names[1:7], \n                   highlight_frame=45)\n\n\n\n\n\n\n\n\n\n\n\nCode\nmetrics_to_plot = vel_metrics\nplot_swing_metrics(swing_objects[1:7], \n                   metrics_to_plot, \n                   labels=clip_names[1:7], \n                   highlight_frame=45)\n\n\n\n\n\n\n\n\n\n\n\nCode\nmetrics_to_plot = acc_metrics\nplot_swing_metrics(swing_objects[1:7], \n                   metrics_to_plot, \n                   labels=clip_names[1:7], \n                   highlight_frame=45)\n\n\n\n\n\n\n\n\n\n\nSide Bend (Lateral Flexion) This is the exact metric for â€œdistance from hip to shoulder.â€ What it is: The contraction of the obliques on one side and lengthening on the other. The Metric: Calculate the Euclidean distance between the shoulder (acromion) and the hip (iliac crest) on both the lead and trail sides. Kinematic Pattern: Address: Distances are roughly equal. Top of Backswing: The lead side (left for right-handers) should contract slightly (dipping the shoulder), decreasing the distance.â€‹ Impact: The trail side (right side) contracts significantly (â€œside crunchâ€), while the lead side extends fully. Why it matters: Failure to shorten the trail side distance usually indicates â€œearly extensionâ€ (standing up too straight) or a slide, causing a loss of posture.\nVertical Extension (The â€œJumpâ€) This measures the vertical separation of the body from the ground. What it is: The golfer pushing off the ground to generate vertical ground reaction forces (GRF). The Metric: Track the vertical (y-axis) distance of the Mid-Hip or Mid-Shoulder point relative to the ankles. Kinematic Pattern: The distance should drop (compress) during the transition (squatting motion) and then rapidly increase (separate) just before impact.â€‹ Why it matters: This â€œsquat-then-jumpâ€ pattern is highly correlated with clubhead speed. If you only track rotation (angles), you miss this power source entirely.\nSwing Radius (Width) What it is: How â€œwideâ€ the swing is. The Metric: The distance between the hands/wrists and the chest center (sternum). Kinematic Pattern: You want this distance to be maximized during the backswing (width) and maintained or managed during the downswing. Collapsing this distance usually means the arms are bending too much or the body is outracing the arms\n\n\n\nCode\n# idxZ = row.first_highest_wrist_idx\n# #mp4_path = \n# #get_frames(row.pkl\n# video_path = f'{row.pkl_path[:-3]}mp4'\n# frames = get_frames(video_path, start_idx=idxZ-90, num_frames=180)\n\n\n\n\nCode\nrows = []\nfor idx, row in df_low_high.iterrows():\n    rows.append(row)\n\n\n\n\nCode\nkps_holder = [KpExtractor(row.pkl_path).kps[row.start_idx: row.end_idx+30] for row in rows] #if row.video_name == 'IMG_1167']\n#kps_holder.shape\n\n\n\n\nCode\n#rows[3]\n\n\n\n\nCode\nframes, fps = get_frames(f\"{rows[3].pkl_path[:-3]}mp4\", num_frames=None)\nframes.shape\n\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5824/5824 [00:10&lt;00:00, 572.22it/s]\n\n\n(5824, 256, 256, 3)\n\n\n\n\nCode\n%matplotlib widget\nanimate_keypoints_interactive(kps_holder[:], vertical=False,\n                              dark_mode=True, )\n                             #labels=lbls)\n#display(HTML(animator.to_jshtml()))\n\n\n\n\n\nTempo: - Address â€“&gt; top of backswing - top of backswing â€“&gt; impact (????) â€“ are you decellerating\n-\n\n\nCode\nend_downswing = [find_last_frame_wrist_is_right(kps) for kps in kps_holder]\ntop_of_swing_idx = [find_last_frame_before_downswing(kps) for kps in kps_holder]\n\n\n\n\nCode\nscores = [row.score for row in rows]\nscores\n\n\n[1, 1, 1, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5]\n\n\n\n\nCode\ndownswing_timing = np.array(end_downswing) - np.array(top_of_swing_idx)\ndownswing_timing\n\n\narray([28, 29, 28, 28, 29, 30, 29, 27, 31, 29, 28, 31, 30])\n\n\n\n\nCode\nspeed_df = pd.DataFrame(zip(scores, downswing_timing), columns=['score','speed'])\nspeed_df.head(5)\n\n\n\n\n\n\n\n\n\nscore\nspeed\n\n\n\n\n0\n1\n28\n\n\n1\n1\n29\n\n\n2\n1\n28\n\n\n3\n1\n28\n\n\n4\n5\n29\n\n\n\n\n\n\n\n\n\nCode\nimport seaborn as sns\nplt.figure(figsize=(8, 6))\nsns.boxplot(data=speed_df, x='score', y='speed')\n\n# 3. Add labels and title for context (Optional)\nplt.title('Speed Distribution by Score')\nplt.xlabel('Score')\nplt.ylabel('Number of Frames')\n\n# 4. Display the plot\nplt.show()\n\n\n\n\n\n\n\nCode\n[find_last_frame_wrist_is_right(kps) for kps in kps_holder]\n\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[16], line 1\n----&gt; 1 [find_last_frame_wrist_is_right(kps) for kps in kps_holder]\n\nCell In[16], line 1, in &lt;listcomp&gt;(.0)\n----&gt; 1 [find_last_frame_wrist_is_right(kps) for kps in kps_holder]\n\nNameError: name 'find_last_frame_wrist_is_right' is not defined\n\n\n\n\n\nCode\n[find_last_frame_before_downswing(kps) for kps in kps_holder]\n\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[17], line 1\n----&gt; 1 [find_last_frame_before_downswing(kps) for kps in kps_holder]\n\nCell In[17], line 1, in &lt;listcomp&gt;(.0)\n----&gt; 1 [find_last_frame_before_downswing(kps) for kps in kps_holder]\n\nNameError: name 'find_last_frame_before_downswing' is not defined\n\n\n\n\n\nCode\n#[find_last_frame_right_hand_crosses_left_body(kps) for kps in kps_holder]\n\n\n\n\nCode\ndef get_signed_distance(p_hand, p_shoulder, p_hip):\n    \"\"\"\n    Returns &gt; 0 if hand is to the RIGHT of the shoulder-hip line.\n    Returns &lt; 0 if hand is to the LEFT of the shoulder-hip line.\n    Uses a vertical boundary when the hand is above the shoulder.\n    \"\"\"\n    x_h, y_h = p_hand[:2]\n    x_s, y_s = p_shoulder[:2]\n    x_hip, y_hip = p_hip[:2]\n    \n    # 1. Vertical Projection Fix:\n    # If hand is above the shoulder (y_h &lt; y_s in image coords), \n    # use the shoulder's X as the vertical boundary.\n    if y_h &lt; y_s:\n        return x_h - x_s\n\n    # 2. Standard Line Projection (Below Shoulder):\n    # Avoid division by zero\n    if abs(y_hip - y_s) &lt; 1e-6: \n        return x_h - x_s \n        \n    # Calculate x of the body line at the hand's y-coordinate\n    slope_inv = (x_hip - x_s) / (y_hip - y_s)\n    x_line_at_hand_y = x_s + (y_h - y_s) * slope_inv\n    \n    return x_h - x_line_at_hand_y\n\n\ndef find_crossing_frames(keypoints):\n    \"\"\"\n    Identifies frames where hands cross body lines in a specific direction (Right -&gt; Left).\n    \n    Args:\n        keypoints: Numpy array of shape (num_frames, num_kps, 2)\n    \n    Returns:\n        dict: Lists of frame indices where the crossing event completes.\n    \"\"\"\n    # COCO Indices\n    L_SHOULDER, L_HIP = 5, 11\n    R_SHOULDER, R_HIP = 6, 12\n    L_HAND, R_HAND = 9, 10  # Using Wrists as proxies for Hands\n\n    events = {\n        'right_hand_crosses_left_body': [], # Right Hand crossing Left Body Line\n        'left_hand_crosses_right_body': []  # Left Hand crossing Right Body Line\n    } \n    holder = []\n    # Iterate through frames\n    for t in range(len(keypoints) - 1):\n        kp_curr = keypoints[t]\n        kp_next = keypoints[t+1]\n\n        # --- Check 1: Right Hand crossing Left Body Line (Right -&gt; Left) ---\n        dist_curr = get_signed_distance(kp_curr[R_HAND], kp_curr[L_SHOULDER], kp_curr[L_HIP])\n        dist_next = get_signed_distance(kp_next[R_HAND], kp_next[L_SHOULDER], kp_next[L_HIP])\n        \n        # Check for transition from Positive (Right) to Negative (Left)\n        if dist_curr &gt; 0 and dist_next &lt;= 0:\n            events['right_hand_crosses_left_body'].append(t + 1)\n            holder.append(t)\n\n        # --- Check 2: Left Hand crossing Right Body Line (Right -&gt; Left) ---\n        dist_curr_l = get_signed_distance(kp_curr[L_HAND], kp_curr[R_SHOULDER], kp_curr[R_HIP])\n        dist_next_l = get_signed_distance(kp_next[L_HAND], kp_next[R_SHOULDER], kp_next[R_HIP])\n        \n        # Check for transition from Positive (Right) to Negative (Left)\n        if dist_curr_l &gt; 0 and dist_next_l &lt;= 0:\n            events['left_hand_crosses_right_body'].append(t + 1)\n\n    events['time_between_crossing'] = holder[1] - holder[0]\n\n    return events"
  },
  {
    "objectID": "posts/find_landmarks/index.html",
    "href": "posts/find_landmarks/index.html",
    "title": "Find Swing Landmarks",
    "section": "",
    "text": "Weâ€™re going to try isolate three specific landmarks in the swing and use this as the basis to clip the swings and compare them appropriately.  1. Start of backswing  2. Top of backswing  3. Contact Point  Since weâ€™re using 2d keypoints as proxies to determine this information, we will have to settle with landing in a general region around this landmark, if we can keep it within 2-3 frames (~5% of the number of frames in a second) this should be good enough for comparison purposes\nCode\ndef get_top_idxs(swing_list):\n    x_lowest = [get_x_lowest(swing_list[x].r_wrist) for x in range(len(swing_list))]\n    y_lowest = [get_y_lowest(swing_list[x].r_wrist) for x in range(len(swing_list))]\n    xy_lowest = [get_xy_sum_lowest(swing_list[x].r_wrist) for x in range(len(swing_list))]\n    complex_backswing_top_frames = [get_top_idx(swing_list[x].r_wrist, \n                 y_axis_only=True,\n                thresh_value=0.001) for x in range(len(swing_list))]\n    all_idxs = [x_lowest, y_lowest, xy_lowest,]# complex_backswing_top_frames]\n    avg_backswing_idxs = list(np.array([np.array(x) for x in all_idxs]).mean(axis=0).round().astype(int))\n    return avg_backswing_idxs\nCode\n# sep14_df, sep14_swings, sep14_clip_names = get_cleaned_df(day_path='sep14', \n#                                                           before_increment=10,\n#                                                           after_increment=20,\n#                                                           return_random_df=False)\n# avg_top_backswing_idxs = get_top_idxs(sep14_swings)\n# sep14_df['top_backswing_idx'] = sep14_df.start_idx + avg_top_backswing_idxs\n#sep14_df.to_csv('sep14_df.csv', index=False)\n# sep14_df.head(1)\nCode\noct25_df, oct25_swings, oct25_clip_names = get_cleaned_df(day_path='oct25', \n                                                          before_increment=10,\n                                                          after_increment=20,\n                                                          return_random_df=False)\navg_top_backswing_idxs = get_top_idxs(oct25_swings)\noct25_df['top_backswing_idx'] = oct25_df.start_idx + avg_top_backswing_idxs\noct25_df.to_csv('oct25_df.csv', index=False)\noct25_df.head(1)\n\n\n\n\n\n\n\n\n\nvideo_name\nswing_index\nscore\npkl_path\nclip_name\nfirst_higher_wrists_backswing_frame\nswing_day\nstart_idx\nend_idx\ntop_backswing_idx\n\n\n\n\n0\nIMG_1185\n0\n1\n../../../data/full_videos/ymirza/oct25/IMG_1185/keypoints/IMG_1185.pkl\nIMG_1185_swing_0_score_1\n1359\noct25\n1349\n1379\n1370\nCode\nnov16_df, nov16_swings, nov16_clip_names = get_cleaned_df(day_path='nov16', \n                                                          before_increment=10,\n                                                          after_increment=20,\n                                                          return_random_df=False)\navg_top_backswing_idxs = get_top_idxs(nov16_swings)\nnov16_df['top_backswing_idx'] = nov16_df.start_idx + avg_top_backswing_idxs\nnov16_df.to_csv('nov16_df.csv', index=False)\nnov16_df.head(1)\n\n\n\n\n\n\n\n\n\nvideo_name\nswing_index\nscore\npkl_path\nclip_name\nfirst_higher_wrists_backswing_frame\nswing_day\nstart_idx\nend_idx\ntop_backswing_idx\n\n\n\n\n0\nIMG_1274\n0\n4\n../../../data/full_videos/ymirza/nov16/IMG_1274/keypoints/IMG_1274.pkl\nIMG_1274_swing_0_score_4\n1771\nnov16\n1761\n1791\n1784\nCode\naug9_df, aug9_swings, aug9_clip_names = get_cleaned_df(day_path='aug9', \n                                                          before_increment=10,\n                                                          after_increment=20,\n                                                          return_random_df=False)\navg_top_backswing_idxs = get_top_idxs(aug9_swings)\naug9_df['top_backswing_idx'] = aug9_df.start_idx + avg_top_backswing_idxs\naug9_df.to_csv('nov16_df.csv', index=False)\naug9_df.head(1)\n\n\n\n\n\n\n\n\n\nclip_name\nvideo_name\nswing_index\nscore\npkl_path\nfirst_higher_wrists_backswing_frame\nswing_day\nstart_idx\nend_idx\ntop_backswing_idx\n\n\n\n\n0\nIMG_1023_swing_0_score_1\nIMG_1023\n0\n1\n../../../data/full_videos/ymirza/aug9/IMG_1023/keypoints/IMG_1023.pkl\n1540\naug9\n1530\n1560\n1550\nCode\ndef get_spec_frames(df, start=90, after=30):\n    df['start_idx'] = df.top_backswing_idx - start\n    df['end_idx'] = df.top_backswing_idx + after\n    random_idxs = np.random.randint(0, len(df), 12)\n    frames_list = get_frames_from_df(df.iloc[random_idxs].reset_index(drop=True))\n    return frames_list\nCode\naug9_df.shape, sep14_df.shape, oct25_df.shape, nov16_df.shape\n\n\n((54, 10), (46, 10), (33, 10), (42, 10))\nCode\ndf_list = [aug9_df, sep14_df, oct25_df, nov16_df]\nsum([x.shape[0] for x in df_list])\n\n\n175\nCode\nframes_list = get_spec_frames(nov16_df, start=75, after=30)\nCode\nview_videos_grid(frames_list[6:])"
  },
  {
    "objectID": "posts/find_landmarks/index.html#lets-find-the-top-of-the-backswing",
    "href": "posts/find_landmarks/index.html#lets-find-the-top-of-the-backswing",
    "title": "Find Swing Landmarks",
    "section": "Lets find the top of the backswing",
    "text": "Lets find the top of the backswing\n\n\nCode\ndef get_cleaned_df(base_path=None,#folder that contains all csvs\n                   day_path=None, #i.e. sep14\n                   before_increment=30,\n                   after_increment=30,\n                   return_low_high_df=False,\n                   return_random_df=True,\n                   return_kps=True):\n    if base_path is None:\n        base_path = '../../../data/full_videos/ymirza'\n    if day_path:\n        full_path = f\"{base_path}/{day_path}\"\n    else: full_path = base_path\n    cleaned_df_paths = [file for file in get_files(full_path, \n                               extensions='.csv') if file.name == 'clean_lbls.csv']    \n    df_holder = [pd.read_csv(df_path) for df_path in cleaned_df_paths]\n    cleaned_df = pd.concat(df_holder).reset_index(drop=True)\n    cleaned_df['swing_day'] = cleaned_df.pkl_path.map(lambda x: x.split('/')[0])\n    cleaned_df['pkl_path'] = cleaned_df.pkl_path.map(lambda x: f'{base_path}/{x}')\n    cleaned_df['start_idx'] = cleaned_df['first_higher_wrists_backswing_frame'] - before_increment\n    cleaned_df['end_idx'] = cleaned_df['first_higher_wrists_backswing_frame'] + after_increment\n    if return_low_high_df:\n        df5 = cleaned_df[cleaned_df.score.map(lambda x: x == 5)]\n        df1 = cleaned_df[cleaned_df.score.map(lambda x: x == 1)]\n        test_df = pd.concat([df5.iloc[:3], df1.iloc[:3]]).reset_index(drop=True)\n    elif return_random_df:\n        rand_idxs = np.random.randint(0, len(cleaned_df), 6)\n        test_df = cleaned_df.iloc[rand_idxs]\n    else:\n        test_df = cleaned_df\n    test_df = test_df.reset_index(drop=True)\n    if return_kps:\n        SwExt_list = [SwingExtractor(row).kps for idx, row in test_df.iterrows()]\n    else:\n        SwExt_list = [SwingExtractor(row) for idx, row in test_df.iterrows()]\n    clip_names = [SwExt_list[x].clip_name for x in range(len(SwExt_list))]\n    return test_df, SwExt_list, clip_names\n\n\n\n\nCode\ndef get_frames_from_df(df, resize_dim=(512,512)):\n    frames_list = []\n    for idx, row in df.iterrows():\n        video_path = f\"{row.pkl_path[:-3]}mp4\"\n        frames, fps = get_frames(video_path,\n                                start_idx=row.start_idx,\n                                 num_frames=row.end_idx - row.start_idx,\n                                 show_progress=False,\n                                 resize_dim=resize_dim\n                                )\n        frames_list.append(frames)\n    return frames_list\n\n\n\n\nCode\ntop_backswing_df, top_backswing_SwExt_list, top_backswing_clip_names = get_cleaned_df(\n    before_increment=10,\n    after_increment=20,\n)\ntop_backswing_frames_list = get_frames_from_df(top_backswing_df)\nprint(set([x.shape for x in top_backswing_frames_list]))\nview_videos_grid(top_backswing_frames_list[:3])\n\n\n{(30, 512, 512, 3)}\n\n\n\n\n\n\n\nCode\ndef get_lowest(np_array): return np.argmin(np_array)\ndef get_highest(np_array): return np.argmax(np_array)\ndef get_x_lowest(np_array): return get_lowest(np_array[:, 0])\ndef get_y_lowest(np_array): return get_lowest(np_array[:, 1])\ndef get_x_highest(np_array): return get_highest(np_array[:, 0])\ndef get_y_highest(np_array): return get_highest(np_array[:, 1])\ndef get_xy_sum_highest(np_array): return get_highest(np_array[:, :2].sum(axis=1))\ndef get_xy_sum_lowest(np_array): return get_lowest(np_array[:, :2].sum(axis=1))\n\nx_lowest = [get_x_lowest(top_backswing_SwExt_list[x].r_wrist) for x in range(len(top_backswing_SwExt_list))]\ny_lowest = [get_y_lowest(top_backswing_SwExt_list[x].r_wrist) for x in range(len(top_backswing_SwExt_list))]\nxy_lowest = [get_xy_sum_lowest(top_backswing_SwExt_list[x].r_wrist) for x in range(len(top_backswing_SwExt_list))]\ncomplex_backswing_top_frames = [get_top_idx(top_backswing_SwExt_list[x].r_wrist, \n             y_axis_only=True,\n            thresh_value=0.001) for x in range(len(top_backswing_SwExt_list))]\nall_idxs = [x_lowest, y_lowest, xy_lowest,]# complex_backswing_top_frames]\navg_backswing_idxs = list(np.array([np.array(x) for x in all_idxs]).mean(axis=0).round().astype(int))\n\n\n\n\nCode\nprint(x_lowest)\nprint(y_lowest)\nprint(xy_lowest)\nprint(complex_backswing_top_frames)\nprint(avg_backswing_idxs)\n\n\n[25, 23, 21, 21, 20, 24]\n[22, 20, 18, 20, 22, 21]\n[22, 20, 20, 20, 22, 22]\n[22, 21, 19, 21, 21, 22]\n[23, 21, 20, 20, 21, 22]\n\n\n\n\nCode\nplot_feature_across_instances(top_backswing_SwExt_list,\n                              feature_name='r_wrist',\n                              highlight_frames_red=avg_backswing_idxs,\n                              highlight_frames_orange=y_lowest,\n                              highlight_frames_magenta=xy_lowest,\n                              highlight_frames_eblue=x_lowest,\n                              #highlight_frames_eblue=complex_backswing_top_frames,\n                             )\n\n\n\n\n\n\n\n\n\n\n\nCode\ntop_backswing_df['top_backswing_idx'] = top_backswing_df.start_idx + np.array(avg_backswing_idxs) - 10\n\n\n\n\nCode\nframes_list = []\nfor idx, row in top_backswing_df.iterrows():\n    video_path = f\"{row.pkl_path[:-3]}mp4\"\n    frames, fps = get_frames(video_path,\n                            start_idx=row.top_backswing_idx - 66,\n                             num_frames=96,\n                             show_progress=False,\n                             resize_dim=(512,512)\n                            )\n    frames_list.append(frames)\n\n\n\n\nCode\nview_videos_grid(frames_list[3:])"
  },
  {
    "objectID": "posts/find_landmarks/index.html#lets-find-the-contact-frame",
    "href": "posts/find_landmarks/index.html#lets-find-the-contact-frame",
    "title": "Find Swing Landmarks",
    "section": "Lets find the contact frame",
    "text": "Lets find the contact frame\n\n\nCode\ncontact_df, contact_SwExt_list, contact_clip_names = get_cleaned_df(\n    before_increment=-20,\n    after_increment=40,\n)\ncontact_frames_list = get_frames_from_df(contact_df)\nprint(set([x.shape for x in contact_frames_list]))\nview_videos_grid(contact_frames_list[:3])\n\n\n{(20, 512, 512, 3)}\n\n\n\n\n\n\n\nCode\nx_highest = [get_x_highest(contact_SwExt_list[x].r_wrist) for x in range(len(contact_SwExt_list))]\ny_highest = [get_y_highest(contact_SwExt_list[x].r_wrist) for x in range(len(contact_SwExt_list))]\nxy_highest = [get_xy_sum_highest(contact_SwExt_list[x].r_wrist) for x in range(len(contact_SwExt_list))]\n#complex_contact_bottom_frames = [get_top_idx(contact_SwExt_list[x].r_wrist, \n#                                 y_axis_only=True,\n#                                 thresh_value=0.001) for x in range(len(contact_SwExt_list))]\ncontact_idxs = [x_highest, y_highest, xy_highest,]# complex_contact_bottom_frames]\navg_contact_idxs = list(np.array([np.array(x) for x in contact_idxs]).mean(axis=0).round().astype(int))\nprint(avg_contact_idxs)\nprint(y_highest)\nprint(xy_highest)\nprint(x_highest)\n\n\n[7, 7, 10, 6, 7, 9]\n[8, 8, 10, 6, 7, 10]\n[7, 7, 10, 6, 7, 9]\n[7, 6, 9, 5, 6, 9]\n\n\n\n\nCode\nplot_feature_across_instances(contact_SwExt_list[:3],\n                              feature_name='r_wrist',\n                              highlight_frames_red=avg_contact_idxs,\n                              highlight_frames_orange=y_highest,\n                              highli ght_frames_magenta=xy_highest,\n                              #highlight_frames_eblue=complex_contact_bottom_frames,\n                              highlight_frames_eblue=x_highest,\n                             )"
  },
  {
    "objectID": "posts/find_landmarks/index.html#now-lets-look-at-just-top-of-backswing-to-contact",
    "href": "posts/find_landmarks/index.html#now-lets-look-at-just-top-of-backswing-to-contact",
    "title": "Find Swing Landmarks",
    "section": "Now lets look at just top of backswing to contact",
    "text": "Now lets look at just top of backswing to contact\n\n\nCode\ncomplex_backswing_top_frames, highlight_frames\n\n\n\n\nCode\n# 20 frames before the first wrist over shoulder\ntop_frame = np.array(backswing_top_idxs) - 20\n#top_frame = np.array(backswing_top_idxs) - 20\n#bottom_frame = np.array(contact_idxs) + 20\nbottom_frame = np.array(highlight_frames) + 20\nbottom_frame - top_frame\n\n\n\n\nCode\ntop_frame, bottom_frame\n\n\n\n\nCode\nframes_list = []\nfor idx, row in test_df.reset_index(drop=True).iterrows():\n    video_path = f\"{row.pkl_path[:-3]}mp4\"\n    frames, fps = get_frames(video_path,\n                            start_idx=row.start_idx + top_frame[idx] - 20 ,\n                             num_frames=bottom_frame[idx] - top_frame[idx] + 3,\n                             show_progress=False,\n                            )\n    frames_list.append(frames)\nview_videos_grid(frames_list)"
  },
  {
    "objectID": "posts/find_landmarks/index.html#lets-find-the-start-of-the-swings-frame",
    "href": "posts/find_landmarks/index.html#lets-find-the-start-of-the-swings-frame",
    "title": "Find Swing Landmarks",
    "section": "Lets find the start of the swings frame",
    "text": "Lets find the start of the swings frame\n\n\nCode\nstart_df, start_SwExt_list, contact_clip_names = get_cleaned_df(\n    before_increment=90,\n    after_increment=0,\n    return_kps=False\n)\nstart_frames_list = get_frames_from_df(start_df)\nprint(set([x.shape for x in start_frames_list]))\nview_videos_grid(start_frames_list)\n\n\n{(90, 512, 512, 3)}\n\n\n\n\n\n\n\nCode\nstart_idxs = [30, 18, 24, 13, 25, 25]\n\n\n\n\nCode\nright_angle_list = [start_SwExt_list[x].right_arm_angle for x in range(len(start_SwExt_list))]\nplot_grid_variable_markers(right_angle_list, start_idxs)\n\n\n\n\n\n\n\n\n\n\n\nCode\ndef plot_grid_variable_markers(data_list, marker_indices):\n    \"\"\"\n    Plots a grid of lines where each plot highlights a specific, unique x-index.\n    \n    Args:\n        data_list (list): List of arrays for y-values.\n        marker_indices (list): List of x-indices, one for each plot. \n                               e.g., [12, 15, 10, ...]\n    \"\"\"\n    n_plots = len(data_list)\n    cols = 3\n    rows = math.ceil(n_plots / cols)\n\n    # Create figure with constrained layout\n    fig, axes = plt.subplots(rows, cols, figsize=(15, 3.5 * rows), constrained_layout=True)\n    \n    # Flatten axes for single-loop iteration\n    if n_plots &gt; 1:\n        axes = axes.flatten()\n    else:\n        axes = [axes]\n\n    for i, ax in enumerate(axes):\n        if i &lt; n_plots:\n            # 1. Get data\n            y_data = data_list[i]\n            x_data = np.arange(len(y_data))\n            \n            # 2. Get the specific marker for THIS plot\n            # (Check bounds to ensure we have a marker for this plot index)\n            if i &lt; len(marker_indices):\n                marker_idx = marker_indices[i]\n            else:\n                marker_idx = None\n\n            # 3. Plot Line\n            ax.plot(x_data, y_data, linewidth=2, label=f'Series {i}')\n\n            # 4. Highlight the variable marker\n            if marker_idx is not None and 0 &lt;= marker_idx &lt; len(y_data):\n                # Vertical line\n                ax.axvline(x=marker_idx, color='red', linestyle='--', alpha=0.6)\n                # Point marker\n                ax.plot(marker_idx, y_data[marker_idx], 'ro', markersize=8)\n                # Optional: Label the frame number\n                ax.text(marker_idx, y_data[marker_idx], f' x={marker_idx}', \n                        verticalalignment='bottom', fontsize=9)\n\n            ax.set_title(f\"Plot {i+1}\")\n            ax.grid(True, alpha=0.3)\n        else:\n            # Hide unused subplots\n            ax.axis('off')\n\n    plt.show()\n\n\n\n\nCode\nplot_feature_trajectories("
  },
  {
    "objectID": "posts/find_score_hand/index.html",
    "href": "posts/find_score_hand/index.html",
    "title": "Auto Detect Score Hand",
    "section": "",
    "text": "Code\nfrom fastai.vision.all import *\nfrom eagle_swing.data_class import *\nfrom eagle_swing.animate import *\nfrom eagle_swing.video_utils import *\nfrom eagle_swing.find_landmarks import *\n%matplotlib inline\n\n\n\n\nCode\n# base_path = '../../../data/full_videos/ymirza/nov16/'#sep14/IMG_1092/keypoint'\n# os.listdir(base_path)[:4]\n\n\n\n\nCode\n# df = pd.read_csv('../../../data/full_videos/ymirza/ymirza_lbls.csv')\n# df.head(1)\n\n\n\n\nCode\n# scores = df[df.video_name == 'IMG_1092'].reset_index(drop=True).score.values\n# scores\n\n\n\n\nCode\n# #pkl_file_path, video_path  = get_files(base_path)\n# pkl_file_paths  = get_files(base_path, extensions='.pkl')\n# #pkl_file_path, video_path \n# pkl_file_paths\n\n\n\n\nCode\n# date_folder = \"sep14\"\n# video_name = \"IMG_1086\"\n# problem_path = f'../../../data/full_videos/ymirza/{date_folder}/{video_name}/keypoints/{video_name}.pkl'\n# #problem_path = '../../../data/full_videos/ymirza/sep14/IMG_1091/keypoints/IMG_1091.pkl'\n# #kp_extracted = KpExtractor(pkl_file_path)\n# kp_extracted = KpExtractor(problem_path)\n# kps = kp_extracted.kps\n# kps.shape\n\n\n\n\nCode\n# kp_extracted = KpExtractor(problem_path)\n# #kp_extracted = KpExtractor(pkl_file_paths[0])\n# sequence_dict, frame_mask = find_score_hand(kp_extracted, min_consecutive=75)\n# frame_mask.sum(), sequence_dict.__len__(), sequence_dict[0]\n\n\n\n\nCode\nls ../../../data/full_videos/ymirza/oct25//\n\n\n\nIMG_1183/     IMG_1185.MOV  IMG_1187.mp4  IMG_1190/     IMG_1192.MOV\n\nIMG_1183.MOV  IMG_1185.mp4  IMG_1188/     IMG_1190.MOV  IMG_1192.mp4\n\nIMG_1183.mp4  IMG_1186/     IMG_1188.MOV  IMG_1190.mp4  IMG_1193/\n\nIMG_1184/     IMG_1186.MOV  IMG_1188.mp4  IMG_1191/     IMG_1193.MOV\n\nIMG_1184.MOV  IMG_1186.mp4  IMG_1189/     IMG_1191.MOV  IMG_1193.mp4\n\nIMG_1184.mp4  IMG_1187/     IMG_1189.MOV  IMG_1191.mp4\n\nIMG_1185/     IMG_1187.MOV  IMG_1189.mp4  IMG_1192/\n\n\n\n\n\n\nCode\n#get_files('../../../data/full_videos/ymirza/oct25', extensions='.pkl')\n\n\n\n\nCode\ndate_folder = \"oct25\"\nvideo_name = \"IMG_1184\"\nproblem_path = f'../../../data/full_videos/ymirza/{date_folder}/{video_name}/keypoints/{video_name}.pkl'\n#problem_df = df[df.video_name == video_name].reset_index(drop=True)\n#problem_df.shape\n\n\n\n\nCode\nkp_ext = KpExtractor(problem_path)\nall_higher_wrists = find_all_higher_wrist_idxs(kp_ext.kps)\nfirst_higher_list = find_each_first_higher_wrist(all_higher_wrists)\n#first_higher_list = first_higher_list[:6].append(first_higher_list[-2])\nbefore_increment = 60\nafter_increment = 900\npotential_swing_idxs = [(idx-before_increment, idx+after_increment) for idx in first_higher_list]\nlen(potential_swing_idxs), potential_swing_idxs[:3]\n\n\n(11, [(1784, 2744), (2404, 3364), (3998, 4958)])\n\n\n\n\nCode\nswings_holder = []\nfor start_idx, end_idx in potential_swing_idxs:\n    frames, fps = get_frames(f\"{problem_path[:-3]}mp4\",\n                          start_idx=start_idx,\n                          num_frames=end_idx-start_idx,\n                          resize_dim=(512, 512),\n                            )\n    #print(f\"frames per second for this are: {fps}\")\n    swings_holder.append(frames)\n\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 960/960 [00:02&lt;00:00, 446.50it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 960/960 [00:02&lt;00:00, 446.82it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 960/960 [00:02&lt;00:00, 445.21it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 960/960 [00:02&lt;00:00, 457.22it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 960/960 [00:02&lt;00:00, 444.93it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 960/960 [00:02&lt;00:00, 438.75it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 960/960 [00:02&lt;00:00, 436.85it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 960/960 [00:02&lt;00:00, 429.47it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 960/960 [00:02&lt;00:00, 432.49it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 960/960 [00:02&lt;00:00, 443.38it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 960/960 [00:02&lt;00:00, 425.49it/s]\n\n\n\n\nCode\n# good_idxs = [1, 3, \n            4, 5\n#                6, 8, 9]\n# good_swings = [x for idx, x in enumerate(swings_holder) if idx in good_idxs]\n# final_higher_list = [x for idx, x in enumerate(first_higher_list) if idx in good_idxs]\n# print(final_higher_list)\n\n\n\n\nCode\nfirst_higher_list\n\n\n[983, 3197, 4733, 5334, 7040, 7641, 9339, 11131]\n\n\n\n\nCode\n#view_videos_grid(good_swings)\n#view_videos_grid(swings_holder[1:7])\n#view_videos_grid(swings_holder[3:])\n\n\n\n\nCode\nhands_holder = get_hands_from_video(problem_path, min_consecutive=30);\n\n\nissue at index 0\n\n\n\n\nCode\n#view_videos_grid(hands_holder)\n\n\n\n\nCode\ncorrect_scores = [1, 5, 5,\n                  2, 5, 1, 4, 1]\ncorrect_idxs = np.arange(len(correct_scores))\nvideo_names = [video_name] * len(correct_scores)\npkl_paths = [f\"{date_folder}/{video_name}/keypoints/{video_name}.pkl\"] * len(correct_scores)\nnew_problem_df = pd.DataFrame([video_names, correct_idxs, correct_scores, pkl_paths],\n                             index=['video_name', 'swing_idx', 'score', 'pkl_path']).T\nclip_names = []\nfor idx, row in new_problem_df.iterrows():\n    clip_name = f\"{row.video_name}_swing_{row.swing_idx}_score_{row.score}\"\n    clip_names.append(clip_name)\nnew_problem_df['clip_name'] = clip_names\nnew_problem_df.head(2)\n\n\n\n\n\n\n\n\n\nvideo_name\nswing_idx\nscore\npkl_path\nclip_name\n\n\n\n\n0\nIMG_1192\n0\n1\noct25/IMG_1192/keypoints/IMG_1192.pkl\nIMG_1192_swing_0_score_1\n\n\n1\nIMG_1192\n1\n5\noct25/IMG_1192/keypoints/IMG_1192.pkl\nIMG_1192_swing_1_score_5\n\n\n\n\n\n\n\n\n\nCode\n# keep_idx_list = final_higher_list#first_higher_list[1:]\n# new_problem_df['first_higher_wrists_backswing_frame'] = keep_idx_list\n# save_csv_path = f\"{Path(problem_path).parent}/clean_lbls.csv\"\n# new_problem_df.to_csv(save_csv_path, index=False)\n# save_csv_path\n\n\n\n\nCode\nkeep_idx_list = first_higher_list\n#keep_idx_list = final_higher_list#first_higher_list[1:]\n# one_list = first_higher_list[1:6]\n# keep_idx_list = one_list.append(first_higher_list[7])\n\n\n\n\nCode\nnew_problem_df['first_higher_wrists_backswing_frame'] = keep_idx_list\nsave_csv_path = f\"{Path(problem_path).parent}/clean_lbls.csv\"\nnew_problem_df.to_csv(save_csv_path, index=False)\nsave_csv_path\n\n\n'../../../data/full_videos/ymirza/oct25/IMG_1192/keypoints/clean_lbls.csv'\n\n\nWe have the start and end frames where one wrist above the shoulder and elbow while the other is below the hip and knee on the opposite side, lets index into the areas where this happens and find the frame where the hand is at itâ€™s highest point on the y-axis, from there we can clip X+/- frames around the highest point and only have images of the hands\n\n\nCode\nsingle_highest_wrist_idx, wrist_xy = find_highest_single_wrist_frame(kp_extracted, sequence_dict, 1)\nsingle_highest_wrist_idx\n\n\n4404\n\n\n\n\nCode\nstart_idx, end_idx = get_highest_single_wrist_bounding_idxs(single_highest_wrist_idx, 60)\nstart_idx, end_idx\n\n\n(4344, 4434)\n\n\n\n\nCode\none_kps = get_highest_wrist_kps(kp_extracted, start_idx, end_idx)\none_frames, fps = get_highest_wrist_frames(kp_extracted, start_idx, end_idx)\none_frames.shape\n\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:00&lt;00:00, 287.13it/s]\n\n\n(90, 1920, 1080, 3)\n\n\n\n\nCode\nnov16_score_dict = {\n                    \"IMG_1274\" : [4, 2, 4, 3, 2, 4, 2, 5, 2, 5, 2, 2, 3, 4],\n                    \"IMG_1272\" : [1, 3, 5, 2, 2, 2, 5, 1],\n                    \"IMG_1273\" : [2, 2, 4, 3, 4, 5, 5, 4, 5, 4, 3, 2, 5],\n                    }\n\n\n\n\nCode\ndf_holder = []\nfor video_key in nov16_score_dict.keys():\n    scores = nov16_score_dict[video_key]\n    swing_idxs = np.arange(len(scores))\n    video_names = [video_key] * len(scores)\n    df_holder.append(pd.DataFrame(zip(video_names, swing_idxs, scores), \n                       columns=['video_name','swing_index','score']), \n          )\n\n\n\n\nCode\nnov16_df = pd.concat(df_holder).reset_index(drop=True)\nnov16_df['pkl_path'] = nov16_df.video_name.map(lambda x: f\"nov16/{x}/keypoints/{x}.pkl\")\nclip_names = []\nfor idx, row in nov16_df.iterrows():\n    clip_names.append(f\"{row.video_name}_swing_{row.swing_index}_score_{row.score}\")\nnov16_df['clip_name'] = clip_names\nnov16_df.shape\n\n\n(35, 5)\n\n\n\n\nCode\nlbl_df.head(2)\n\n\n\n\n\n\n\n\n\nclip_name\nvideo_name\nswing_index\nscore\npkl_path\n\n\n\n\n0\nIMG_1015_swing_0_score_3\nIMG_1015\n0\n3\naug9/IMG_1015/keypoints/IMG_1015.pkl\n\n\n1\nIMG_1015_swing_1_score_1\nIMG_1015\n1\n1\naug9/IMG_1015/keypoints/IMG_1015.pkl\n\n\n\n\n\n\n\n\n\nCode\n! ls ../../../data/full_videos/ymirza/ymirza_lbls.csv\n\n\naug9             jun8       nov16  Untitled1.ipynb\nhard_bake_videos.py  label_videos.py    oct25  Untitled.ipynb\nindex.ipynb      new_analyze.ipynb  sep14  ymirza_lbls.csv\n\n\n\n\nCode\nnov16_df.to_csv('../../../data/full_videos/ymirza/nov16/lbls.csv', index=False)\n\n\n\n\nCode\npd.concat([lbl_df, nov16_df]).reset_index(drop=True)\n\n\n\n\n\n\n\n\n\nclip_name\nvideo_name\nswing_index\nscore\npkl_path\n\n\n\n\n0\nIMG_1015_swing_0_score_3\nIMG_1015\n0\n3\naug9/IMG_1015/keypoints/IMG_1015.pkl\n\n\n1\nIMG_1015_swing_1_score_1\nIMG_1015\n1\n1\naug9/IMG_1015/keypoints/IMG_1015.pkl\n\n\n2\nIMG_1015_swing_2_score_3\nIMG_1015\n2\n3\naug9/IMG_1015/keypoints/IMG_1015.pkl\n\n\n3\nIMG_1015_swing_3_score_3\nIMG_1015\n3\n3\naug9/IMG_1015/keypoints/IMG_1015.pkl\n\n\n4\nIMG_1015_swing_4_score_2\nIMG_1015\n4\n2\naug9/IMG_1015/keypoints/IMG_1015.pkl\n\n\n...\n...\n...\n...\n...\n...\n\n\n225\nIMG_1273_swing_8_score_5\nIMG_1273\n8\n5\nnov16/IMG_1273/keypoints/IMG_1273.pkl\n\n\n226\nIMG_1273_swing_9_score_4\nIMG_1273\n9\n4\nnov16/IMG_1273/keypoints/IMG_1273.pkl\n\n\n227\nIMG_1273_swing_10_score_3\nIMG_1273\n10\n3\nnov16/IMG_1273/keypoints/IMG_1273.pkl\n\n\n228\nIMG_1273_swing_11_score_2\nIMG_1273\n11\n2\nnov16/IMG_1273/keypoints/IMG_1273.pkl\n\n\n229\nIMG_1273_swing_12_score_5\nIMG_1273\n12\n5\nnov16/IMG_1273/keypoints/IMG_1273.pkl\n\n\n\n\n230 rows Ã— 5 columns\n\n\n\n\n\nCode\ndef get_one_hand(kp_extracted,\n                 sequence_dict,\n                 idx=0, \n                 increment_frame_count_before=30,\n                 increment_frame_count_after=60,\n                 animate=True,\n                 return_hand_only=False):    \n    \n    single_highest_wrist_idx, wrist_xy = find_highest_single_wrist_frame(kp_extracted, \n                                                                         sequence_dict, \n                                                                         idx)\n    start_idx, end_idx = get_highest_single_wrist_bounding_idxs(single_highest_wrist_idx, \n                                                                increment_frame_count_before,\n                                                               increment_frame_count_after)\n    one_kps = get_highest_wrist_kps(kp_extracted, start_idx, end_idx)\n    one_frames, fps = get_highest_wrist_frames(kp_extracted, start_idx, end_idx)\n    \n    if animate:\n        animator = animate_keypoints(one_kps, dark_mode=True)\n        display(HTML(animator.to_jshtml()))\n        \n    if return_hand_only:\n        hand_holder = []\n        # Ensure we just get the relevant wrist slice\n        right_wrist_xy = kp_extracted.r_wrist[start_idx: end_idx, :2]\n                \n        for i in range(len(right_wrist_xy)):\n            x_wrist = int(right_wrist_xy[i][0])\n            y_wrist = int(right_wrist_xy[i][1])\n            \n            # Swap X/Y and handle boundary checks (clamp to 0)\n            y1 = max(0, y_wrist - 200)\n            y2 = y_wrist + 100\n            x1 = max(0, x_wrist - 100)\n            x2 = x_wrist + 100\n            \n            # Index as [Frame, Y (Rows), X (Cols)]\n            crop = one_frames[i, y1:y2, x1:x2]\n            hand_holder.append(crop)\n            \n        return np.stack(hand_holder) \n        \n    return one_frames\n\n\n\n\nCode\ndef get_hands_from_video(pkl_file_path,\n                        min_consecutive=75,\n                        animate=False):\n    kp_extracted = KpExtractor(pkl_file_path)\n    sequence_dict, frame_mask = find_score_hand(kp_extracted, \n                                                min_consecutive=min_consecutive)\n     \n    holder = []\n    for x in range(len(sequence_dict)):\n       try:\n           holder.append(get_one_hand(kp_extracted,\n                                  sequence_dict,\n                                  idx=x,\n                                  increment_frame_count_before=0,\n                                  increment_frame_count_after=60,\n                                  animate=animate, \n                                  return_hand_only=True))\n       except:\n            print(f'issue at index {x}')\n    return holder\n\n\n\n\nCode\nhands_holder = get_hands_from_video(pkl_file_paths[0])\nview_videos_grid(hands_holder)\n\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:00&lt;00:00, 288.56it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:00&lt;00:00, 278.35it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:00&lt;00:00, 276.82it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:00&lt;00:00, 283.91it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:00&lt;00:00, 281.93it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:00&lt;00:00, 282.88it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:00&lt;00:00, 281.32it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:00&lt;00:00, 280.80it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:00&lt;00:00, 278.50it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:00&lt;00:00, 270.31it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:00&lt;00:00, 283.15it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:00&lt;00:00, 268.24it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:00&lt;00:00, 285.64it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:00&lt;00:00, 284.00it/s]\n\n\nWarning: Displaying 14 videos might cause performance lag.\n\n\n\n\n\n\n\n\n\n\nCode\nhands_holder = get_hands_from_video(pkl_file_paths[1])\nview_videos_grid(hands_holder)\n\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:00&lt;00:00, 288.22it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:00&lt;00:00, 273.09it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:00&lt;00:00, 284.24it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:00&lt;00:00, 276.12it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:00&lt;00:00, 286.43it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:00&lt;00:00, 283.59it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:00&lt;00:00, 281.78it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:00&lt;00:00, 283.84it/s]\n\n\n\n\n\n\n\nCode\nhands_holder = get_hands_from_video(pkl_file_paths[2])\nview_videos_grid(hands_holder)\n\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:00&lt;00:00, 280.47it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:00&lt;00:00, 276.23it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:00&lt;00:00, 282.36it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:00&lt;00:00, 279.33it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:00&lt;00:00, 285.15it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:00&lt;00:00, 285.54it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:00&lt;00:00, 279.49it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:00&lt;00:00, 280.42it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:00&lt;00:00, 279.58it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:00&lt;00:00, 274.53it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:00&lt;00:00, 286.09it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:00&lt;00:00, 271.42it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:00&lt;00:00, 275.04it/s]\n\n\nWarning: Displaying 13 videos might cause performance lag.\n\n\n\n\n\n\n\n\n\n\nCode\n\n\n\nPath('../../../data/full_videos/ymirza/nov16/IMG_1274/keypoints/IMG_1274.pkl')\n\n\n\n\nCode\n#view_videos(holder[6:])\n\n\n\n\nCode\ndf.video_name.unique()[10]\n\n\n'IMG_0860'\n\n\n\n\nCode\nparent_path = '../../../data/full_videos/ymirza/'\n\n\n\n\nCode\nhand_dataset_parent_dir = '../../../data/score_hands'\nhand_dataset_parent_dir\n\n\n'../../../data/score_hands'\n\n\n\n\nCode\n#df.pkl_path.unique().__len__()\n\n\n\n\nCode\ndf.iloc[1]\n\n\nclip_name                  IMG_1015_swing_1_score_1\nvideo_name                                 IMG_1015\nswing_index                                       1\nscore                                             1\npkl_path       aug9/IMG_1015/keypoints/IMG_1015.pkl\nName: 1, dtype: object\n\n\n\n\nCode\ndf[df['video_name'] == df.iloc[0].video_name].score.values\n\n\narray([3, 1, 3, 3, 2, 2, 1, 4, 1, 2, 4, 4, 2])\n\n\n\n\nCode\nlbl_df = pd.read_csv('../../../data/full_videos/ymirza/ymirza_lbls.csv')\nlbl_df.head(2)\n\n\n\n\n\n\n\n\n\nclip_name\nvideo_name\nswing_index\nscore\npkl_path\n\n\n\n\n0\nIMG_1015_swing_0_score_3\nIMG_1015\n0\n3\naug9/IMG_1015/keypoints/IMG_1015.pkl\n\n\n1\nIMG_1015_swing_1_score_1\nIMG_1015\n1\n1\naug9/IMG_1015/keypoints/IMG_1015.pkl\n\n\n\n\n\n\n\n\n\nCode\ndef save_hand_score_frames(video_name, \n                           df=None,\n                           parent_path=None,\n                           save_path_parent_dir=None,\n                           min_consecutive=75,\n                          ):\n    if df is None:\n        df = pd.read_csv('../../../data/full_videos/ymirza/ymirza_lbls.csv')\n#    return df.video_name\n    row = df[df.video_name == video_name].reset_index(drop=True).iloc[0]                           \n    if parent_path is None:\n        parent_path = '../../../data/full_videos/ymirza/'\n    if save_path_parent_dir is None:\n        save_path_parent_dir = '../../../data/score_hands'\n    pkl_path = f'{parent_path}/{row.pkl_path}'\n    try:\n        holder = get_hands_from_video(pkl_path, min_consecutive)\n    except:\n        print(f'issue with {row}')\n    save_fpath_names = df[df['video_name'] == row.video_name].clip_name.values\n    save_paths = [f\"{save_path_parent_dir}/{save_fpath}.npy\" for save_fpath in save_fpath_names]\n    for idx in range(len(save_paths)):\n        try:\n            np.save(file=save_paths[idx], arr=holder[idx])\n        except:\n            print(f'having an issue with {save_paths[idx]}')\n            print(f'the array has shape{holder[idx].shape}')\n\n\n\n\nCode\ndf.video_name.unique()[24:]\n\n\narray(['IMG_1091', 'IMG_1092', 'IMG_1093'], dtype=object)\n\n\n\n\nCode\n# for img_name in df.video_name.unique()[24:]:\n#     save_hand_score_frames(img_name)\n\n\n\n\nCode\nview_videos(np.load('../../../data/score_hands/IMG_1088_swing_2_score_3.npy'))\n\n\n\n\n\n\n\nCode\n#pd.read_csv('../../../data/full_videos/ymirza/ymirza_lbls.csv')\n\n\n\n\nCode\ndf[df.video_name == 'IMG_1018'].pkl_path.iloc[0]\n\n\n'aug9/IMG_1018/keypoints/IMG_1018.pkl'\n\n\n\n\nCode\ndf.video_name.unique()[6:19]\n\n\narray(['IMG_0848', 'IMG_0849', 'IMG_0851', 'IMG_0858', 'IMG_0860',\n       'IMG_0852', 'IMG_0853', 'IMG_0854', 'IMG_0855', 'IMG_0856',\n       'IMG_0857', 'IMG_0859', 'IMG_0861'], dtype=object)\n\n\n\n\nCode\n# problem_video = df.video_name.unique()[18]\n# save_hand_score_frames(problem_video, min_consecutive=15)\n\n\n\n\nCode\nproblem_video = 'IMG_0860'\nproblem_video = df.video_name.unique()[6]\nproblem_pkl_path = df[df.video_name == problem_video].pkl_path.iloc[0]\nfull_path = f'{parent_path}/{problem_pkl_path}'\nsecond_holder = get_hands_from_video(f'{parent_path}/{problem_pkl_path}',\n                                    min_consecutive=15)\n\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:00&lt;00:00, 285.25it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:00&lt;00:00, 283.12it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:00&lt;00:00, 275.43it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:00&lt;00:00, 282.17it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:00&lt;00:00, 284.52it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:00&lt;00:00, 288.30it/s]\n\n\nissue at index 5\n\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:00&lt;00:00, 286.73it/s]\n\n\n\n\nCode\nscores = df[df.video_name == problem_video].score\nscores\n\n\n64    2\n65    5\n66    5\n67    4\n68    4\n69    4\n70    4\nName: score, dtype: int64\n\n\n\n\nCode\nview_videos(second_holder[5:])\n\n\n\n\n\n\n\nCode\ndef find_highest_single_wrist_frame(KpExtractor_item, sequence_dict, idx):\n    start_idx = sequence_dict[idx]['start_frame']\n    end_idx = sequence_dict[idx]['end_frame']\n    wrist_idx = sequence_dict[idx]['wrist_above']\n    if sequence_dict[idx]['wrist_above'] == 'right':\n        wrist_xy = KpExtractor_item.r_wrist[start_idx:end_idx][:, :2]\n        top_frame_idx = np.argmin(wrist_xy[:, 1])\n    else:\n        wrist_xy = KpExtractor_item.l_wrist[start_idx:end_idx][:, 2]\n        top_frame_idx = np.argmin(wrist_xy[:, 1])        \n    video_top_frame_idx = start_idx + top_frame_idx\n    return video_top_frame_idx, wrist_xy\n\ndef get_highest_single_wrist_bounding_idxs(highest_frame, \n                                           increment_frame_count_before=30,\n                                           increment_frame_count_after=30,\n                                          ):\n    start_idx = highest_frame - increment_frame_count_before\n    end_idx = highest_frame + increment_frame_count_after\n    return start_idx, end_idx\n\ndef get_highest_wrist_kps(KpExtractor_item, start_idx, end_idx):\n    return KpExtractor_item.kps[start_idx:end_idx]\n    \ndef get_highest_wrist_frames(KpExtractor_item, start_idx, end_idx):\n    video_path = KpExtractor_item.video_path\n    frames, fps = get_frames(video_path, \n                        start_idx=start_idx,\n                        num_frames=end_idx-start_idx,\n                        resize_dim=None)\n    return frames, fps\n\ndef get_highest_hand_crop(frames, \n                          wrist_xy,\n                          increment=50):\n    handup_frames = []\n    for idx in range(len(wrist_xy)):\n        wrist_x = int(wrist_xy[idx, 0])\n        wrist_y = int(wrist_xy[idx, 1])\n        print(wrist_y&lt;frames.shape[2])\n        this_frame = frames[idx, \n                             wrist_x - increment : wrist_x + increment,\n                             wrist_y - increment : wrist_y + increment\n                             ]\n#        print(this_frame.shape)\n        if idx == 10:\n            break\n        handup_frames.append(this_frame)\n    return handup_frames\n\n\n\n\nCode\ndef get_handcrops(pkl_file_path, \n                 min_consecutive_high_frames=75,\n                 crop_bounds=60,\n                ):\n    kp_extracted = KpExtractor(pkl_file_path)\n    sequence_dict, frame_mask = find_score_hand(kp_extracted, \n                                                min_consecutive=min_consecutive_high_frames)\n    hand_crop_holder = []\n    for seq_idx in range(len(sequence_dict)):\n        single_highest_wrist_idx, wrist_xy = find_highest_single_wrist_frame(kp_extracted, \n                                                                             sequence_dict, \n                                                                             seq_idx)\n        start_idx, end_idx = get_highest_single_wrist_bounding_idxs(single_highest_wrist_idx, \n                                                                    crop_bounds)\n        frames, fps = get_frames(kp_extracted.video_path, \n                                 num_frames=end_idx-start_idx, \n                                 start_idx=start_idx, \n                                 resize_dim=None)\n        wrist_xy = kp_extracted.r_wrist[start_idx:end_idx]\n        hand_crop = get_highest_hand_crop(frames=frames,\n                                          wrist_xy=wrist_xy,\n                                          increment=100)\n        hand_crop_holder.append(hand_crop)\n    return hand_crop_holder"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Eagle Swing Takes Off",
    "section": "",
    "text": "This is the first post in the R&D page for Eagle Swing. Welcome!\n\nThe idea behind Eagle Swing is simple, some days you have a good day at the range and sometimes you canâ€™t figure out all the things youâ€™re off on. Here, we take in a recorded video of a driving range session and then after processing the video with our models â€“&gt; we can generate insights into what you are doing when you hit your best swing compared to those swings where you canâ€™t seem to connect.\nThis repo and website will be organized in a specific fashion, in creating the end product, weâ€™ll run into a ton of questions along the way that need to be answered. In this pursuit, each notebook/post will be featuring a specific problem that needs further exploration, sometimes code will be generated within the notebook for further use, while sometimes that code will be only useful for the small and specific purpose of the task at hand."
  },
  {
    "objectID": "posts/exploratory-data-analysis/eda_nb.html",
    "href": "posts/exploratory-data-analysis/eda_nb.html",
    "title": "Initial Video Analysis",
    "section": "",
    "text": "we have 28 total videos & the file names are: \n['IMG_1014', 'IMG_1017', 'IMG_1015', 'IMG_1018', 'IMG_1023', 'IMG_1016', 'IMG_1019', 'IMG_0851', 'IMG_0855', 'IMG_0856', 'IMG_0849', 'IMG_0860', 'IMG_0857', 'IMG_0852', 'IMG_0853', 'IMG_0858', 'IMG_0859', 'IMG_0854', 'IMG_0848', 'IMG_0861', 'IMG_1090', 'IMG_1087', 'IMG_1088', 'IMG_1092', 'IMG_1086', 'IMG_1093', 'IMG_1091', 'IMG_1089']\n\n\n\n\n\n\n\n177M    ../../../data/full_videos/jun8/IMG_0856.MOV\n4.0M    ../../../data/clips/accurate/IMG_0856_swing_3_score_2.mp4\n\n\n\n\n\n\n\nCode\nclass video_metadata():\n    def __init__(self, file_path):\n        self.file_path = file_path\n        self.metadata = self.get_metadata(self.file_path)\n        self.height = self.metadata['height']\n        self.width = self.metadata['width']\n        self.fps = self.get_fps(self.metadata)\n        self.minutes = self.get_duration(self.metadata, minutes=True)\n        self.seconds = self.get_duration(self.metadata)\n        self.bitrate = self.get_bitrate(self.metadata)\n\n    def aggregate_metadata(self):\n        return {'file_name': str(self.file_path).split('/')[-1],\n                'fps': self.fps,\n                'height': self.height,\n                'width': self.width,\n                'minutes': self.minutes,\n                'seconds': self.seconds,\n                'bitrate': self.bitrate,\n                'file_path': self.file_path,\n                }\n    def get_metadata(self, file_path):\n        '''\n        Sometimes the video metadata is not in the first stream??\n        '''\n        meta_list = ffmpeg.probe(file_path)['streams']\n        for meta in meta_list:\n            try: \n                meta['height']\n                return meta\n            except:\n                pass\n                 \n    def get_fps(self, metadata):\n        fps = metadata['r_frame_rate']\n        return round(eval(fps))\n\n    def get_duration(self, metadata, minutes=False):\n        seconds = round(float(metadata['duration']))\n        # returns time in minutes\n        if minutes: \n            return seconds / 60\n        else: return seconds\n\n    def get_bitrate(self, metadata):\n        ### returns bit rate in megabyte -- divide by 1000 for Kbs and once more for Mbs\n        bitrate = int(metadata['bit_rate']) / 1000 / 1000\n        return bitrate\n\n\n\n\nCode\nvideo_metadata(video_paths[12]).aggregate_metadata()\n\n\n{'file_name': 'IMG_0857.MOV',\n 'fps': 30,\n 'height': 1080,\n 'width': 1920,\n 'minutes': 2.55,\n 'seconds': 153,\n 'bitrate': 8.605271,\n 'file_path': Path('../../../data/full_videos/jun8/IMG_0857.MOV')}\n\n\n\n\n\n\n\n\n\n\n\nfile_name\nfps\nheight\nwidth\nminutes\nseconds\nbitrate\nfile_path\n\n\n\n\n0\nIMG_0848.MOV\n30\n1080\n1920\n4.383333\n263\n8.610146\n../../../data/full_videos/jun8/IMG_0848.MOV\n\n\n1\nIMG_0849.MOV\n30\n1080\n1920\n9.200000\n552\n8.583966\n../../../data/full_videos/jun8/IMG_0849.MOV\n\n\n2\nIMG_0851.MOV\n30\n960\n540\n2.866667\n172\n4.692317\n../../../data/full_videos/jun8/IMG_0851.MOV\n\n\n3\nIMG_0852.MOV\n30\n540\n960\n2.950000\n177\n1.370111\n../../../data/full_videos/jun8/IMG_0852.MOV\n\n\n4\nIMG_0853.MOV\n30\n540\n960\n2.716667\n163\n1.367803\n../../../data/full_videos/jun8/IMG_0853.MOV\n\n\n5\nIMG_0854.MOV\n30\n1080\n1920\n2.616667\n157\n8.607743\n../../../data/full_videos/jun8/IMG_0854.MOV\n\n\n6\nIMG_0855.MOV\n30\n1080\n1920\n2.966667\n178\n8.598368\n../../../data/full_videos/jun8/IMG_0855.MOV\n\n\n7\nIMG_0856.MOV\n30\n1080\n1920\n2.783333\n167\n8.588547\n../../../data/full_videos/jun8/IMG_0856.MOV\n\n\n8\nIMG_0857.MOV\n30\n1080\n1920\n2.550000\n153\n8.605271\n../../../data/full_videos/jun8/IMG_0857.MOV\n\n\n9\nIMG_0858.MOV\n30\n568\n320\n3.050000\n183\n1.865664\n../../../data/full_videos/jun8/IMG_0858.MOV\n\n\n10\nIMG_0859.MOV\n30\n1080\n1920\n2.516667\n151\n8.624519\n../../../data/full_videos/jun8/IMG_0859.MOV\n\n\n11\nIMG_0860.MOV\n30\n1920\n1080\n1.800000\n108\n10.544283\n../../../data/full_videos/jun8/IMG_0860.MOV\n\n\n12\nIMG_0861.MOV\n30\n1080\n1920\n7.216667\n433\n8.584579\n../../../data/full_videos/jun8/IMG_0861.MOV\n\n\n13\nIMG_1014.MOV\n60\n1080\n1920\n7.400000\n444\n13.103602\n../../../data/full_videos/aug9/IMG_1014.MOV\n\n\n14\nIMG_1015.MOV\n60\n1080\n1920\n6.550000\n393\n13.103961\n../../../data/full_videos/aug9/IMG_1015.MOV\n\n\n15\nIMG_1016.MOV\n60\n1080\n1920\n5.483333\n329\n13.110048\n../../../data/full_videos/aug9/IMG_1016.MOV\n\n\n16\nIMG_1017.MOV\n60\n1080\n1920\n2.866667\n172\n13.134301\n../../../data/full_videos/aug9/IMG_1017.MOV\n\n\n17\nIMG_1018.MOV\n30\n2160\n3840\n5.250000\n315\n25.100516\n../../../data/full_videos/aug9/IMG_1018.MOV\n\n\n18\nIMG_1019.MOV\n60\n2160\n3840\n4.650000\n279\n53.182729\n../../../data/full_videos/aug9/IMG_1019.MOV\n\n\n19\nIMG_1023.MOV\n60\n2160\n3840\n6.883333\n413\n56.143823\n../../../data/full_videos/aug9/IMG_1023.MOV\n\n\n20\nIMG_1086.MOV\n60\n1920\n1080\n2.883333\n173\n15.800221\n../../../data/full_videos/sep14/IMG_1086.MOV\n\n\n21\nIMG_1087.MOV\n60\n1920\n1080\n2.833333\n170\n15.820864\n../../../data/full_videos/sep14/IMG_1087.MOV\n\n\n22\nIMG_1088.MOV\n60\n1920\n1080\n2.433333\n146\n15.823184\n../../../data/full_videos/sep14/IMG_1088.MOV\n\n\n23\nIMG_1089.MOV\n60\n1920\n1080\n4.200000\n252\n15.795585\n../../../data/full_videos/sep14/IMG_1089.MOV\n\n\n24\nIMG_1090.MOV\n60\n1920\n1080\n3.383333\n203\n15.800890\n../../../data/full_videos/sep14/IMG_1090.MOV\n\n\n25\nIMG_1091.MOV\n60\n1920\n1080\n3.750000\n225\n15.787499\n../../../data/full_videos/sep14/IMG_1091.MOV\n\n\n26\nIMG_1092.MOV\n60\n1920\n1080\n3.200000\n192\n15.800213\n../../../data/full_videos/sep14/IMG_1092.MOV\n\n\n27\nIMG_1093.MOV\n60\n1920\n1080\n3.200000\n192\n15.792813\n../../../data/full_videos/sep14/IMG_1093.MOV\n\n\n\n\n\n\n\nNow we have a quick and easily understandable way to extract all the metadata relative to our videos and get a better understaning of where outliers may lie with respect to data quality or frame rate and also to better understand the overall distribution we have amongst our data"
  },
  {
    "objectID": "posts/exploratory-data-analysis/eda_nb.html#lets-take-a-look-at-our-full-videos-and-pull-some-metadata-from-them-in-case-we-need-this-information-later-on",
    "href": "posts/exploratory-data-analysis/eda_nb.html#lets-take-a-look-at-our-full-videos-and-pull-some-metadata-from-them-in-case-we-need-this-information-later-on",
    "title": "Initial Video Analysis",
    "section": "",
    "text": "we have 28 total videos & the file names are: \n['IMG_1014', 'IMG_1017', 'IMG_1015', 'IMG_1018', 'IMG_1023', 'IMG_1016', 'IMG_1019', 'IMG_0851', 'IMG_0855', 'IMG_0856', 'IMG_0849', 'IMG_0860', 'IMG_0857', 'IMG_0852', 'IMG_0853', 'IMG_0858', 'IMG_0859', 'IMG_0854', 'IMG_0848', 'IMG_0861', 'IMG_1090', 'IMG_1087', 'IMG_1088', 'IMG_1092', 'IMG_1086', 'IMG_1093', 'IMG_1091', 'IMG_1089']\n\n\n\n\n\n\n\n177M    ../../../data/full_videos/jun8/IMG_0856.MOV\n4.0M    ../../../data/clips/accurate/IMG_0856_swing_3_score_2.mp4\n\n\n\n\n\n\n\nCode\nclass video_metadata():\n    def __init__(self, file_path):\n        self.file_path = file_path\n        self.metadata = self.get_metadata(self.file_path)\n        self.height = self.metadata['height']\n        self.width = self.metadata['width']\n        self.fps = self.get_fps(self.metadata)\n        self.minutes = self.get_duration(self.metadata, minutes=True)\n        self.seconds = self.get_duration(self.metadata)\n        self.bitrate = self.get_bitrate(self.metadata)\n\n    def aggregate_metadata(self):\n        return {'file_name': str(self.file_path).split('/')[-1],\n                'fps': self.fps,\n                'height': self.height,\n                'width': self.width,\n                'minutes': self.minutes,\n                'seconds': self.seconds,\n                'bitrate': self.bitrate,\n                'file_path': self.file_path,\n                }\n    def get_metadata(self, file_path):\n        '''\n        Sometimes the video metadata is not in the first stream??\n        '''\n        meta_list = ffmpeg.probe(file_path)['streams']\n        for meta in meta_list:\n            try: \n                meta['height']\n                return meta\n            except:\n                pass\n                 \n    def get_fps(self, metadata):\n        fps = metadata['r_frame_rate']\n        return round(eval(fps))\n\n    def get_duration(self, metadata, minutes=False):\n        seconds = round(float(metadata['duration']))\n        # returns time in minutes\n        if minutes: \n            return seconds / 60\n        else: return seconds\n\n    def get_bitrate(self, metadata):\n        ### returns bit rate in megabyte -- divide by 1000 for Kbs and once more for Mbs\n        bitrate = int(metadata['bit_rate']) / 1000 / 1000\n        return bitrate\n\n\n\n\nCode\nvideo_metadata(video_paths[12]).aggregate_metadata()\n\n\n{'file_name': 'IMG_0857.MOV',\n 'fps': 30,\n 'height': 1080,\n 'width': 1920,\n 'minutes': 2.55,\n 'seconds': 153,\n 'bitrate': 8.605271,\n 'file_path': Path('../../../data/full_videos/jun8/IMG_0857.MOV')}\n\n\n\n\n\n\n\n\n\n\n\nfile_name\nfps\nheight\nwidth\nminutes\nseconds\nbitrate\nfile_path\n\n\n\n\n0\nIMG_0848.MOV\n30\n1080\n1920\n4.383333\n263\n8.610146\n../../../data/full_videos/jun8/IMG_0848.MOV\n\n\n1\nIMG_0849.MOV\n30\n1080\n1920\n9.200000\n552\n8.583966\n../../../data/full_videos/jun8/IMG_0849.MOV\n\n\n2\nIMG_0851.MOV\n30\n960\n540\n2.866667\n172\n4.692317\n../../../data/full_videos/jun8/IMG_0851.MOV\n\n\n3\nIMG_0852.MOV\n30\n540\n960\n2.950000\n177\n1.370111\n../../../data/full_videos/jun8/IMG_0852.MOV\n\n\n4\nIMG_0853.MOV\n30\n540\n960\n2.716667\n163\n1.367803\n../../../data/full_videos/jun8/IMG_0853.MOV\n\n\n5\nIMG_0854.MOV\n30\n1080\n1920\n2.616667\n157\n8.607743\n../../../data/full_videos/jun8/IMG_0854.MOV\n\n\n6\nIMG_0855.MOV\n30\n1080\n1920\n2.966667\n178\n8.598368\n../../../data/full_videos/jun8/IMG_0855.MOV\n\n\n7\nIMG_0856.MOV\n30\n1080\n1920\n2.783333\n167\n8.588547\n../../../data/full_videos/jun8/IMG_0856.MOV\n\n\n8\nIMG_0857.MOV\n30\n1080\n1920\n2.550000\n153\n8.605271\n../../../data/full_videos/jun8/IMG_0857.MOV\n\n\n9\nIMG_0858.MOV\n30\n568\n320\n3.050000\n183\n1.865664\n../../../data/full_videos/jun8/IMG_0858.MOV\n\n\n10\nIMG_0859.MOV\n30\n1080\n1920\n2.516667\n151\n8.624519\n../../../data/full_videos/jun8/IMG_0859.MOV\n\n\n11\nIMG_0860.MOV\n30\n1920\n1080\n1.800000\n108\n10.544283\n../../../data/full_videos/jun8/IMG_0860.MOV\n\n\n12\nIMG_0861.MOV\n30\n1080\n1920\n7.216667\n433\n8.584579\n../../../data/full_videos/jun8/IMG_0861.MOV\n\n\n13\nIMG_1014.MOV\n60\n1080\n1920\n7.400000\n444\n13.103602\n../../../data/full_videos/aug9/IMG_1014.MOV\n\n\n14\nIMG_1015.MOV\n60\n1080\n1920\n6.550000\n393\n13.103961\n../../../data/full_videos/aug9/IMG_1015.MOV\n\n\n15\nIMG_1016.MOV\n60\n1080\n1920\n5.483333\n329\n13.110048\n../../../data/full_videos/aug9/IMG_1016.MOV\n\n\n16\nIMG_1017.MOV\n60\n1080\n1920\n2.866667\n172\n13.134301\n../../../data/full_videos/aug9/IMG_1017.MOV\n\n\n17\nIMG_1018.MOV\n30\n2160\n3840\n5.250000\n315\n25.100516\n../../../data/full_videos/aug9/IMG_1018.MOV\n\n\n18\nIMG_1019.MOV\n60\n2160\n3840\n4.650000\n279\n53.182729\n../../../data/full_videos/aug9/IMG_1019.MOV\n\n\n19\nIMG_1023.MOV\n60\n2160\n3840\n6.883333\n413\n56.143823\n../../../data/full_videos/aug9/IMG_1023.MOV\n\n\n20\nIMG_1086.MOV\n60\n1920\n1080\n2.883333\n173\n15.800221\n../../../data/full_videos/sep14/IMG_1086.MOV\n\n\n21\nIMG_1087.MOV\n60\n1920\n1080\n2.833333\n170\n15.820864\n../../../data/full_videos/sep14/IMG_1087.MOV\n\n\n22\nIMG_1088.MOV\n60\n1920\n1080\n2.433333\n146\n15.823184\n../../../data/full_videos/sep14/IMG_1088.MOV\n\n\n23\nIMG_1089.MOV\n60\n1920\n1080\n4.200000\n252\n15.795585\n../../../data/full_videos/sep14/IMG_1089.MOV\n\n\n24\nIMG_1090.MOV\n60\n1920\n1080\n3.383333\n203\n15.800890\n../../../data/full_videos/sep14/IMG_1090.MOV\n\n\n25\nIMG_1091.MOV\n60\n1920\n1080\n3.750000\n225\n15.787499\n../../../data/full_videos/sep14/IMG_1091.MOV\n\n\n26\nIMG_1092.MOV\n60\n1920\n1080\n3.200000\n192\n15.800213\n../../../data/full_videos/sep14/IMG_1092.MOV\n\n\n27\nIMG_1093.MOV\n60\n1920\n1080\n3.200000\n192\n15.792813\n../../../data/full_videos/sep14/IMG_1093.MOV\n\n\n\n\n\n\n\nNow we have a quick and easily understandable way to extract all the metadata relative to our videos and get a better understaning of where outliers may lie with respect to data quality or frame rate and also to better understand the overall distribution we have amongst our data"
  },
  {
    "objectID": "posts/auto_score/Untitled.html",
    "href": "posts/auto_score/Untitled.html",
    "title": "eagle-swing",
    "section": "",
    "text": "from fastai.vision.all import *\n\n\nhand_path = '../../../data/score_hands/'\n\n\nfiles = get_files(hand_path)\nfiles[:3]\n\n(#3) [Path('../../../data/score_hands/IMG_1092_swing_1_score_1.npy'),Path('../../../data/score_hands/IMG_0861_swing_0_score_3.npy'),Path('../../../data/score_hands/IMG_1015_swing_2_score_3.npy')]\n\n\n\nfiles[0].name.split('_')[-1].split('.')[0]\n\n'1'\n\n\n\ndef label_func(fpath): \n    return fpath.name.split('_')[-1].split('.')[0]\n\n\nlabel_func(files[0])\n\n'1'\n\n\n\ntotal_pool = np.arange(len(files))\ntrain_idxs = np.random.choice(total_pool, 120, replace=False)\nvalid_idxs = np.setdiff1d(total_pool, train_idxs)\nlen(train_idxs), len(valid_idxs)\n\n(120, 36)\n\n\n\ntrain_files = files[train_idxs]\nvalid_files = files[valid_idxs]\n\n\nfrom torchvision import transforms\n\ntransform_pipeline = transforms.Compose([\n    transforms.RandomHorizontalFlip(p=0.5), # Randomly flip horizontally with 50% probability\n    transforms.RandomRotation(degrees=30), # Randomly rotate by up to 30 degrees\n    transforms.Resize((224, 224)), # Resize to a common size\n    transforms.ToTensor(), # Convert PIL Image to PyTorch Tensor\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # Normalize pixel values\n])\n\n\nfrom torch.utils.data import Dataset\n\ndef label_func(fpath): \n    return fpath.name.split('_')[-1].split('.')[0]\n\nclass HandDataset(Dataset):\n    def __init__(self, \n                 file_paths,\n                 transform=None,\n                 idx=None,\n                ):\n        self.file_paths = file_paths\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.file_paths)\n\n    def __getitem__(self, idx):\n        npy_path = self.file_paths[idx]\n        npy_hands = np.load(npy_path).astype(np.float32)\n        rand_idx = np.random.randint(len(npy_hands))\n        npy_hand = npy_hands[rand_idx].transpose(2,0,1)\n        #npy_hand = npy_hands[0].transpose(2,0,1)\n        score = int(label_func(npy_path)) - 1\n        if score == 98:\n            print(npy_path)\n        return npy_hand, score\n\n\ntrain_ds = HandDataset(train_files, transform=transform_pipeline)\nvalid_ds = HandDataset(valid_files)\nlen(train_ds), len(valid_ds)\n\n(120, 36)\n\n\n\n#train_ds[0]\n\n\n# from eagle_swing.video_utils import *\n\n\n# vids = [x[0] for x in train_ds]\n# scores = [x[1] for x in train_ds]\n\n\n# idxs = [12, 15]\n# print(scores[idxs[0]: idxs[1]])\n# view_videos(vids[idxs[0]:idxs[1]])\n\n\nfrom torch.utils.data import DataLoader\n\ntrain_dataloader = DataLoader(train_ds, batch_size=16, shuffle=True)\ntest_dataloader = DataLoader(valid_ds, batch_size=8, shuffle=True)\ndls = DataLoaders(train_dataloader, test_dataloader)\n\n\nlearn = Learner(dls, xresnet50(n_out=5), \n                metrics=accuracy,\n               #loss_func=nn.CrossEntropyLoss()\n                loss_func=nn.MSELoss()\n               )\nlearn.fine_tune(base_lr=0.1, epochs=100)\n\n\n\n\n\n\n      \n      0.00% [0/1 00:00&lt;?]\n    \n    \n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n\n\n\n    \n      \n      0.00% [0/8 00:00&lt;?]\n    \n\n\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/torch/nn/modules/loss.py:616: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([16, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n  return F.mse_loss(input, target, reduction=self.reduction)\n\n\n\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\nCell In[17], line 6\n      1 learn = Learner(dls, xresnet50(n_out=5), \n      2                 metrics=accuracy,\n      3                #loss_func=nn.CrossEntropyLoss()\n      4                 loss_func=nn.MSELoss()\n      5                )\n----&gt; 6 learn.fine_tune(base_lr=0.1, epochs=100)\n\nFile ~/anaconda3/envs/fastdl/lib/python3.10/site-packages/fastai/callback/schedule.py:167, in fine_tune(self, epochs, base_lr, freeze_epochs, lr_mult, pct_start, div, **kwargs)\n    165 \"Fine tune with `Learner.freeze` for `freeze_epochs`, then with `Learner.unfreeze` for `epochs`, using discriminative LR.\"\n    166 self.freeze()\n--&gt; 167 self.fit_one_cycle(freeze_epochs, slice(base_lr), pct_start=0.99, **kwargs)\n    168 base_lr /= 2\n    169 self.unfreeze()\n\nFile ~/anaconda3/envs/fastdl/lib/python3.10/site-packages/fastai/callback/schedule.py:121, in fit_one_cycle(self, n_epoch, lr_max, div, div_final, pct_start, wd, moms, cbs, reset_opt, start_epoch)\n    118 lr_max = np.array([h['lr'] for h in self.opt.hypers])\n    119 scheds = {'lr': combined_cos(pct_start, lr_max/div, lr_max, lr_max/div_final),\n    120           'mom': combined_cos(pct_start, *(self.moms if moms is None else moms))}\n--&gt; 121 self.fit(n_epoch, cbs=ParamScheduler(scheds)+L(cbs), reset_opt=reset_opt, wd=wd, start_epoch=start_epoch)\n\nFile ~/anaconda3/envs/fastdl/lib/python3.10/site-packages/fastai/learner.py:272, in Learner.fit(self, n_epoch, lr, wd, cbs, reset_opt, start_epoch)\n    270 self.opt.set_hypers(lr=self.lr if lr is None else lr)\n    271 self.n_epoch = n_epoch\n--&gt; 272 self._with_events(self._do_fit, 'fit', CancelFitException, self._end_cleanup)\n\nFile ~/anaconda3/envs/fastdl/lib/python3.10/site-packages/fastai/learner.py:207, in Learner._with_events(self, f, event_type, ex, final)\n    206 def _with_events(self, f, event_type, ex, final=noop):\n--&gt; 207     try: self(f'before_{event_type}');  f()\n    208     except ex: self(f'after_cancel_{event_type}')\n    209     self(f'after_{event_type}');  final()\n\nFile ~/anaconda3/envs/fastdl/lib/python3.10/site-packages/fastai/learner.py:261, in Learner._do_fit(self)\n    259 for epoch in range(self.n_epoch):\n    260     self.epoch=epoch\n--&gt; 261     self._with_events(self._do_epoch, 'epoch', CancelEpochException)\n\nFile ~/anaconda3/envs/fastdl/lib/python3.10/site-packages/fastai/learner.py:207, in Learner._with_events(self, f, event_type, ex, final)\n    206 def _with_events(self, f, event_type, ex, final=noop):\n--&gt; 207     try: self(f'before_{event_type}');  f()\n    208     except ex: self(f'after_cancel_{event_type}')\n    209     self(f'after_{event_type}');  final()\n\nFile ~/anaconda3/envs/fastdl/lib/python3.10/site-packages/fastai/learner.py:255, in Learner._do_epoch(self)\n    254 def _do_epoch(self):\n--&gt; 255     self._do_epoch_train()\n    256     self._do_epoch_validate()\n\nFile ~/anaconda3/envs/fastdl/lib/python3.10/site-packages/fastai/learner.py:247, in Learner._do_epoch_train(self)\n    245 def _do_epoch_train(self):\n    246     self.dl = self.dls.train\n--&gt; 247     self._with_events(self.all_batches, 'train', CancelTrainException)\n\nFile ~/anaconda3/envs/fastdl/lib/python3.10/site-packages/fastai/learner.py:207, in Learner._with_events(self, f, event_type, ex, final)\n    206 def _with_events(self, f, event_type, ex, final=noop):\n--&gt; 207     try: self(f'before_{event_type}');  f()\n    208     except ex: self(f'after_cancel_{event_type}')\n    209     self(f'after_{event_type}');  final()\n\nFile ~/anaconda3/envs/fastdl/lib/python3.10/site-packages/fastai/learner.py:213, in Learner.all_batches(self)\n    211 def all_batches(self):\n    212     self.n_iter = len(self.dl)\n--&gt; 213     for o in enumerate(self.dl): self.one_batch(*o)\n\nFile ~/anaconda3/envs/fastdl/lib/python3.10/site-packages/fastai/learner.py:243, in Learner.one_batch(self, i, b)\n    241 b = self._set_device(b)\n    242 self._split(b)\n--&gt; 243 self._with_events(self._do_one_batch, 'batch', CancelBatchException)\n\nFile ~/anaconda3/envs/fastdl/lib/python3.10/site-packages/fastai/learner.py:207, in Learner._with_events(self, f, event_type, ex, final)\n    206 def _with_events(self, f, event_type, ex, final=noop):\n--&gt; 207     try: self(f'before_{event_type}');  f()\n    208     except ex: self(f'after_cancel_{event_type}')\n    209     self(f'after_{event_type}');  final()\n\nFile ~/anaconda3/envs/fastdl/lib/python3.10/site-packages/fastai/learner.py:227, in Learner._do_one_batch(self)\n    225 self('after_pred')\n    226 if len(self.yb):\n--&gt; 227     self.loss_grad = self.loss_func(self.pred, *self.yb)\n    228     self.loss = self.loss_grad.clone()\n    229 self('after_loss')\n\nFile ~/anaconda3/envs/fastdl/lib/python3.10/site-packages/torch/nn/modules/module.py:1773, in Module._wrapped_call_impl(self, *args, **kwargs)\n   1771     return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]\n   1772 else:\n-&gt; 1773     return self._call_impl(*args, **kwargs)\n\nFile ~/anaconda3/envs/fastdl/lib/python3.10/site-packages/torch/nn/modules/module.py:1784, in Module._call_impl(self, *args, **kwargs)\n   1779 # If we don't have any hooks, we want to skip the rest of the logic in\n   1780 # this function, and just call forward.\n   1781 if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n   1782         or _global_backward_pre_hooks or _global_backward_hooks\n   1783         or _global_forward_hooks or _global_forward_pre_hooks):\n-&gt; 1784     return forward_call(*args, **kwargs)\n   1786 result = None\n   1787 called_always_called_hooks = set()\n\nFile ~/anaconda3/envs/fastdl/lib/python3.10/site-packages/torch/nn/modules/loss.py:616, in MSELoss.forward(self, input, target)\n    615 def forward(self, input: Tensor, target: Tensor) -&gt; Tensor:\n--&gt; 616     return F.mse_loss(input, target, reduction=self.reduction)\n\nFile ~/anaconda3/envs/fastdl/lib/python3.10/site-packages/torch/nn/functional.py:3868, in mse_loss(input, target, size_average, reduce, reduction, weight)\n   3865 if size_average is not None or reduce is not None:\n   3866     reduction = _Reduction.legacy_get_string(size_average, reduce)\n-&gt; 3868 expanded_input, expanded_target = torch.broadcast_tensors(input, target)\n   3870 if weight is not None:\n   3871     if weight.size() != input.size():\n\nFile ~/anaconda3/envs/fastdl/lib/python3.10/site-packages/torch/functional.py:77, in broadcast_tensors(*tensors)\n     75 if has_torch_function(tensors):\n     76     return handle_torch_function(broadcast_tensors, tensors, *tensors)\n---&gt; 77 return _VF.broadcast_tensors(tensors)\n\nRuntimeError: The size of tensor a (5) must match the size of tensor b (16) at non-singleton dimension 1"
  },
  {
    "objectID": "posts/decision_trees/index.html",
    "href": "posts/decision_trees/index.html",
    "title": "Decision Trees",
    "section": "",
    "text": "Code\n#cleaned_df_paths =[fpath for fpath in get_files('../../../data/full_videos/ymirza/', extensions='.csv') if fpath.name=='clean_lbls.csv']\ncleaned_df_paths =[fpath for fpath in get_files('.', extensions='.csv') ]\ncleaned_df_paths\n\n\n[Path('nov16_df.csv'), Path('sep14_df.csv'), Path('oct25_df.csv')]\n\n\n\n\nCode\ndf_holder = []\nfor df_path in cleaned_df_paths:\n    df_holder.append(pd.read_csv(df_path))\ncleaned_df = pd.concat(df_holder).reset_index(drop=True)\ncleaned_df.shape\n\n\n(133, 10)\n\n\n\n\nCode\ncleaned_df.head(1)\n\n\n\n\n\n\n\n\n\nclip_name\nvideo_name\nswing_index\nscore\npkl_path\nfirst_higher_wrists_backswing_frame\nswing_day\nstart_idx\nend_idx\ntop_backswing_idx\n\n\n\n\n0\nIMG_1023_swing_0_score_1\nIMG_1023\n0\n1\n../../../data/full_videos/ymirza/aug9/IMG_1023/keypoints/IMG_1023.pkl\n1540\naug9\n1530\n1560\n1550\n\n\n\n\n\n\n\n\n\nCode\nbefore_increment = 0\nafter_increment = 30\ncleaned_df['start_idx'] = cleaned_df['top_backswing_idx'] - before_increment\ncleaned_df['end_idx'] = cleaned_df['top_backswing_idx'] + after_increment\n\n\n\n\nCode\ncleaned_df.head(1)\n\n\n\n\n\n\n\n\n\nclip_name\nvideo_name\nswing_index\nscore\npkl_path\nfirst_higher_wrists_backswing_frame\nswing_day\nstart_idx\nend_idx\ntop_backswing_idx\n\n\n\n\n0\nIMG_1023_swing_0_score_1\nIMG_1023\n0\n1\n../../../data/full_videos/ymirza/aug9/IMG_1023/keypoints/IMG_1023.pkl\n1540\naug9\n1550\n1580\n1550\n\n\n\n\n\n\n\n\n\nCode\ndef extract_xgboost_features(extractor: SwingExtractor, offset_idx_val=10):\n    \"\"\"\n    Flattens the time-series data from SwingExtractor into a single \n    dictionary of scalar features for XGBoost.\n    \"\"\"\n    feats = {}\n    \n    # --- 1. Event Detection ---\n    # Top of Backswing index (as defined in your original code)\n    top_idx = int((extractor.row.end_idx - extractor.row.start_idx) / 2)\n\n    dt=0.01\n    try:\n        # Search for peak velocity in the second half of the clip\n        downswing_vel = extractor.right_arm_angle_vel[top_idx:]\n        impact_offset = np.argmax(downswing_vel)\n        impact_idx = top_idx + impact_offset\n    except:\n        impact_idx = len(extractor.shoulder_angle_vel) - 1\n\n    # # Define the Downswing Window (Transition -&gt; Impact)\n    # ds_slice = slice(top_idx, impact_idx)\n\n    # def get_peak_idx(arr_name):\n    #     if not hasattr(extractor, arr_name): return None\n    #     arr = getattr(extractor, arr_name)\n    #     # Search only in the relevant window (approx downswing)\n    #     search_window = arr[top_idx-5 : impact_idx+5] \n    #     if len(search_window) == 0: return top_idx\n    #     return top_idx - 5 + np.argmax(search_window)\n    # # --- 1. Kinematic Sequencing (Timing Deltas) ---\n    # # Find indices of peak velocities to measure the \"Gap\"\n\n    # idx_hip_peak = get_peak_idx('hip_angle_vel')\n    # idx_shldr_peak = get_peak_idx('shoulder_angle_vel')\n    # idx_arm_peak = get_peak_idx('right_arm_angle_vel')\n\n    # # Feature: Sequence Lags (The \"Gap\")\n    # # Positive value = Proper Sequence (Hips peaked before Shoulders)\n    # if idx_hip_peak and idx_shldr_peak:\n    #     feats['seq_hip_shoulder_lag_ms'] = (idx_shldr_peak - idx_hip_peak) * dt\n    # else:\n    #     feats['seq_hip_shoulder_lag_ms'] = 0\n\n    # if idx_shldr_peak and idx_arm_peak:\n    #     feats['seq_shoulder_arm_lag_ms'] = (idx_arm_peak - idx_shldr_peak) * dt\n    # else:\n    #     feats['seq_shoulder_arm_lag_ms'] = 0\n\n    # # --- 2. Dynamic Elasticity (X-Factor Stretch) ---\n    # if hasattr(extractor, 'x_factor'):\n    #     # Look for the \"Stretch\": The max separation *after* the top\n    #     # Usually occurs early in downswing (first ~10-15 frames after top)\n    #     stretch_window = getattr(extractor, 'x_factor')[top_idx : top_idx + 15]\n        \n    #     val_at_top = getattr(extractor, 'x_factor')[top_idx]\n    #     val_max_stretch = np.max(stretch_window) if len(stretch_window) &gt; 0 else val_at_top\n        \n    #     feats['x_factor_stretch_delta'] = val_max_stretch - val_at_top\n    #     feats['x_factor_peak_timing'] = np.argmax(stretch_window) * dt  # How long after top it peaks\n\n    # # --- 3. Smoothness / Efficiency (Jerk Cost) ---\n    # # Theory: Amateurs have high jerk (noisy acceleration). Pros are smooth.\n    # # Metric: Integrated Squared Jerk over the downswing.\n    \n    # targets = ['shoulder_angle_acc', 'hip_angle_acc', 'right_arm_angle_acc']\n    \n    # for attr in targets:\n    #     if hasattr(extractor, attr):\n    #         acc_profile = getattr(extractor, attr)[ds_slice]\n            \n    #         # Calculate Jerk: derivative of acceleration\n    #         jerk_profile = np.diff(acc_profile) / dt\n            \n    #         # Integrated Squared Jerk (ISJ)\n    #         isj = np.sum(jerk_profile ** 2) * dt\n            \n    #         # Log Dimensionless Jerk (optional normalization)\n    #         # Helps compare swings of different durations\n    #         duration = (impact_idx - top_idx) * dt\n    #         if duration &gt; 0 and isj &gt; 0:\n    #             # Formula approximates: -ln( duration^3 / v_peak^2 * ISJ )\n    #             # Simplified version for features:\n    #             feats[f'{attr}_log_jerk'] = np.log(isj)\n    #         else:\n    #             feats[f'{attr}_log_jerk'] = 0\n\n    # # --- 4. Tempo Ratios ---\n    # # Backswing time vs Downswing time (Classic 3:1 ratio is ideal)\n    # backswing_frames = top_idx - extractor.row.start_idx\n    # downswing_frames = impact_idx - top_idx\n    \n    # if downswing_frames &gt; 0:\n    #     feats['tempo_ratio'] = backswing_frames / downswing_frames\n    # else:\n    #     feats['tempo_ratio'] = 0\n\n\n\n    \n    # --- 2. Peaks (Kinematic Sequence) ---\n    feats['peak_shoulder_vel'] = np.max(extractor.shoulder_angle_vel)\n    feats['peak_hip_vel'] = np.max(extractor.hip_angle_vel) if hasattr(extractor, 'hip_angle_vel') else 0\n    feats['peak_x_torque'] = np.max(extractor.x_torque)\n\n    # --- 3. Dynamic Feature Extraction (The Abstract Part) ---\n    \n    # A. Define the lists of attributes you want to sample\n    # These strings must match the attribute names in your SwingExtractor class\n    position_attrs = [\n        'x_factor', 'x_torque', \n        'right_side_bend', 'left_side_bend',\n        'right_arm_angle', 'left_arm_angle', \n        'right_leg_angle', 'left_leg_angle'\n    ]\n    \n    velocity_attrs = [\n        'shoulder_angle_vel', 'shoulder_angle_acc',\n        'hip_angle_vel', 'hip_angle_acc',\n        'right_arm_angle_vel', 'right_arm_angle_acc',\n        'x_factor_vel', 'x_factor_acc',\n        'vertical_extension_vel', 'vertical_extension_acc'\n    ]\n\n    # B. Define the offsets you care about relative to top_idx\n    # 0 = \"at_top\", 1 = \"10+_top\", -1 = \"-10_top\", etc.\n    offsets = [0, \n               1, -1,\n               #2, -2, \n               #3, -3,\n              ]# 4, -4, 5, -5, 6, -6,]\n\n    # C. Helper function to safely get values\n    def get_val(attr_name, index):\n        \"\"\"Safely retrieves value from extractor, handles bounds and missing attrs.\"\"\"\n        if not hasattr(extractor, attr_name):\n            return 0.0 # or np.nan\n        \n        arr = getattr(extractor, attr_name)\n        \n        # Boundary check to prevent index errors\n        if 0 &lt;= index &lt; len(arr):\n            return arr[index]\n        return 0.0 # Return 0 or NaN if index is out of bounds (e.g., start/end of video)\n\n    # D. Loop through attributes and offsets to generate features\n    # Combine lists so we don't have to loop twice if logic is identical\n    all_attrs = position_attrs + velocity_attrs\n    \n    for attr in all_attrs:\n        for mult in offsets:\n            # Calculate the actual index\n            current_idx = top_idx + int(mult * offset_idx_val)\n            \n            # Construct the feature name key\n            # Logic: if mult is 0, suffix is \"_at_top\"\n            # if mult is positive, suffix is \"_10+_top\" (for mult=1) or \"_20+_top\" (for mult=2)\n            # if mult is negative, suffix is \"_-10_top\", etc.\n            if mult == 0:\n                suffix = \"_at_top\"\n            elif mult &gt; 0:\n                suffix = f\"_{int(mult * offset_idx_val)}+_top\" # e.g., _10+_top, _20+_top\n            else:\n                suffix = f\"_{int(mult * offset_idx_val)}_top\"  # e.g., _-10_top, _-20_top\n            \n            feat_key = f\"{attr}{suffix}\"\n            \n            # Store value\n            feats[feat_key] = get_val(attr, current_idx)\n\n    # --- 4. Global Summary Stats ---\n    # Define stats mapping: {feature_name_prefix: (attribute, numpy_func)}\n    summary_stats = {\n        'max_x_factor': ('x_factor', np.max),\n        'max_vertical_ext': ('vertical_extension', np.max),\n        'min_vertical_ext': ('vertical_extension', np.min),\n        'max_right_arm_angle': ('right_arm_angle', np.max),\n        'max_left_arm_angle': ('left_arm_angle', np.max),\n        'max_right_leg_angle': ('right_leg_angle', np.max),\n        'max_left_leg_angle': ('left_leg_angle', np.max),\n        'max_right_side_angle': ('right_side_bend', np.max),\n        'max_left_side_angle': ('left_side_bend', np.max),\n        'shoulder_acc_std': ('shoulder_angle_acc', np.std)\n    }\n\n    for name, (attr, func) in summary_stats.items():\n        if hasattr(extractor, attr):\n            feats[name] = func(getattr(extractor, attr))\n        else:\n            feats[name] = 0\n\n    return feats\n\n\n\n\nCode\n# def extract_xgboost_features(extractor: SwingExtractor,\n#                             offset_idx_val=10):\n#     \"\"\"\n#     Flattens the time-series data from SwingExtractor into a single \n#     dictionary of scalar features for XGBoost.\n#     \"\"\"\n#     feats = {}\n    \n#     # 1. Dynamic Event Detection (Crucial for alignment)\n#     # We assume 'Top of Backswing' is where shoulder rotation (or X-Factor) is max\n#     # We assume 'Impact' is roughly where hips return to square (0 deg) or max speed occurs\n    \n#     # Find index of max shoulder rotation (approx Top of Backswing)\n#     # Using shoulder angle or X-factor usually works best\n#     #top_idx = np.argmax(extractor.shoulder_angle)\n#     #top_idx = np.argmin(extractor.kps.l_wrist[:, 1] + extractor.kps.r_wrist[:, 1])\n#     #top_idx = np.argmax(extractor.max_torque_idx[10:]) + 10\n#     top_idx = int((extractor.row.end_idx - extractor.row.start_idx) / 2)\n    \n    \n#     # Find max rotational velocities (Kinematic Sequence Peaks)\n#     # We use the _vel attributes you created with add_derivatives\n#     feats['peak_shoulder_vel'] = np.max(extractor.shoulder_angle_vel)\n#     feats['peak_hip_vel'] = np.max(extractor.hip_angle_vel) if hasattr(extractor, 'hip_angle_vel') else 0\n#     feats['peak_x_torque'] = np.max(extractor.x_torque) # Max stretch speed\n    \n\n#     # 2. Value at Specific Events (The \"State\" of the golfer)\n#     # What is the X-Factor at the top?\n#     feats['x_factor_at_top'] = extractor.x_factor[top_idx]\n#     feats['x_torque_at_top'] = extractor.x_torque[top_idx]\n#     feats['right_side_bend_at_top'] = extractor.right_side_bend[top_idx]\n#     feats['left_side_bend_at_top'] = extractor.left_side_bend[top_idx]\n#     feats['right_arm_angle_at_top'] = extractor.right_arm_angle[top_idx]\n#     feats['left_arm_angle_at_top'] = extractor.left_arm_angle[top_idx]\n#     feats['right_leg_angle_at_top'] = extractor.right_leg_angle[top_idx]\n#     feats['left_leg_angle_at_top'] = extractor.left_leg_angle[top_idx]\n\n#     # What is the X-Factor 10 frames from the top?\n#     feats['x_factor_10+_top'] = extractor.x_factor[top_idx + offset_idx_val]\n#     feats['x_torque_10+_top'] = extractor.x_torque[top_idx + offset_idx_val]\n#     feats['right_side_bend_10+_top'] = extractor.right_side_bend[top_idx + offset_idx_val]\n#     feats['left_side_bend_10+_top'] = extractor.left_side_bend[top_idx + offset_idx_val]\n#     feats['right_arm_angle_10+_top'] = extractor.right_arm_angle[top_idx + offset_idx_val]\n#     feats['left_arm_angle_10+_top'] = extractor.left_arm_angle[top_idx + offset_idx_val]\n#     feats['right_leg_angle_10+_top'] = extractor.right_leg_angle[top_idx + offset_idx_val]\n#     feats['left_leg_angle_10+_top'] = extractor.left_leg_angle[top_idx + offset_idx_val]\n    \n#     # 10 frames before the top\n#     feats['x_factor_-10_top'] = extractor.x_factor[top_idx - offset_idx_val]\n#     feats['x_torque_-10_top'] = extractor.x_torque[top_idx - offset_idx_val]\n#     feats['right_side_bend_-10_top'] = extractor.right_side_bend[top_idx - offset_idx_val]\n#     feats['left_side_bend_-10_top'] = extractor.left_side_bend[top_idx - offset_idx_val]\n#     feats['right_arm_angle_-10_top'] = extractor.right_arm_angle[top_idx - offset_idx_val]\n#     feats['left_arm_angle_-10_top'] = extractor.left_arm_angle[top_idx - offset_idx_val]\n#     feats['right_leg_angle_-10_top'] = extractor.right_leg_angle[top_idx - offset_idx_val]\n#     feats['left_leg_angle_-10_top'] = extractor.left_leg_angle[top_idx - offset_idx_val]\n\n\n#     # ## 20 frames around\n#     # # What is the X-Factor 20 frames from the top?\n#     # feats['x_factor_20+_top'] = extractor.x_factor[top_idx + int(2 * offset_idx_val)]\n#     # feats['x_torque_20+_top'] = extractor.x_torque[top_idx + int(2 * offset_idx_val)]\n#     # feats['right_side_bend_20+_top'] = extractor.right_side_bend[top_idx + int(2 * offset_idx_val)]\n#     # feats['left_side_bend_20+_top'] = extractor.left_side_bend[top_idx + int(2 * offset_idx_val)]\n#     # feats['right_arm_angle_20+_top'] = extractor.right_arm_angle[top_idx + int(2 * offset_idx_val)]\n#     # feats['left_arm_angle_20+_top'] = extractor.left_arm_angle[top_idx + int(2 * offset_idx_val)]\n#     # feats['right_leg_angle_20+_top'] = extractor.right_leg_angle[top_idx + int(2 * offset_idx_val)]\n#     # feats['left_leg_angle_20+_top'] = extractor.left_leg_angle[top_idx + int(2 * offset_idx_val)]\n    \n#     # # 20 frames before the top\n#     # feats['x_factor_-20_top'] = extractor.x_factor[top_idx - int(2 * offset_idx_val)]\n#     # feats['x_torque_-20_top'] = extractor.x_torque[top_idx - int(2 * offset_idx_val)]\n#     # feats['right_side_bend_-20_top'] = extractor.right_side_bend[top_idx - int(2 * offset_idx_val)]\n#     # feats['left_side_bend_-20_top'] = extractor.left_side_bend[top_idx - int(2 * offset_idx_val)]\n#     # feats['right_arm_angle_-20_top'] = extractor.right_arm_angle[top_idx - int(2 * offset_idx_val)]\n#     # feats['left_arm_angle_-20_top'] = extractor.left_arm_angle[top_idx - int(2 * offset_idx_val)]\n#     # feats['right_leg_angle_-20_top'] = extractor.right_leg_angle[top_idx - int(2 * offset_idx_val)]\n#     # feats['left_leg_angle_-20_top'] = extractor.left_leg_angle[top_idx - int(2 * offset_idx_val)]\n    \n\n#     ## 30 frames around\n#     # What is the X-Factor 30 frames from the top?\n#     feats['x_factor_30+_top'] = extractor.x_factor[top_idx + int(3 * offset_idx_val)]\n#     feats['x_torque_30+_top'] = extractor.x_torque[top_idx + int(3 * offset_idx_val)]\n#     feats['right_side_bend_30+_top'] = extractor.right_side_bend[top_idx + int(3 * offset_idx_val)]\n#     feats['left_side_bend_30+_top'] = extractor.left_side_bend[top_idx + int(3 * offset_idx_val)]\n#     feats['right_arm_angle_30+_top'] = extractor.right_arm_angle[top_idx + int(3 * offset_idx_val)]\n#     feats['left_arm_angle_30+_top'] = extractor.left_arm_angle[top_idx + int(3 * offset_idx_val)]\n#     feats['right_leg_angle_30+_top'] = extractor.right_leg_angle[top_idx + int(3 * offset_idx_val)]\n#     feats['left_leg_angle_30+_top'] = extractor.left_leg_angle[top_idx + int(3 * offset_idx_val)]\n    \n#     # 30 frames before the top\n#     feats['x_factor_-30_top'] = extractor.x_factor[top_idx - int(3 * offset_idx_val)]\n#     feats['x_torque_-30_top'] = extractor.x_torque[top_idx - int(3 * offset_idx_val)]\n#     feats['right_side_bend_-30_top'] = extractor.right_side_bend[top_idx - int(3 * offset_idx_val)]\n#     feats['left_side_bend_-30_top'] = extractor.left_side_bend[top_idx - int(3 * offset_idx_val)]\n#     feats['right_arm_angle_-30_top'] = extractor.right_arm_angle[top_idx - int(3 * offset_idx_val)]\n#     feats['left_arm_angle_-30_top'] = extractor.left_arm_angle[top_idx - int(3 * offset_idx_val)]\n#     feats['right_leg_angle_-30_top'] = extractor.right_leg_angle[top_idx - int(3 * offset_idx_val)]\n#     feats['left_leg_angle_-30_top'] = extractor.left_leg_angle[top_idx - int(3 * offset_idx_val)]\n    \n\n#     # Find the angle changes at the index\n#     feats['shoulder_angle_vel_at_top'] = extractor.shoulder_angle_vel[top_idx]\n#     feats['shoulder_angle_acc_at_top'] = extractor.shoulder_angle_acc[top_idx]\n#     feats['hip_angle_vel_at_top'] = extractor.hip_angle_vel[top_idx]\n#     feats['hip_angle_acc_at_top'] = extractor.hip_angle_acc[top_idx]\n#     feats['right_arm_angle_vel_at_top'] = extractor.right_arm_angle_vel[top_idx]\n#     feats['right_arm_angle_acc_at_top'] = extractor.hip_angle_acc[top_idx]\n#     feats['x_factor_vel_at_top'] = extractor.x_factor_vel[top_idx]\n#     feats['x_factor_acc_at_top'] = extractor.x_factor_acc[top_idx]\n#     feats['vertical_extension_vel_at_top'] = extractor.vertical_extension_vel[top_idx]\n#     feats['vertical_extension_acc_at_top'] = extractor.vertical_extension_acc[top_idx]\n\n#     feats['shoulder_angle_vel_10+_top'] = extractor.shoulder_angle_vel[top_idx + offset_idx_val]\n#     feats['shoulder_angle_acc_10+_top'] = extractor.shoulder_angle_acc[top_idx + offset_idx_val]\n#     feats['hip_angle_vel_10+_top'] = extractor.hip_angle_vel[top_idx + offset_idx_val]\n#     feats['hip_angle_acc_10+_top'] = extractor.hip_angle_acc[top_idx + offset_idx_val]\n#     feats['right_arm_angle_vel_10+_top'] = extractor.right_arm_angle_vel[top_idx + offset_idx_val]\n#     feats['right_arm_angle_acc_10+_top'] = extractor.hip_angle_acc[top_idx + offset_idx_val]\n#     feats['x_factor_vel_10+_top'] = extractor.x_factor_vel[top_idx + offset_idx_val]\n#     feats['x_factor_acc_10+_top'] = extractor.x_factor_acc[top_idx + offset_idx_val]\n#     feats['vertical_extension_vel_10+_top'] = extractor.vertical_extension_vel[top_idx + offset_idx_val]\n#     feats['vertical_extension_acc_10+_top'] = extractor.vertical_extension_acc[top_idx + offset_idx_val]\n\n#     feats['shoulder_angle_vel_-10_top'] = extractor.shoulder_angle_vel[top_idx - offset_idx_val]\n#     feats['shoulder_angle_acc_-10_top'] = extractor.shoulder_angle_acc[top_idx - offset_idx_val]\n#     feats['hip_angle_vel_-10_top'] = extractor.hip_angle_vel[top_idx - offset_idx_val]\n#     feats['hip_angle_acc_-10_top'] = extractor.hip_angle_acc[top_idx - offset_idx_val]\n#     feats['right_arm_angle_vel_-10_top'] = extractor.right_arm_angle_vel[top_idx - offset_idx_val]\n#     feats['right_arm_angle_acc_-10_top'] = extractor.hip_angle_acc[top_idx - offset_idx_val]\n#     feats['x_factor_vel_-10_top'] = extractor.x_factor_vel[top_idx - offset_idx_val]\n#     feats['x_factor_acc_-10_top'] = extractor.x_factor_acc[top_idx - offset_idx_val]\n#     feats['vertical_extension_vel_-10_top'] = extractor.vertical_extension_vel[top_idx - offset_idx_val]\n#     feats['vertical_extension_acc_-10_top'] = extractor.vertical_extension_acc[top_idx - offset_idx_val]\n\n\n#     # ### 20 frames around....\n#     # feats['shoulder_angle_acc_20+_top'] = extractor.shoulder_angle_acc[top_idx + int(2* offset_idx_val)]\n#     # feats['hip_angle_vel_20+_top'] = extractor.hip_angle_vel[top_idx + int(2* offset_idx_val)]\n#     # feats['hip_angle_acc_20+_top'] = extractor.hip_angle_acc[top_idx + int(2* offset_idx_val)]\n#     # feats['right_arm_angle_vel_20+_top'] = extractor.right_arm_angle_vel[top_idx + int(2* offset_idx_val)]\n#     # feats['right_arm_angle_acc_20+_top'] = extractor.hip_angle_acc[top_idx + int(2* offset_idx_val)]\n#     # feats['x_factor_vel_20+_top'] = extractor.x_factor_vel[top_idx + int(2* offset_idx_val)]\n#     # feats['x_factor_acc_20+_top'] = extractor.x_factor_acc[top_idx + int(2* offset_idx_val)]\n#     # feats['vertical_extension_vel_20+_top'] = extractor.vertical_extension_vel[top_idx + int(2* offset_idx_val)]\n#     # feats['vertical_extension_acc_20+_top'] = extractor.vertical_extension_acc[top_idx + int(2* offset_idx_val)]\n\n#     # feats['shoulder_angle_vel_-20_top'] = extractor.shoulder_angle_vel[top_idx - int(2* offset_idx_val)]\n#     # feats['shoulder_angle_acc_-20_top'] = extractor.shoulder_angle_acc[top_idx - int(2* offset_idx_val)]\n#     # feats['hip_angle_vel_-20_top'] = extractor.hip_angle_vel[top_idx - int(2* offset_idx_val)]\n#     # feats['hip_angle_acc_-20_top'] = extractor.hip_angle_acc[top_idx - int(2* offset_idx_val)]\n#     # feats['right_arm_angle_vel_-20_top'] = extractor.right_arm_angle_vel[top_idx - int(2* offset_idx_val)]\n#     # feats['right_arm_angle_acc_-20_top'] = extractor.hip_angle_acc[top_idx - int(2* offset_idx_val)]\n#     # feats['x_factor_vel_-20_top'] = extractor.x_factor_vel[top_idx - int(2* offset_idx_val)]\n#     # feats['x_factor_acc_-20_top'] = extractor.x_factor_acc[top_idx - int(2* offset_idx_val)]\n#     # feats['vertical_extension_vel_-20_top'] = extractor.vertical_extension_vel[top_idx - int(2* offset_idx_val)]\n#     # feats['vertical_extension_acc_-20_top'] = extractor.vertical_extension_acc[top_idx - int(2* offset_idx_val)]\n\n#     ### 30 frames around....\n#     feats['shoulder_angle_acc_30+_top'] = extractor.shoulder_angle_acc[top_idx + int(3* offset_idx_val)]\n#     feats['hip_angle_vel_30+_top'] = extractor.hip_angle_vel[top_idx + int(3* offset_idx_val)]\n#     feats['hip_angle_acc_30+_top'] = extractor.hip_angle_acc[top_idx + int(3* offset_idx_val)]\n#     feats['right_arm_angle_vel_30+_top'] = extractor.right_arm_angle_vel[top_idx + int(3* offset_idx_val)]\n#     feats['right_arm_angle_acc_30+_top'] = extractor.hip_angle_acc[top_idx + int(3* offset_idx_val)]\n#     feats['x_factor_vel_30+_top'] = extractor.x_factor_vel[top_idx + int(3* offset_idx_val)]\n#     feats['x_factor_acc_30+_top'] = extractor.x_factor_acc[top_idx + int(3* offset_idx_val)]\n#     feats['vertical_extension_vel_30+_top'] = extractor.vertical_extension_vel[top_idx + int(3* offset_idx_val)]\n#     feats['vertical_extension_acc_30+_top'] = extractor.vertical_extension_acc[top_idx + int(3* offset_idx_val)]\n\n#     feats['shoulder_angle_vel_-30_top'] = extractor.shoulder_angle_vel[top_idx - int(3 * offset_idx_val)]\n#     feats['shoulder_angle_acc_-30_top'] = extractor.shoulder_angle_acc[top_idx - int(3 * offset_idx_val)]\n#     feats['hip_angle_vel_-30_top'] = extractor.hip_angle_vel[top_idx - int(3 * offset_idx_val)]\n#     feats['hip_angle_acc_-30_top'] = extractor.hip_angle_acc[top_idx - int(3 * offset_idx_val)]\n#     feats['right_arm_angle_vel_-30_top'] = extractor.right_arm_angle_vel[top_idx - int(3 * offset_idx_val)]\n#     feats['right_arm_angle_acc_-30_top'] = extractor.hip_angle_acc[top_idx - int(3 * offset_idx_val)]\n#     feats['x_factor_vel_-30_top'] = extractor.x_factor_vel[top_idx - int(3 * offset_idx_val)]\n#     feats['x_factor_acc_-30_top'] = extractor.x_factor_acc[top_idx - int(3 * offset_idx_val)]\n#     feats['vertical_extension_vel_-30_top'] = extractor.vertical_extension_vel[top_idx - int(3 * offset_idx_val)]\n#     feats['vertical_extension_acc_-30_top'] = extractor.vertical_extension_acc[top_idx - int(3 * offset_idx_val)]\n                                \n    \n#     # 3. Global Summary Stats (Min/Max/Range)\n#     feats['max_x_factor'] = np.max(extractor.x_factor)\n#     feats['max_vertical_ext'] = np.max(extractor.vertical_extension)\n#     feats['min_vertical_ext'] = np.min(extractor.vertical_extension) # Squat before jump\n    \n#     feats['max_right_arm_angle'] = np.max(extractor.right_arm_angle)\n#     feats['max_left_arm_angle'] = np.max(extractor.left_arm_angle)\n#     feats['max_right_leg_angle'] = np.max(extractor.right_leg_angle)\n#     feats['max_left_leg_angle'] = np.max(extractor.left_leg_angle)\n#     feats['max_right_side_angle'] = np.max(extractor.right_side_bend)\n#     feats['max_left_side_angle'] = np.max(extractor.left_side_bend)\n    \n#     # 4. Consistency/Smoothness Metrics\n#     # Standard deviation of acceleration represents \"jerk\" or inefficiency\n#     feats['shoulder_acc_std'] = np.std(extractor.shoulder_angle_acc)\n    \n#     return feats\n\n\n\n\nCode\ndef process_batch_swings(df_input: pd.DataFrame,\n                        offset_idx_val=10):\n    \"\"\"\n    Transforms a dataframe of video metadata into an XGBoost-ready feature matrix.\n    \"\"\"\n    feature_rows = []\n    failed_indices = []\n\n    # Iterate over the raw dataframe (30 rows)\n    for idx, row in tqdm(df_input.iterrows(), total=len(df_input), desc=\"Extracting Features\"):\n        try:\n            # 1. Instantiate the Extractor\n            # This runs __init__, loads KPs, normalizes, and computes derivatives\n            extractor = SwingExtractor(row, normalizer=True)\n            \n            # 2. Flatten Time-Series to Scalar Features\n            # (Using the helper function defined in the previous turn)\n            feats = extract_xgboost_features(extractor, offset_idx_val)\n\n            \n            # 4. Add ID for debugging\n            feats['clip_name'] = row.clip_name\n            feats['swing_day'] = row.swing_day\n            \n            feature_rows.append(feats)\n            \n        except Exception as e:\n            print(f\"âš ï¸ Failed on row {idx} ({row.get('clip_name', 'Unknown')}): {e}\")\n            failed_indices.append(idx)\n\n    # 5. Create the final Feature DataFrame\n    # This is much faster than appending to a DF inside the loop\n    df_features = pd.DataFrame(feature_rows)\n    \n    return df_features, failed_indices\n\n\n\n\nCode\n# --- Execution ---\n# Assuming 'df_raw' is your starting dataframe with 30 rows\ndf_ready, failures = process_batch_swings(cleaned_df, offset_idx_val=10)\n\nprint(f\"Successfully processed {len(df_ready)} swings.\")\n#print(df_ready.head())\n\n\nExtracting Features: 100%|â–ˆâ–ˆâ–ˆâ–ˆ| 133/133 [01:31&lt;00:00,  1.45it/s]\n\n\nSuccessfully processed 133 swings.\n\n\n\n\n\n\n\nCode\n#df_ready.to_csv('test_df.csv', index=False)\n#df_ready = pd.read_csv('test_df.csv').reset_index(drop=True)\ndf_ready.shape\n\n\n(133, 69)\n\n\n\n\nCode\ndef get_train_test_split(df_ready, random_split=False, test_day='sep14',):\n    df_ready['score'] = df_ready.clip_name.map(lambda x: int(x.split('_')[-1]) - 1)\n    df_ready = df_ready[df_ready.score != 98].reset_index(drop=True)\n    \n    drop_cols = [\n                'clip_name', \n                'score',\n                'swing_day'\n                ]\n    feature_cols = [c for c in df_ready.columns if c not in drop_cols]\n    cols_to_fix = [c for c in df_ready.columns if c != 'clip_name']\n    \n    test_day = test_day\n    train_rows = (df_ready.swing_day != test_day).values\n    valid_rows = (df_ready.swing_day == test_day).values\n    \n    \n    for col in cols_to_fix:\n        # This handles the \"array([5.2])\" issue by extracting the scalar\n        df_ready[col] = df_ready[col].apply(lambda x: x.item() if isinstance(x, np.ndarray) else x)    \n        # This converts strings/objects to float, setting errors='coerce' to turn bad data into NaN\n        df_ready[col] = pd.to_numeric(df_ready[col], errors='coerce')\n\n    if random_split:\n        train_x, test_x, train_y, test_y = get_random_split(df_ready, test_size=0.2)\n    else:\n        train_df = df_ready.loc[train_rows]\n        test_df = df_ready.loc[valid_rows]\n        train_x = train_df.drop(columns=['clip_name', 'score', 'swing_day']).reset_index(drop=True)\n        test_x = test_df.drop(columns=['clip_name', 'score', 'swing_day']).reset_index(drop=True)\n        train_y = train_df['score'].reset_index(drop=True)\n        test_y = test_df['score'].reset_index(drop=True)\n    return train_x, test_x, train_y, test_y\n\n\n\n\nCode\ndef get_swingday_split(df, test_day=None):\n    if test_day is None:\n        test_day = df.swing_day[0]\n    train_rows = (final.swing_day != test_day).values\n    valid_rows = (df.swing_day == test_day).values\n    train_df = df.loc[train_rows]\n    test_df = df.loc[valid_rows]\n    train_x = train_df.drop(columns=['clip_name', 'score', 'swing_day'])\n    test_x = test_df.drop(columns=['clip_name', 'score', 'swing_day'])\n    train_y = train_df['score']\n    test_y = test_df['score']\n    return train_x, test_x, train_y, test_y\n\ndef get_random_split(df, test_size=0.2, random_state=42):\n    X = df.drop(columns=['clip_name', 'score', 'swing_day'])\n    y = df['score']\n    train_x, test_x, train_y, test_y = train_test_split(X, y, test_size=0.2, random_state=42)\n    return train_x, test_x, train_y, test_y\n\n\n\n\nCode\ndef get_stats(model, x_data, y_data, training=True):\n    y_pred = model.predict(x_data)\n    y_pred = np.clip(y_pred, 1, 5)\n    mae = mean_absolute_error(y_data, y_pred)\n    r2 = r2_score(y_data, y_pred)\n    if training:\n        data_type = 'Training'\n    else: data_type = 'Validation'\n    print(f\"XGBoost Model Performance -- {data_type} Set:\")\n    print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n    print(f\"R-squared Score (R2):      {r2:.4f}\")\n\n\ndef plot_feature_importance(model, x_data, y_data, max_num_features=20):\n    xgb.plot_importance(model, max_num_features=max_num_features)\n    plt.title(f\"Top {max_num_features} Features Driving Golf Score\")\n    plt.tight_layout() \n    plt.show()\n\n\n\n\nCode\ndef run_xgb(x_train,\n            y_train,\n            x_valid,\n            y_valid,\n            training_summary_plots=True,\n            regression=True,\n            objective='reg:squarederror',\n            n_estimators=1000,           # Increased: Lower learning rate requires more trees\n            learning_rate=0.25,          # Reduced significantly: Prevents rapid overfitting\n            max_depth=3,                 # Reduced: 2-3 is ideal for small data to force simple logic\n            min_child_weight=4,          # Critical: Requires ~4 samples to create a leaf (reduces noise)\n            gamma=0.2,                   # Conservative: Minimum loss reduction required to make a split\n            subsample=0.7,               # Randomness: Use only 70% of rows per tree\n            colsample_bytree=0.7,        # Randomness: Use only 70% of features per tree\n            reg_lambda=1.0,              # L2 Regularization (default is 1, maybe increase to 2-3 if needed)\n            early_stopping_rounds=50,    # Stop if validation score doesn't improve\n            random_state=42\n            ):\n    xgb_model = xgb.XGBRegressor(\n                            objective=objective,\n                            n_estimators=n_estimators,    \n                            learning_rate=learning_rate,  \n                            max_depth=max_depth,              \n                            min_child_weight=min_child_weight,\n                            gamma=gamma,                   \n                            subsample=subsample,              \n                            colsample_bytree=colsample_bytree,\n                            reg_lambda=reg_lambda,              \n                            early_stopping_rounds=early_stopping_rounds,    \n                            random_state=random_state,)\n    xgb_model.fit(\n                x_train, y_train,\n                eval_set=[(x_valid, y_valid)],\n                verbose=False\n                )\n    \n    get_stats(xgb_model, x_train, y_train, training=True)\n\n    get_stats(xgb_model, x_valid, y_valid, training=False)\n\n    explainer = shap.TreeExplainer(xgb_model)\n    plt.figure()\n                \n    if training_summary_plots:\n        plt.title(\"SHAP Summary Plot -- XGBoost -- Training Set\")\n        shap_values = explainer(x_train)\n        shap.summary_plot(shap_values, x_train, show=False)\n        plot_feature_importance(xgb_model, x_train, y_train)\n    else:\n        plt.title(\"SHAP Summary Plot -- XGBoost -- Validation Set\")\n        shap_values = explainer(x_test)\n        shap.summary_plot(shap_values, x_test, show=False)\n        plot_feature_importance(xgb_model, x_valid, y_valid)\n    \n    plt.show()\n\n\n\n\nCode\ndf_ready.head(1)\n\n\n\n\n\n\n\n\n\npeak_shoulder_vel\npeak_hip_vel\npeak_x_torque\nx_factor_at_top\nx_factor_10+_top\nx_factor_-10_top\nx_torque_at_top\nx_torque_10+_top\nx_torque_-10_top\nright_side_bend_at_top\n...\nmin_vertical_ext\nmax_right_arm_angle\nmax_left_arm_angle\nmax_right_leg_angle\nmax_left_leg_angle\nmax_right_side_angle\nmax_left_side_angle\nshoulder_acc_std\nclip_name\nswing_day\n\n\n\n\n0\n1.062188\n3.838415\n6.373439\n4.23186\n10.889758\n10.601812\n-2.471613\n4.238002\n-1.609466\n391.073418\n...\n0.841479\n155.697695\n179.676236\n-138.967705\n-133.330083\n406.743114\n521.148424\n2.217134\nIMG_1023_swing_0_score_1\naug9\n\n\n\n\n1 rows Ã— 69 columns\n\n\n\n\n\nCode\ntrain_x, test_x, train_y, test_y = get_train_test_split(df_ready, random_split=True)\n#train_x, test_x, train_y, test_y = get_train_test_split(df_ready, random_split=False)\n\n\n\n\nCode\nrun_xgb(train_x, \n        train_y, \n        test_x,\n        test_y,\n        n_estimators=1000,           # Lower learning rate requires more trees\n        learning_rate=0.09,          # Lower --&gt; Prevents rapid overfitting\n        max_depth=3,                 # 2-3 is ideal for small data to force simple logic\n        min_child_weight=5,          # Critical: Requires ~5 samples to create a leaf (reduces noise)\n        gamma=0.2,                   # Conservative: Minimum loss reduction required to make a split\n        subsample=0.9,               # Randomness: Use only 70% of rows per tree\n        colsample_bytree=0.9,        # Randomness: Use only 70% of features per tree\n        #reg_lambda=1.0,              # L2 Regularization (default is 1, maybe increase to 2-3 if needed)\n        early_stopping_rounds=50,    # Stop if validation score doesn't improve\n        random_state=42)\n\n\nXGBoost Model Performance -- Training Set:\nMean Absolute Error (MAE): 0.3333\nR-squared Score (R2):      0.8677\nXGBoost Model Performance -- Validation Set:\nMean Absolute Error (MAE): 1.0760\nR-squared Score (R2):      0.2780\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# # 1. Initialize (Note: No learning_rate in RF)\n#rf_model = RandomForestClassifier(\nrf_model = RandomForestRegressor(\n    n_estimators=500,\n    max_depth=5,             # very shallow\n    min_samples_leaf=3,      # each leaf has at least 5 swings\n    max_features=\"sqrt\",     # or even a small int\n    random_state=0,\n    n_jobs=-1,\n    oob_score=True\n)\n\n# 2. Fit (Same syntax)\nrf_model.fit(train_x, train_y)\n\n\nRandomForestRegressor(max_depth=5, max_features='sqrt', min_samples_leaf=3,\n                      n_estimators=500, n_jobs=-1, oob_score=True,\n                      random_state=0)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.RandomForestRegressor?Documentation for RandomForestRegressoriFitted\n        \n            \n                Parameters\n                \n\n\n\n\nn_estimatorsÂ \n500\n\n\n\ncriterionÂ \n'squared_error'\n\n\n\nmax_depthÂ \n5\n\n\n\nmin_samples_splitÂ \n2\n\n\n\nmin_samples_leafÂ \n3\n\n\n\nmin_weight_fraction_leafÂ \n0.0\n\n\n\nmax_featuresÂ \n'sqrt'\n\n\n\nmax_leaf_nodesÂ \nNone\n\n\n\nmin_impurity_decreaseÂ \n0.0\n\n\n\nbootstrapÂ \nTrue\n\n\n\noob_scoreÂ \nTrue\n\n\n\nn_jobsÂ \n-1\n\n\n\nrandom_stateÂ \n0\n\n\n\nverboseÂ \n0\n\n\n\nwarm_startÂ \nFalse\n\n\n\nccp_alphaÂ \n0.0\n\n\n\nmax_samplesÂ \nNone\n\n\n\nmonotonic_cstÂ \nNone\n\n\n\n\n            \n        \n    \n\n\n\n\nCode\n# def train_rf(n_estimators=500, \n#              max_depth=8, \n#              min_samples_leaf=10,\n#              max_samples=0.7,\n#              max_features='sqrt',\n#             ):\n#     rf_model = RandomForestRegressor(\n#         n_estimators=n_estimators,\n#         max_depth=max_depth,   # RFs often grow full trees by default\n#         min_samples_leaf=min_samples_leaf,\n#         max_features=max_features, # Crucial hyperparameter for RF\n#         random_state=42\n#     )\n#     # 2. Fit (Same syntax)\n#     rf_model.fit(X_train, y_train)\n#     y_pred = rf_model.predict(X_test)\n    \n#     mae = mean_absolute_error(y_test, y_pred)\n#     r2 = r2_score(y_test, y_pred)\n#     return mae, r2\n\n\n\n\nCode\n# import itertools\n# from sklearn.ensemble import RandomForestRegressor\n# from sklearn.metrics import mean_absolute_error, r2_score\n\n# # 1. Define your lists of parameters to test\n# n_estimators_list = [50, 100, 200, 500]\n# max_depth_list = [4, 8, 12, 20, None]  # 'None' lets it grow forever (careful!)\n# min_samples_leaf_list = [1, 5, 10, 20]\n\n# results = []\n\n# print(f\"Starting training on {len(n_estimators_list) * len(max_depth_list) * len(min_samples_leaf_list)} combinations...\")\n\n# # itertools.product creates a cartesian product of input iterables\n# for n_est, depth, min_samples in itertools.product(n_estimators_list, max_depth_list, min_samples_leaf_list):\n    \n#     # Run your training function\n#     # Note: Ensure X_train, y_train, etc., are defined in your environment before running this\n#     mae, r2 = train_rf(n_est, depth, min_samples)\n    \n#     # Print progress (optional)\n#     #print(f\"Params: [n={n_est}, depth={depth}, leaf={min_samples}] -&gt; MAE: {mae:.4f}, R2: {r2:.4f}\")\n    \n#     # Save result\n#     results.append({\n#         'n_estimators': n_est,\n#         'max_depth': depth,\n#         'min_samples_leaf': min_samples,\n#         'MAE': mae,\n#         'R2': r2\n#     })\n\n# # 4. Convert to DataFrame for analysis\n# results_df = pd.DataFrame(results)\n\n# # 5. Sort by Best Performance (Lowest MAE or Highest R2)\n# best_results = results_df.sort_values(by='R2', ascending=False)\n\n# print(\"\\nTop 5 Parameter Combinations:\")\n# print(best_results.head(5))\n\n\n\n\nCode\nfeature_cols = [c for c in df_ready.columns]\n\nresult = permutation_importance(\n    rf_model, test_x, test_y, \n    n_repeats=10, \n    random_state=42, \n    n_jobs=-1\n)\n\n# Sort indices by mean importance\nsorted_idx = result.importances_mean.argsort()[-20:] # Top 20\n\nplt.boxplot(\n    result.importances[sorted_idx].T,\n    vert=False, \n    tick_labels=np.array(feature_cols)[sorted_idx]\n)\nplt.title(\"Permutation Importances (Test Set)\")\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\n#Validation set\ny_pred = rf_model.predict(test_x)\n\nmae = mean_absolute_error(test_y, y_pred)\nr2 = r2_score(test_y, y_pred)\nprint(\"Model Performance -- Test Set:\")\nprint(f\"Mean Absolute Error (MAE): {mae:.4f}\")\nprint(f\"R-squared Score (R2):      {r2:.4f}\")\n\n#Train Results\ny_pred = rf_model.predict(train_x)\nmae = mean_absolute_error(train_y, y_pred)\nr2 = r2_score(train_y, y_pred)\n\nprint(\"Model Performance -- Training Set:\")\nprint(f\"Mean Absolute Error (MAE): {mae:.4f}\")\nprint(f\"R-squared Score (R2):      {r2:.4f}\")\n\n# 5. SHAP Visualization\n# Initialize the TreeExplainer (optimized for Random Forests)\nexplainer = shap.TreeExplainer(rf_model)\n\n# Calculate SHAP values for the test set\n# Note: If your dataset is very large, you can pass a sample (e.g., X_test.sample(100)) to speed this up\n#shap_values = explainer(X_test)\nshap_values = explainer(train_x)\n\n# Create the summary plot (Beeswarm plot)\nplt.figure()\nplt.title(\"SHAP Summary Plot (Feature Importance) --&gt; training set\")\nshap.summary_plot(shap_values, train_x, show=False)\nplt.show()\n\n\nModel Performance -- Test Set:\nMean Absolute Error (MAE): 1.2274\nR-squared Score (R2):      0.0878\nModel Performance -- Training Set:\nMean Absolute Error (MAE): 0.7403\nR-squared Score (R2):      0.6106\n\n\n\n\n\n\n\n\n\n\n\nCode\nshap_values = explainer(test_x)\n\n# Create the summary plot (Beeswarm plot)\nplt.figure()\nplt.title(\"SHAP Summary Plot (Feature Importance)- validation set\")\nshap.summary_plot(shap_values, test_x, show=False)\n#shap.summary_plot(shap_values, X_train, show=False)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\nimport numpy as np\nimport pandas as pd\nfrom sklearn.linear_model import ElasticNetCV, ElasticNet\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_absolute_error, r2_score\n\n# IMPORTANT: ElasticNet requires feature scaling (RF doesn't)\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(train_x)\nX_test_scaled = scaler.transform(test_x)\n\n# ElasticNetCV automatically tunes alpha (regularization strength) and l1_ratio\n# l1_ratio: 0 = Ridge (L2), 1 = Lasso (L1), 0.5 = balanced ElasticNet\nelastic_cv = ElasticNetCV(\n    l1_ratio=[0.1, 0.5, 0.7, 0.9, 0.95, 0.99, 1.0],  # Mix of L1/L2\n    alphas=np.logspace(-4, 1, 50),                    # Regularization strengths\n    cv=5,                                             # 5-fold cross-validation\n    max_iter=10000,\n    random_state=42,\n    n_jobs=-1\n)\n\n# Fit the model\nelastic_cv.fit(X_train_scaled, train_y)\n\n# Predictions\ny_train_pred = elastic_cv.predict(X_train_scaled)\ny_test_pred = elastic_cv.predict(X_test_scaled)\n\n# Performance metrics\nprint(\"=\" * 50)\nprint(\"ElasticNet Model Performance\")\nprint(\"=\" * 50)\nprint(f\"Best alpha (regularization): {elastic_cv.alpha_:.6f}\")\nprint(f\"Best l1_ratio: {elastic_cv.l1_ratio_:.2f}\")\nprint()\nprint(\"Test Set:\")\nprint(f\"  MAE: {mean_absolute_error(train_y, y_test_pred):.4f}\")\nprint(f\"  RÂ²:  {r2_score(test_y, y_test_pred):.4f}\")\nprint()\nprint(\"Training Set:\")\nprint(f\"  MAE: {mean_absolute_error(train_y, y_train_pred):.4f}\")\nprint(f\"  RÂ²:  {r2_score(train_y, y_train_pred):.4f}\")\n\n# Feature coefficients (interpretable!)\nfeature_names = X_train.columns if hasattr(X_train, 'columns') else [f'feature_{i}' for i in range(X_train.shape[1])]\ncoef_df = pd.DataFrame({\n    'feature': feature_names,\n    'coefficient': elastic_cv.coef_\n}).sort_values('coefficient', key=abs, ascending=False)\n\nprint()\nprint(\"Top 10 Features by Coefficient Magnitude:\")\nprint(\"-\" * 40)\nfor idx, row in coef_df.head(10).iterrows():\n    print(f\"  {row['feature']:35s} {row['coefficient']:+.4f}\")\n\n# Count non-zero coefficients (feature selection via L1)\nn_nonzero = np.sum(elastic_cv.coef_ != 0)\nprint(f\"\\nNon-zero coefficients: {n_nonzero} / {len(elastic_cv.coef_)}\")\n\n\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.648e-02, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.438e-02, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.979e-02, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.223e-02, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.798e-02, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.122e-01, tolerance: 1.610e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.174e-02, tolerance: 1.610e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.019e-02, tolerance: 1.610e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.018e-02, tolerance: 1.732e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.757e-01, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.499e-02, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.892e-02, tolerance: 1.732e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.606e-02, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.595e-02, tolerance: 1.610e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.257e-02, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.288e-02, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.358e-02, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.971e-01, tolerance: 1.610e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.832e-01, tolerance: 1.610e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.138e-01, tolerance: 1.610e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.984e-01, tolerance: 1.732e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.575e-02, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.171e-02, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.639e-01, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.745e-02, tolerance: 1.732e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.961e-02, tolerance: 1.732e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.818e-02, tolerance: 1.610e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.321e-02, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.140e-02, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.730e-02, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.400e-01, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.915e-02, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.702e-02, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.349e-01, tolerance: 1.610e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.891e-01, tolerance: 1.610e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.907e-02, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.066e-01, tolerance: 1.610e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.949e-01, tolerance: 1.732e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.575e-01, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.392e-01, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.926e-02, tolerance: 1.732e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.334e-01, tolerance: 1.610e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.471e-02, tolerance: 1.732e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.276e-01, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.283e-01, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.247e-01, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.846e-02, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.447e-02, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.275e-02, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.572e-01, tolerance: 1.610e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.908e-01, tolerance: 1.610e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.598e-02, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.406e+00, tolerance: 1.610e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.686e+00, tolerance: 1.732e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.746e-01, tolerance: 1.610e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.990e-01, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.342e-01, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.590e-01, tolerance: 1.732e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.733e-02, tolerance: 1.732e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.687e-01, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.229e-01, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.302e-01, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.246e-02, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.382e-02, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.801e-02, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.209e+00, tolerance: 1.610e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.241e+00, tolerance: 1.610e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.081e+00, tolerance: 1.610e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.439e-01, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.871e+00, tolerance: 1.610e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.150e+00, tolerance: 1.732e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.192e+00, tolerance: 1.732e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.905e-01, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.385e-01, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.788e-01, tolerance: 1.732e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.103e+00, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.565e-01, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.556e+00, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.479e-02, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.546e-02, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.339e-01, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.420e+00, tolerance: 1.610e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.807e+00, tolerance: 1.610e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.679e+00, tolerance: 1.610e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.202e+00, tolerance: 1.610e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.878e+00, tolerance: 1.732e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.181e+00, tolerance: 1.732e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.310e+00, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.804e-01, tolerance: 1.732e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.564e-01, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.196e-01, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.146e+00, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.549e-01, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.804e+00, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.090e-01, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.263e-01, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.405e-01, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.530e+00, tolerance: 1.610e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.152e+00, tolerance: 1.610e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.536e+00, tolerance: 1.610e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.641e+00, tolerance: 1.732e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.343e+00, tolerance: 1.610e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.658e+00, tolerance: 1.732e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.431e+00, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.985e+00, tolerance: 1.732e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.850e-01, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.567e+00, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.860e-01, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.624e+00, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.374e-01, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.791e-01, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.420e-01, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.268e+00, tolerance: 1.610e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.507e-01, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.598e+00, tolerance: 1.610e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.699e+00, tolerance: 1.610e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.771e+00, tolerance: 1.610e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.651e+00, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.909e+00, tolerance: 1.732e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.217e-01, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.573e+00, tolerance: 1.732e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.898e+00, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.271e+00, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.720e+00, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.154e+00, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.919e+00, tolerance: 1.610e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.483e-01, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.467e-01, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.006e+00, tolerance: 1.610e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.792e-01, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.816e+00, tolerance: 1.610e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.125e+00, tolerance: 1.610e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.636e-01, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.781e+00, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.902e+00, tolerance: 1.732e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.875e+00, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.890e+00, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.660e+00, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.102e+00, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.433e-01, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.827e-01, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.969e+00, tolerance: 1.610e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.835e+00, tolerance: 1.610e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.077e-01, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.992e+00, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.902e-01, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.030e+00, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.192e+00, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.720e+00, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.246e-02, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.498e-01, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.423e+00, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.322e+00, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.922e-01, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.292e+00, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.826e+00, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.248e-01, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.472e-02, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.262e+00, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.145e+00, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.272e-02, tolerance: 1.610e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.728e+00, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.032e-02, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.633e+00, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.540e+00, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.570e-02, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.869e-01, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.944e-01, tolerance: 1.610e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.836e-02, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.041e-01, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.936e-02, tolerance: 1.732e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.400e-02, tolerance: 1.610e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.916e-02, tolerance: 1.732e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.463e-02, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.891e-02, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.729e-01, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.745e-02, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.960e-01, tolerance: 1.610e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.153e-01, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.678e-02, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.506e-02, tolerance: 1.732e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.023e-01, tolerance: 1.610e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.229e-02, tolerance: 1.732e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.011e-02, tolerance: 1.732e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.417e-02, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.475e-02, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.798e-02, tolerance: 1.610e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.215e-02, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.750e-01, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.801e-01, tolerance: 1.610e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.128e-02, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.266e-01, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.978e-02, tolerance: 1.732e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.902e-01, tolerance: 1.610e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.162e-02, tolerance: 1.732e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.324e-02, tolerance: 1.732e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.962e-01, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.374e-02, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.972e-02, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.622e-01, tolerance: 1.610e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.497e-01, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.652e-02, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.138e+00, tolerance: 1.610e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.100e-02, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.390e-01, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.832e-01, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.857e-02, tolerance: 1.732e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.017e+00, tolerance: 1.610e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.048e-01, tolerance: 1.732e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.209e-02, tolerance: 1.732e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.929e-01, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.403e-01, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.649e-01, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.994e-01, tolerance: 1.610e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.710e-01, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.894e-02, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.241e-02, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.281e+00, tolerance: 1.610e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.359e-01, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.111e-01, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.157e-02, tolerance: 1.732e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.262e+00, tolerance: 1.610e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.166e-02, tolerance: 1.732e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.423e-01, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.968e-01, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.129e-01, tolerance: 1.732e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.660e-01, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.112e+00, tolerance: 1.610e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.530e-01, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.066e-02, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.908e-02, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.856e-01, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.698e-01, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.395e+00, tolerance: 1.610e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.797e-01, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.564e-02, tolerance: 1.732e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.855e-02, tolerance: 1.732e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.273e+00, tolerance: 1.610e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.850e-01, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.160e-01, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.554e-01, tolerance: 1.732e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.143e+00, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.345e+00, tolerance: 1.610e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.424e-01, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.005e-01, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.740e-02, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.486e-01, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.057e-01, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.440e+00, tolerance: 1.610e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.739e-01, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.600e-01, tolerance: 1.732e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.889e-02, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.409e-02, tolerance: 1.732e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.300e+00, tolerance: 1.610e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.945e-01, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.340e-01, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.613e-01, tolerance: 1.732e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.401e+00, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.310e+00, tolerance: 1.610e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.308e-01, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.411e-01, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.196e-01, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.189e-01, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.487e+00, tolerance: 1.610e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.633e-01, tolerance: 1.732e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.821e-01, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.712e-02, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.617e-02, tolerance: 1.732e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.128e-01, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.456e+00, tolerance: 1.610e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.583e-01, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.300e-01, tolerance: 1.732e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.447e+00, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.475e+00, tolerance: 1.610e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.442e-01, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.289e-01, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.373e-02, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.189e-01, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.858e-01, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.560e+00, tolerance: 1.610e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.675e-01, tolerance: 1.732e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.631e-01, tolerance: 1.732e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.532e-01, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.153e+00, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.182e+00, tolerance: 1.610e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.420e-01, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.555e-01, tolerance: 1.732e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.287e+00, tolerance: 1.610e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.454e+00, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.295e-01, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.849e-01, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.425e-01, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.613e-01, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.573e+00, tolerance: 1.610e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.712e-01, tolerance: 1.732e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.572e-01, tolerance: 1.732e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.127e-01, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.730e-02, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.238e+00, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.095e+00, tolerance: 1.610e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.105e+00, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.504e-01, tolerance: 1.732e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.073e+00, tolerance: 1.610e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.773e-01, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.694e-01, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.203e-01, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.389e-01, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.409e-01, tolerance: 1.732e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.288e-01, tolerance: 1.732e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.600e-01, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.783e-01, tolerance: 1.610e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.195e-01, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.201e+00, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.492e-02, tolerance: 1.732e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.057e+00, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.814e-01, tolerance: 1.610e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.939e-01, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.346e-01, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.242e-01, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.347e-01, tolerance: 1.732e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.153e-01, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.471e-01, tolerance: 1.732e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.699e-01, tolerance: 1.732e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.288e-01, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.900e-02, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.961e-01, tolerance: 1.610e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.154e+00, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.484e-01, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.896e-02, tolerance: 1.732e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.166e-01, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.859e-01, tolerance: 1.610e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.133e-01, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.774e-01, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.337e-01, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.016e-01, tolerance: 1.732e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.993e-01, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.936e-01, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.322e-02, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.284e-01, tolerance: 1.732e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.674e-01, tolerance: 1.732e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.567e-01, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.499e-01, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.163e-01, tolerance: 1.732e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.779e-01, tolerance: 1.610e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.642e-01, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.620e-01, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.267e-01, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.550e-01, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.166e-01, tolerance: 1.732e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.574e-02, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.690e-02, tolerance: 1.732e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.286e-01, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.369e-01, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.378e-01, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.821e-01, tolerance: 1.732e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.364e-02, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.797e-01, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.148e-01, tolerance: 1.732e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.178e-01, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.132e-02, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.058e-01, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.169e-01, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.494e-01, tolerance: 1.732e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.956e-01, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.812e-01, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.711e-01, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.466e-01, tolerance: 1.732e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.751e-01, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.595e-02, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.612e-01, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.055e-01, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.624e-01, tolerance: 1.732e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.641e-01, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.774e-01, tolerance: 1.770e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.711e-01, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.956e-01, tolerance: 1.732e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.383e-01, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.079e+00, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.307e-01, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.178e-01, tolerance: 1.732e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.993e-01, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.357e-01, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.765e-02, tolerance: 1.732e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.726e-01, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.184e-01, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.038e-01, tolerance: 1.732e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.712e-01, tolerance: 1.641e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.902e-01, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.590e-01, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.316e-01, tolerance: 1.570e-02\n  model = cd_fast.enet_coordinate_descent_gram(\n\n\n==================================================\nElasticNet Model Performance\n==================================================\nBest alpha (regularization): 0.294705\nBest l1_ratio: 0.50\n\nTest Set:\n\n\n\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\nCell In[177], line 38\n     36 print()\n     37 print(\"Test Set:\")\n---&gt; 38 print(f\"  MAE: {mean_absolute_error(train_y, y_test_pred):.4f}\")\n     39 print(f\"  RÂ²:  {r2_score(test_y, y_test_pred):.4f}\")\n     40 print()\n\nFile ~/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:218, in validate_params.&lt;locals&gt;.decorator.&lt;locals&gt;.wrapper(*args, **kwargs)\n    212 try:\n    213     with config_context(\n    214         skip_parameter_validation=(\n    215             prefer_skip_nested_validation or global_skip_validation\n    216         )\n    217     ):\n--&gt; 218         return func(*args, **kwargs)\n    219 except InvalidParameterError as e:\n    220     # When the function is just a wrapper around an estimator, we allow\n    221     # the function to delegate validation to the estimator, but we replace\n    222     # the name of the estimator by the name of the function in the error\n    223     # message to avoid confusion.\n    224     msg = re.sub(\n    225         r\"parameter of \\w+ must be\",\n    226         f\"parameter of {func.__qualname__} must be\",\n    227         str(e),\n    228     )\n\nFile ~/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/metrics/_regression.py:284, in mean_absolute_error(y_true, y_pred, sample_weight, multioutput)\n    228 \"\"\"Mean absolute error regression loss.\n    229 \n    230 The mean absolute error is a non-negative floating point value, where best value\n   (...)\n    279 0.85...\n    280 \"\"\"\n    281 xp, _ = get_namespace(y_true, y_pred, sample_weight, multioutput)\n    283 _, y_true, y_pred, sample_weight, multioutput = (\n--&gt; 284     _check_reg_targets_with_floating_dtype(\n    285         y_true, y_pred, sample_weight, multioutput, xp=xp\n    286     )\n    287 )\n    289 output_errors = _average(\n    290     xp.abs(y_pred - y_true), weights=sample_weight, axis=0, xp=xp\n    291 )\n    292 if isinstance(multioutput, str):\n\nFile ~/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/metrics/_regression.py:209, in _check_reg_targets_with_floating_dtype(y_true, y_pred, sample_weight, multioutput, xp)\n    160 \"\"\"Ensures y_true, y_pred, and sample_weight correspond to same regression task.\n    161 \n    162 Extends `_check_reg_targets` by automatically selecting a suitable floating-point\n   (...)\n    205     correct keyword.\n    206 \"\"\"\n    207 dtype_name = _find_matching_floating_dtype(y_true, y_pred, sample_weight, xp=xp)\n--&gt; 209 y_type, y_true, y_pred, sample_weight, multioutput = _check_reg_targets(\n    210     y_true, y_pred, sample_weight, multioutput, dtype=dtype_name, xp=xp\n    211 )\n    213 return y_type, y_true, y_pred, sample_weight, multioutput\n\nFile ~/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/metrics/_regression.py:114, in _check_reg_targets(y_true, y_pred, sample_weight, multioutput, dtype, xp)\n     63 \"\"\"Check that y_true, y_pred and sample_weight belong to the same regression task.\n     64 \n     65 To reduce redundancy when calling `_find_matching_floating_dtype`,\n   (...)\n    110     correct keyword.\n    111 \"\"\"\n    112 xp, _ = get_namespace(y_true, y_pred, multioutput, xp=xp)\n--&gt; 114 check_consistent_length(y_true, y_pred, sample_weight)\n    115 y_true = check_array(y_true, ensure_2d=False, dtype=dtype)\n    116 y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n\nFile ~/anaconda3/envs/fastdl/lib/python3.10/site-packages/sklearn/utils/validation.py:473, in check_consistent_length(*arrays)\n    471 lengths = [_num_samples(X) for X in arrays if X is not None]\n    472 if len(set(lengths)) &gt; 1:\n--&gt; 473     raise ValueError(\n    474         \"Found input variables with inconsistent numbers of samples: %r\"\n    475         % [int(l) for l in lengths]\n    476     )\n\nValueError: Found input variables with inconsistent numbers of samples: [105, 27]"
  },
  {
    "objectID": "posts/auto_clipper/index.html",
    "href": "posts/auto_clipper/index.html",
    "title": "Auto Clipping",
    "section": "",
    "text": "1) Our auto detection functions from the previous notebook to find each swing\n2) Core conditional logic to save and store these individual clips for future use\n\n\n\n\n\nCode\nparent_dir = files[0].parent\nparent_dir\n\n\nPath('../../../data/full_videos/sep14')\n\n\n\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [00:00&lt;00:00, 350.69it/s]\n\n\nThe video IMG_1090.MOV is in numpy array with shape: (250, 256, 256, 3)\n\n\n\n\nCode\n# 11:48 seconds for one video (3ish min) -- lets just run once so we don't have to keep dealing with this wait\n# process_label_video(f'{parent_dir}/{fname}/full_clip.mp4', \n#                                    out_dir=f'{parent_dir}/{fname}/keypoints')\n\n\n\n\nCode\nkps = KpExtractor(f'keypoints/{fname}_full_clip.pkl').keypoint_data.kps\nhigher_idxs = find_all_higher_wrist_idxs(kps, conf_threshold=0.7)\nframe_increment = 90 # add 90 frames before and after our first frame with both hands above in backswing\"\nhighest_idxs = find_each_first_higher_wrist(higher_idxs, skip_frames=900) # 900 frames is 15 seconds\nall_idx_bounds = get_all_idx_bounds(highest_idxs, frame_increment=frame_increment)\nfinal_frames = np.vstack([frames[idxs[0]: idxs[1]] for idxs in all_idx_bounds])\nprint(f'the highest (first) indexes where both wrists are above elbow and shoulder are:\\n{highest_idxs}')\nprint(f'the start end end indexes based on an increment of {frame_increment} is:\\n{all_idx_bounds}')\nprint(f'Our final combined video has shape: {final_frames.shape}')\n\n\nthe highest (first) indexes where both wrists are above elbow and shoulder are:\n[1750, 3273, 5298, 6901, 8773, 10945]\nthe start end end indexes based on an increment of 90 is:\n[(1660, 1840), (3183, 3363), (5208, 5388), (6811, 6991), (8683, 8863), (10855, 11035)]\nOur final combined video has shape: (1080, 256, 256, 3)\n\n\n\n\n\n\n\nWe can extend the number of frames to 120 (2 seconds) before and after if we want\n\n\n\nWe have 6 total swings from our original video IMG_1090"
  },
  {
    "objectID": "posts/auto_clipper/index.html#now-that-we-have-some-functionality-to-find-each-swing-in-the-video-lets-clip-a-longer-video",
    "href": "posts/auto_clipper/index.html#now-that-we-have-some-functionality-to-find-each-swing-in-the-video-lets-clip-a-longer-video",
    "title": "Auto Clipping",
    "section": "",
    "text": "1) Our auto detection functions from the previous notebook to find each swing\n2) Core conditional logic to save and store these individual clips for future use\n\n\n\n\n\nCode\nparent_dir = files[0].parent\nparent_dir\n\n\nPath('../../../data/full_videos/sep14')\n\n\n\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [00:00&lt;00:00, 350.69it/s]\n\n\nThe video IMG_1090.MOV is in numpy array with shape: (250, 256, 256, 3)\n\n\n\n\nCode\n# 11:48 seconds for one video (3ish min) -- lets just run once so we don't have to keep dealing with this wait\n# process_label_video(f'{parent_dir}/{fname}/full_clip.mp4', \n#                                    out_dir=f'{parent_dir}/{fname}/keypoints')\n\n\n\n\nCode\nkps = KpExtractor(f'keypoints/{fname}_full_clip.pkl').keypoint_data.kps\nhigher_idxs = find_all_higher_wrist_idxs(kps, conf_threshold=0.7)\nframe_increment = 90 # add 90 frames before and after our first frame with both hands above in backswing\"\nhighest_idxs = find_each_first_higher_wrist(higher_idxs, skip_frames=900) # 900 frames is 15 seconds\nall_idx_bounds = get_all_idx_bounds(highest_idxs, frame_increment=frame_increment)\nfinal_frames = np.vstack([frames[idxs[0]: idxs[1]] for idxs in all_idx_bounds])\nprint(f'the highest (first) indexes where both wrists are above elbow and shoulder are:\\n{highest_idxs}')\nprint(f'the start end end indexes based on an increment of {frame_increment} is:\\n{all_idx_bounds}')\nprint(f'Our final combined video has shape: {final_frames.shape}')\n\n\nthe highest (first) indexes where both wrists are above elbow and shoulder are:\n[1750, 3273, 5298, 6901, 8773, 10945]\nthe start end end indexes based on an increment of 90 is:\n[(1660, 1840), (3183, 3363), (5208, 5388), (6811, 6991), (8683, 8863), (10855, 11035)]\nOur final combined video has shape: (1080, 256, 256, 3)\n\n\n\n\n\n\n\nWe can extend the number of frames to 120 (2 seconds) before and after if we want\n\n\n\nWe have 6 total swings from our original video IMG_1090"
  },
  {
    "objectID": "posts/auto_clipper/index.html#some-functions-to-walk-through-generated-keypoints-to-find-all-swing-start-and-end-indexes",
    "href": "posts/auto_clipper/index.html#some-functions-to-walk-through-generated-keypoints-to-find-all-swing-start-and-end-indexes",
    "title": "Auto Clipping",
    "section": "### Some functions to walk through generated keypoints to find all swing start and end indexes",
    "text": "### Some functions to walk through generated keypoints to find all swing start and end indexes\n\n\nCode\ndef save_idx_df(fname, all_idx_bounds, out_dir):\n    start_idxs = [idxs[0] for idxs in all_idx_bounds]\n    end_idxs = [idxs[1] for idxs in all_idx_bounds]\n    swing_idxs = [x for x in range(len(all_idx_bounds))]\n    df = pd.DataFrame([swing_idxs, start_idxs, end_idxs], \n                 index=['swing_idx', 'start_idx', 'end_idx']).T\n    df.to_csv(f'{out_dir}/{fname}.csv', index=False)\n    return df\n\n\n\n\nCode\ndef get_swing_idx_df(kps_fpath,\n                     fname,\n                     out_dir,\n                     conf_threshold=0.7, \n                     frame_increment=90, # add 1.5 seconds before and the found idx\n                     skip_frames=900, # 900 frames is 15 seconds\n                     # ^ skips frames between swings\n                     ):\n    kps = KpExtractor(kps_fpath).keypoint_data.kps\n    higher_idxs = find_all_higher_wrist_idxs(kps, conf_threshold=conf_threshold)\n    highest_idxs = find_each_first_higher_wrist(higher_idxs, skip_frames=skip_frames) # 900 frames is 15 seconds\n    all_idx_bounds = get_all_idx_bounds(highest_idxs, frame_increment=frame_increment)\n    df = save_idx_df(fname, all_idx_bounds, out_dir)\n    return df\n\n\n\n\nCode\ndef ensure_out_dir(out_dir_fpath):\n    if not os.path.isdir(out_dir_fpath):\n        os.makedirs(out_dir_fpath)\n\ndef find_each_swing(video_path,\n                    per_second=False, # only grab every fps frame\n                    num_frames=None, #1500, # Pulls down all of the frames of video\n                    start_idx=None, #600, # None starts from 0\n                    resize_dim=(256,256),\n                    show_progress=True,\n                    model_type='vit', \n                    #out_dir='testing'\n                   ):\n    parent_dir = video_path.parent\n    fname = video_path.name.split('.')[0]\n    out_dir = f'{parent_dir}/{fname}'\n    ensure_out_dir(out_dir)                        \n    fname = video_path.name.split('.')[0]\n    frames, fps = get_frames(video_path,\n                             start_idx=start_idx,\n                             per_second=per_second, # only grab every fps frame\n                             num_frames=num_frames,#None, # Pulls down all of the frames of video\n                             resize_dim=resize_dim,\n                             show_progress=show_progress,\n                            )\n    output_filename = 'full_video.mp4'\n    out_fpath = f'{out_dir}/{output_filename}'\n    kp_fpath = f'{out_dir}/keypoints/{output_filename.split(\".\")[0]}.pkl'\n    \n    save_frames(frames=frames, fps=fps, \n            parent_dir=f'{parent_dir}/{fname}',\n            output_filename=output_filename)\n    #save_frames(frames=frames, fps=fps, fname=out_fpath)\n                       \n    process_label_video(out_fpath, out_dir=f'{out_dir}/keypoints')\n    df = get_swing_idx_df(kps_fpath=kp_fpath, fname=fname, out_dir=out_dir)\n    return df\n\n\n\n\nCode\n#fname = files[0].name.split('.')[0]\n#df = find_each_swing(files[1], start_idx=None, num_frames=1500, )#out_dir=fname)\n\n\n\nNow everything is setup so we can extract all the swing frames with one command\n\nthe entire thing is parameterized in order to make small tweaks in how much data we index around the peak\nIt should make things easier/more reproducible\n\nImagine a scenario where we decide to add some processing to videos before doing all of this, now that can be added with a function/line of code into this overall pipeline\n\nEverything should remain organizable\nScaling things up to full frame shouldnâ€™t be a problem. we grab the frames and just clip with ffmpeg commands â€“&gt; label them with the labeler. 7 swings is about 20-25 seconds. This can be done in parallel ## Next up:\nProcess individual swings and apply the analysis framework\n\nWant to further build out functionality; add x-torque and others\n\nUpdate plotting functionality to make it more modular and flexible\nUltimately want to be able to point to a folder of videos and output all the plots of interest\n\n\n\nCode\ndf.head()\n\n\n\n\n\n\n\n\n\nswing_idx\nstart_idx\nend_idx\n\n\n\n\n0\n0\n1369\n1549\n\n\n\n\n\n\n\n\n\nCode\nimport ffmpeg\n\ndef make_output_filename(fname, swing_idx, score=None):\n    return f'{fname}_swing_{swing_idx}_score_{score}'\n\ndef make_clip(input_file_path, \n              output_folder_path,\n              row, \n              #duration_frames=90,  # Changed from time='0:03'\n              crf='18',\n              vcodec='libx264'):   # Changed from 'copy' since we need to use filter\n    fname = input_file_path.name.split('.')[0]\n    swing_idx, start_frame, end_frame = row.values\n    output_file_name = make_output_filename(fname, swing_idx)\n    output_file_path = f'{output_folder_path}/{fname}/{output_file_name}.mp4'\n    import pdb\n    #pdb.set_trace()\n    if os.path.isdir(output_folder_path) is False:\n        os.mkdir(output_folder_path)\n        \n    # Use trim filter for frame-accurate cutting\n    (\n        ffmpeg.input(input_file_path)\n        .trim(start_frame=start_frame, \n              end_frame=end_frame)\n        .setpts('PTS-STARTPTS')  # Reset timestamps\n        .output(output_file_path, \n                vcodec=vcodec,\n                crf=crf, \n                acodec='aac')\n        .global_args('-movflags', '+faststart')\n        .overwrite_output()\n        .run()\n    )\n\n\n\n\nCode\n# for x in range(len(df)):\n#     make_clip(input_file_path=files[1], \n#               output_folder_path=parent_dir,\n#               row = df.iloc[x]\n#              )\n\n\n\n\nCode\ndef end_to_end_detect(fpath, start_idx=None, num_frames=None):\n    df = find_each_swing(fpath, start_idx=start_idx, num_frames=num_frames,)#1500, )\n    parent_dir = fpath.parent\n    for x in range(len(df)):\n        make_clip(input_file_path=fpath, \n                  output_folder_path=parent_dir,\n                  row = df.iloc[x]\n                 )\n    return df\n\n\n\n\nCode\nfrom fastai.vision.all import *\nfrom auto_clipper import *\n\n\n\n\nCode\nbase_path = '../../../data/full_videos'\n#swing_days = ['jun8', 'aug9', 'sep14']\nfiles = get_files(f'{base_path}/david', extensions='.MOV')\nfiles\n\n\n(#6) [Path('../../../data/full_videos/david/IMG_3857.MOV'),Path('../../../data/full_videos/david/IMG_3853.MOV'),Path('../../../data/full_videos/david/IMG_3854.MOV'),Path('../../../data/full_videos/david/IMG_3855.MOV'),Path('../../../data/full_videos/david/IMG_3856.MOV'),Path('../../../data/full_videos/david/IMG_3858.MOV')]\n\n\n\n\nCode\ndef detect_then_label(files):\n    [end_to_end_detect(file) for file in files]\n    #[lbl_clips(file) for file in files]\n\n\n\n\nCode\n#detect_then_label(files)\n\n\n\n\nCode\n#end_to_end_detect(files[2])\n#end_to_end_detect(files[7])\n\n\n\n\nCode\ndef lbl_clips(fpath):\n    fname = fpath.name.split('.')[0]\n    parent_dir = fpath.parent\n    clips_folder_path = f'{parent_dir}/{fname}'\n    clipped_videos = [x.name for x in get_files(clips_folder_path, extensions='.mp4') if x.name[:3] == 'IMG']\n    for video in clipped_videos:\n        clip_video_path = f'{clips_folder_path}/{video}'\n        process_label_video(clip_video_path, \n                    out_dir=f'{clips_folder_path}/keypoints')\n\n\n\n\nCode\ndef get_output_folder(fpath):\n    return f'{fpath.parent}/{fpath.name.split(\".\")[0]}'\nget_output_folder(files[0])\n\n\n'../../../data/full_videos/david/IMG_3857'\n\n\n\n\nCode\nfor x in range(len(files)):\n    process_label_video(files[x], out_dir=get_output_folder(files[x]))\n\n\nLoads checkpoint by http backend from path: https://download.openmmlab.com/mmpose/v1/body_2d_keypoint/topdown_heatmap/coco/td-hm_ViTPose-huge_8xb64-210e_coco-256x192-e32adcd4_20230314.pth\nThe model and loaded state dict do not match exactly\n\nunexpected key in source state_dict: backbone.cls_token\n\n\n\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/importlib/__init__.py:169: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools&lt;81.\n  _bootstrap._exec(spec, module)\n\n\nLoads checkpoint by http backend from path: https://download.openmmlab.com/mmpose/v1/projects/rtmposev1/rtmdet_m_8xb32-100e_coco-obj365-person-235e8209.pth\n\n\n0it [00:00, ?it/s]/home/azaidi/Desktop/golf/tools/mmdetection/mmdet/models/layers/se_layer.py:158: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=False):\n/home/azaidi/Desktop/golf/tools/mmdetection/mmdet/models/backbones/csp_darknet.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=False):\n1255it [01:31, 13.87it/s]\n\n\n\n11/15 23:06:36 - mmengine - INFO - the output video has been saved at ../../../data/full_videos/david/IMG_3857/IMG_3857.MOV\n\n\n\n\n1256it [01:31, 13.76it/s]\n\n\nLoads checkpoint by http backend from path: https://download.openmmlab.com/mmpose/v1/body_2d_keypoint/topdown_heatmap/coco/td-hm_ViTPose-huge_8xb64-210e_coco-256x192-e32adcd4_20230314.pth\nThe model and loaded state dict do not match exactly\n\nunexpected key in source state_dict: backbone.cls_token\n\n\n\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/importlib/__init__.py:169: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools&lt;81.\n  _bootstrap._exec(spec, module)\n\n\nLoads checkpoint by http backend from path: https://download.openmmlab.com/mmpose/v1/projects/rtmposev1/rtmdet_m_8xb32-100e_coco-obj365-person-235e8209.pth\n\n\n0it [00:00, ?it/s]/home/azaidi/Desktop/golf/tools/mmdetection/mmdet/models/layers/se_layer.py:158: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=False):\n/home/azaidi/Desktop/golf/tools/mmdetection/mmdet/models/backbones/csp_darknet.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=False):\n879it [01:04, 13.44it/s]\n\n\n\n11/15 23:07:45 - mmengine - INFO - the output video has been saved at ../../../data/full_videos/david/IMG_3853/IMG_3853.MOV\n\n\n\n\n880it [01:04, 13.58it/s]\n\n\nLoads checkpoint by http backend from path: https://download.openmmlab.com/mmpose/v1/body_2d_keypoint/topdown_heatmap/coco/td-hm_ViTPose-huge_8xb64-210e_coco-256x192-e32adcd4_20230314.pth\nThe model and loaded state dict do not match exactly\n\nunexpected key in source state_dict: backbone.cls_token\n\n\n\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/importlib/__init__.py:169: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools&lt;81.\n  _bootstrap._exec(spec, module)\n\n\nLoads checkpoint by http backend from path: https://download.openmmlab.com/mmpose/v1/projects/rtmposev1/rtmdet_m_8xb32-100e_coco-obj365-person-235e8209.pth\n\n\n0it [00:00, ?it/s]/home/azaidi/Desktop/golf/tools/mmdetection/mmdet/models/layers/se_layer.py:158: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=False):\n/home/azaidi/Desktop/golf/tools/mmdetection/mmdet/models/backbones/csp_darknet.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=False):\n927it [01:12, 13.54it/s]\n\n\n\n11/15 23:09:01 - mmengine - INFO - the output video has been saved at ../../../data/full_videos/david/IMG_3854/IMG_3854.MOV\n\n\n\n\n927it [01:12, 12.84it/s]\n\n\nLoads checkpoint by http backend from path: https://download.openmmlab.com/mmpose/v1/body_2d_keypoint/topdown_heatmap/coco/td-hm_ViTPose-huge_8xb64-210e_coco-256x192-e32adcd4_20230314.pth\nThe model and loaded state dict do not match exactly\n\nunexpected key in source state_dict: backbone.cls_token\n\n\n\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/importlib/__init__.py:169: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools&lt;81.\n  _bootstrap._exec(spec, module)\n\n\nLoads checkpoint by http backend from path: https://download.openmmlab.com/mmpose/v1/projects/rtmposev1/rtmdet_m_8xb32-100e_coco-obj365-person-235e8209.pth\n\n\n0it [00:00, ?it/s]/home/azaidi/Desktop/golf/tools/mmdetection/mmdet/models/layers/se_layer.py:158: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=False):\n/home/azaidi/Desktop/golf/tools/mmdetection/mmdet/models/backbones/csp_darknet.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=False):\n1017it [01:14, 13.45it/s]\n\n\n\n11/15 23:10:19 - mmengine - INFO - the output video has been saved at ../../../data/full_videos/david/IMG_3855/IMG_3855.MOV\n\n\n\n\n1017it [01:14, 13.61it/s]\n\n\nLoads checkpoint by http backend from path: https://download.openmmlab.com/mmpose/v1/body_2d_keypoint/topdown_heatmap/coco/td-hm_ViTPose-huge_8xb64-210e_coco-256x192-e32adcd4_20230314.pth\nThe model and loaded state dict do not match exactly\n\nunexpected key in source state_dict: backbone.cls_token\n\n\n\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/importlib/__init__.py:169: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools&lt;81.\n  _bootstrap._exec(spec, module)\n\n\nLoads checkpoint by http backend from path: https://download.openmmlab.com/mmpose/v1/projects/rtmposev1/rtmdet_m_8xb32-100e_coco-obj365-person-235e8209.pth\n\n\n0it [00:00, ?it/s]/home/azaidi/Desktop/golf/tools/mmdetection/mmdet/models/layers/se_layer.py:158: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=False):\n/home/azaidi/Desktop/golf/tools/mmdetection/mmdet/models/backbones/csp_darknet.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=False):\n895it [01:05, 13.57it/s]\n\n\n\n11/15 23:11:29 - mmengine - INFO - the output video has been saved at ../../../data/full_videos/david/IMG_3856/IMG_3856.MOV\n\n\n\n\n895it [01:05, 13.62it/s]\n\n\nLoads checkpoint by http backend from path: https://download.openmmlab.com/mmpose/v1/body_2d_keypoint/topdown_heatmap/coco/td-hm_ViTPose-huge_8xb64-210e_coco-256x192-e32adcd4_20230314.pth\nThe model and loaded state dict do not match exactly\n\nunexpected key in source state_dict: backbone.cls_token\n\n\n\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/importlib/__init__.py:169: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools&lt;81.\n  _bootstrap._exec(spec, module)\n\n\nLoads checkpoint by http backend from path: https://download.openmmlab.com/mmpose/v1/projects/rtmposev1/rtmdet_m_8xb32-100e_coco-obj365-person-235e8209.pth\n\n\n0it [00:00, ?it/s]/home/azaidi/Desktop/golf/tools/mmdetection/mmdet/models/layers/se_layer.py:158: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=False):\n/home/azaidi/Desktop/golf/tools/mmdetection/mmdet/models/backbones/csp_darknet.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=False):\n987it [01:12, 13.44it/s]\n\n\n\n11/15 23:12:45 - mmengine - INFO - the output video has been saved at ../../../data/full_videos/david/IMG_3858/IMG_3858.MOV\n\n\n\n\n987it [01:12, 13.64it/s]"
  },
  {
    "objectID": "ball_club_finder/Untitled.html",
    "href": "ball_club_finder/Untitled.html",
    "title": "eagle-swing",
    "section": "",
    "text": "from fastai.vision.all import *\nfrom ultralytics import YOLO\n\n\ngolf_files = get_files('../../../custom_models/Golf-club-path-analysis-1/')\ngolf_files[-3:]\n\n(#3) [Path('../../../custom_models/Golf-club-path-analysis-1/test/images/youtube-6_jpg.rf.88a64b8ab46009dcf521c58c9568eb08.jpg'),Path('../../../custom_models/Golf-club-path-analysis-1/test/images/youtube-0_jpg.rf.e9e572e33d76c18bc348c43f81e11be4.jpg'),Path('../../../custom_models/Golf-club-path-analysis-1/test/images/youtube-7_jpg.rf.de732739ad329496ad2eddc3345acdcc.jpg')]\n\n\n\nimg_files = get_files('../../../custom_models/Golf-club-path-analysis-1/train/images/')\nimg_files[-1]\n\nPath('../../../custom_models/Golf-club-path-analysis-1/train/images/youtube-4_jpg.rf.2ae372a0768a1b2350ad4474427fd261.jpg')\n\n\n\nget_files('../../../custom_models/Golf-club-path-analysis-1/train/labels/')[0]\n\nPath('../../../custom_models/Golf-club-path-analysis-1/train/labels/youtube-1_jpg.rf.6bd646e819aceb367c867a28c25159cc.txt')\n\n\n\nparent_lbl_path = '../../../custom_models/Golf-club-path-analysis-1/train/labels/'\nlbl_paths = [f\"{parent_lbl_path}{'.'.join(x.name.split('.')[:-1])}.txt\" for x in img_files]\n\n\nplot_yolo_segmentation_as_bbox(img_files[140], \n                               lbl_paths[140], \n                               class_names=['golf_ball', 'golf_club', 'golf_clubhead'])\n\n\n\n\n\n\n\n\n\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef plot_yolo_segmentation_as_bbox(image_path, label_path, class_names=None):\n    \"\"\"\n    Plots bounding boxes derived from YOLO segmentation labels.\n    \"\"\"\n    # 1. Load the image to get dimensions\n    img = cv2.imread(image_path)\n    if img is None:\n        print(f\"Error: Could not load image at {image_path}\")\n        return\n    \n    # Convert BGR to RGB for matplotlib\n    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    h, w, _ = img.shape\n\n    # 2. Read the label file\n    with open(label_path, 'r') as f:\n        lines = f.readlines()\n\n    # 3. Parse each line\n    for line in lines:\n        parts = list(map(float, line.strip().split()))\n        class_id = int(parts[0])\n        coords = parts[1:]\n        \n        # Reshape into (N, 2) array of (x, y) pairs\n        points_norm = np.array(coords).reshape(-1, 2)\n        \n        # Denormalize: Convert from 0-1 range to pixel coordinates\n        # x_pixel = x_norm * width, y_pixel = y_norm * height\n        points_pixel = points_norm * np.array([w, h])\n        points_pixel = points_pixel.astype(int)\n        \n        # 4. Calculate Bounding Box (min/max x and y)\n        x_min = np.min(points_pixel[:, 0])\n        x_max = np.max(points_pixel[:, 0])\n        y_min = np.min(points_pixel[:, 1])\n        y_max = np.max(points_pixel[:, 1])\n        \n        # Draw the Bounding Box\n        # Color: Green (0, 255, 0), Thickness: 2\n        cv2.rectangle(img_rgb, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n        \n        # Optional: Draw the Polygon itself (to see the actual segmentation)\n        # cv2.polylines(img_rgb, [points_pixel], isClosed=True, color=(255, 0, 0), thickness=2)\n\n        # Add Label Text\n        label_text = f\"Class {class_id}\"\n        if class_names and class_id &lt; len(class_names):\n            label_text = class_names[class_id]\n            \n        cv2.putText(img_rgb, label_text, (x_min, y_min - 5), \n                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\n    # 5. Display the result\n    plt.figure(figsize=(10, 10))\n    plt.imshow(img_rgb)\n    plt.axis('off')\n    plt.title(\"Derived Bounding Boxes from Segmentation Labels\")\n    plt.show()"
  }
]