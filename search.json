[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/auto_clipper/index.html",
    "href": "posts/auto_clipper/index.html",
    "title": "Auto Clipping",
    "section": "",
    "text": "1) Our auto detection functions from the previous notebook to find each swing\n2) Core conditional logic to save and store these individual clips for future use\n\n\n\n\n\nCode\nparent_dir = files[0].parent\nparent_dir\n\n\nPath('../../../data/full_videos/sep14')\n\n\n\n\n100%|█████████████████████████████████████████████████████████████████████████████| 250/250 [00:00&lt;00:00, 350.69it/s]\n\n\nThe video IMG_1090.MOV is in numpy array with shape: (250, 256, 256, 3)\n\n\n\n\nCode\n# 11:48 seconds for one video (3ish min) -- lets just run once so we don't have to keep dealing with this wait\n# process_label_video(f'{parent_dir}/{fname}/full_clip.mp4', \n#                                    out_dir=f'{parent_dir}/{fname}/keypoints')\n\n\n\n\nCode\nkps = KpExtractor(f'keypoints/{fname}_full_clip.pkl').keypoint_data.kps\nhigher_idxs = find_all_higher_wrist_idxs(kps, conf_threshold=0.7)\nframe_increment = 90 # add 90 frames before and after our first frame with both hands above in backswing\"\nhighest_idxs = find_each_first_higher_wrist(higher_idxs, skip_frames=900) # 900 frames is 15 seconds\nall_idx_bounds = get_all_idx_bounds(highest_idxs, frame_increment=frame_increment)\nfinal_frames = np.vstack([frames[idxs[0]: idxs[1]] for idxs in all_idx_bounds])\nprint(f'the highest (first) indexes where both wrists are above elbow and shoulder are:\\n{highest_idxs}')\nprint(f'the start end end indexes based on an increment of {frame_increment} is:\\n{all_idx_bounds}')\nprint(f'Our final combined video has shape: {final_frames.shape}')\n\n\nthe highest (first) indexes where both wrists are above elbow and shoulder are:\n[1750, 3273, 5298, 6901, 8773, 10945]\nthe start end end indexes based on an increment of 90 is:\n[(1660, 1840), (3183, 3363), (5208, 5388), (6811, 6991), (8683, 8863), (10855, 11035)]\nOur final combined video has shape: (1080, 256, 256, 3)\n\n\n\n\n\n\n\nWe can extend the number of frames to 120 (2 seconds) before and after if we want\n\n\n\nWe have 6 total swings from our original video IMG_1090"
  },
  {
    "objectID": "posts/auto_clipper/index.html#now-that-we-have-some-functionality-to-find-each-swing-in-the-video-lets-clip-a-longer-video",
    "href": "posts/auto_clipper/index.html#now-that-we-have-some-functionality-to-find-each-swing-in-the-video-lets-clip-a-longer-video",
    "title": "Auto Clipping",
    "section": "",
    "text": "1) Our auto detection functions from the previous notebook to find each swing\n2) Core conditional logic to save and store these individual clips for future use\n\n\n\n\n\nCode\nparent_dir = files[0].parent\nparent_dir\n\n\nPath('../../../data/full_videos/sep14')\n\n\n\n\n100%|█████████████████████████████████████████████████████████████████████████████| 250/250 [00:00&lt;00:00, 350.69it/s]\n\n\nThe video IMG_1090.MOV is in numpy array with shape: (250, 256, 256, 3)\n\n\n\n\nCode\n# 11:48 seconds for one video (3ish min) -- lets just run once so we don't have to keep dealing with this wait\n# process_label_video(f'{parent_dir}/{fname}/full_clip.mp4', \n#                                    out_dir=f'{parent_dir}/{fname}/keypoints')\n\n\n\n\nCode\nkps = KpExtractor(f'keypoints/{fname}_full_clip.pkl').keypoint_data.kps\nhigher_idxs = find_all_higher_wrist_idxs(kps, conf_threshold=0.7)\nframe_increment = 90 # add 90 frames before and after our first frame with both hands above in backswing\"\nhighest_idxs = find_each_first_higher_wrist(higher_idxs, skip_frames=900) # 900 frames is 15 seconds\nall_idx_bounds = get_all_idx_bounds(highest_idxs, frame_increment=frame_increment)\nfinal_frames = np.vstack([frames[idxs[0]: idxs[1]] for idxs in all_idx_bounds])\nprint(f'the highest (first) indexes where both wrists are above elbow and shoulder are:\\n{highest_idxs}')\nprint(f'the start end end indexes based on an increment of {frame_increment} is:\\n{all_idx_bounds}')\nprint(f'Our final combined video has shape: {final_frames.shape}')\n\n\nthe highest (first) indexes where both wrists are above elbow and shoulder are:\n[1750, 3273, 5298, 6901, 8773, 10945]\nthe start end end indexes based on an increment of 90 is:\n[(1660, 1840), (3183, 3363), (5208, 5388), (6811, 6991), (8683, 8863), (10855, 11035)]\nOur final combined video has shape: (1080, 256, 256, 3)\n\n\n\n\n\n\n\nWe can extend the number of frames to 120 (2 seconds) before and after if we want\n\n\n\nWe have 6 total swings from our original video IMG_1090"
  },
  {
    "objectID": "posts/auto_clipper/index.html#some-functions-to-walk-through-generated-keypoints-to-find-all-swing-start-and-end-indexes",
    "href": "posts/auto_clipper/index.html#some-functions-to-walk-through-generated-keypoints-to-find-all-swing-start-and-end-indexes",
    "title": "Auto Clipping",
    "section": "### Some functions to walk through generated keypoints to find all swing start and end indexes",
    "text": "### Some functions to walk through generated keypoints to find all swing start and end indexes\n\n\nCode\ndef save_idx_df(fname, all_idx_bounds, out_dir):\n    start_idxs = [idxs[0] for idxs in all_idx_bounds]\n    end_idxs = [idxs[1] for idxs in all_idx_bounds]\n    swing_idxs = [x for x in range(len(all_idx_bounds))]\n    df = pd.DataFrame([swing_idxs, start_idxs, end_idxs], \n                 index=['swing_idx', 'start_idx', 'end_idx']).T\n    df.to_csv(f'{out_dir}/{fname}.csv', index=False)\n    return df\n\n\n\n\nCode\ndef get_swing_idx_df(kps_fpath,\n                     fname,\n                     out_dir,\n                     conf_threshold=0.7, \n                     frame_increment=90, # add 1.5 seconds before and the found idx\n                     skip_frames=900, # 900 frames is 15 seconds\n                     # ^ skips frames between swings\n                     ):\n    kps = KpExtractor(kps_fpath).keypoint_data.kps\n    higher_idxs = find_all_higher_wrist_idxs(kps, conf_threshold=conf_threshold)\n    highest_idxs = find_each_first_higher_wrist(higher_idxs, skip_frames=skip_frames) # 900 frames is 15 seconds\n    all_idx_bounds = get_all_idx_bounds(highest_idxs, frame_increment=frame_increment)\n    df = save_idx_df(fname, all_idx_bounds, out_dir)\n    return df\n\n\n\n\nCode\ndef ensure_out_dir(out_dir_fpath):\n    if not os.path.isdir(out_dir_fpath):\n        os.makedirs(out_dir_fpath)\n\ndef find_each_swing(video_path,\n                    per_second=False, # only grab every fps frame\n                    num_frames=None, #1500, # Pulls down all of the frames of video\n                    start_idx=None, #600, # None starts from 0\n                    resize_dim=(256,256),\n                    show_progress=True,\n                    model_type='vit', \n                    #out_dir='testing'\n                   ):\n    parent_dir = video_path.parent\n    fname = video_path.name.split('.')[0]\n    out_dir = f'{parent_dir}/{fname}'\n    ensure_out_dir(out_dir)                        \n    fname = video_path.name.split('.')[0]\n    frames, fps = get_frames(video_path,\n                             start_idx=start_idx,\n                             per_second=per_second, # only grab every fps frame\n                             num_frames=num_frames,#None, # Pulls down all of the frames of video\n                             resize_dim=resize_dim,\n                             show_progress=show_progress,\n                            )\n    output_filename = 'full_video.mp4'\n    out_fpath = f'{out_dir}/{output_filename}'\n    kp_fpath = f'{out_dir}/keypoints/{output_filename.split(\".\")[0]}.pkl'\n    \n    save_frames(frames=frames, fps=fps, \n            parent_dir=f'{parent_dir}/{fname}',\n            output_filename=output_filename)\n    #save_frames(frames=frames, fps=fps, fname=out_fpath)\n                       \n    process_label_video(out_fpath, out_dir=f'{out_dir}/keypoints')\n    df = get_swing_idx_df(kps_fpath=kp_fpath, fname=fname, out_dir=out_dir)\n    return df\n\n\n\n\nCode\n#fname = files[0].name.split('.')[0]\n#df = find_each_swing(files[1], start_idx=None, num_frames=1500, )#out_dir=fname)\n\n\n\nNow everything is setup so we can extract all the swing frames with one command\n\nthe entire thing is parameterized in order to make small tweaks in how much data we index around the peak\nIt should make things easier/more reproducible\n\nImagine a scenario where we decide to add some processing to videos before doing all of this, now that can be added with a function/line of code into this overall pipeline\n\nEverything should remain organizable\nScaling things up to full frame shouldn’t be a problem. we grab the frames and just clip with ffmpeg commands –&gt; label them with the labeler. 7 swings is about 20-25 seconds. This can be done in parallel ## Next up:\nProcess individual swings and apply the analysis framework\n\nWant to further build out functionality; add x-torque and others\n\nUpdate plotting functionality to make it more modular and flexible\nUltimately want to be able to point to a folder of videos and output all the plots of interest\n\n\n\nCode\ndf.head()\n\n\n\n\n\n\n\n\n\nswing_idx\nstart_idx\nend_idx\n\n\n\n\n0\n0\n1369\n1549\n\n\n\n\n\n\n\n\n\nCode\nimport ffmpeg\n\ndef make_output_filename(fname, swing_idx, score=None):\n    return f'{fname}_swing_{swing_idx}_score_{score}'\n\ndef make_clip(input_file_path, \n              output_folder_path,\n              row, \n              #duration_frames=90,  # Changed from time='0:03'\n              crf='18',\n              vcodec='libx264'):   # Changed from 'copy' since we need to use filter\n    fname = input_file_path.name.split('.')[0]\n    swing_idx, start_frame, end_frame = row.values\n    output_file_name = make_output_filename(fname, swing_idx)\n    output_file_path = f'{output_folder_path}/{fname}/{output_file_name}.mp4'\n    import pdb\n    #pdb.set_trace()\n    if os.path.isdir(output_folder_path) is False:\n        os.mkdir(output_folder_path)\n        \n    # Use trim filter for frame-accurate cutting\n    (\n        ffmpeg.input(input_file_path)\n        .trim(start_frame=start_frame, \n              end_frame=end_frame)\n        .setpts('PTS-STARTPTS')  # Reset timestamps\n        .output(output_file_path, \n                vcodec=vcodec,\n                crf=crf, \n                acodec='aac')\n        .global_args('-movflags', '+faststart')\n        .overwrite_output()\n        .run()\n    )\n\n\n\n\nCode\n# for x in range(len(df)):\n#     make_clip(input_file_path=files[1], \n#               output_folder_path=parent_dir,\n#               row = df.iloc[x]\n#              )\n\n\n\n\nCode\ndef end_to_end_detect(fpath, start_idx=None, num_frames=None):\n    df = find_each_swing(fpath, start_idx=start_idx, num_frames=num_frames,)#1500, )\n    parent_dir = fpath.parent\n    for x in range(len(df)):\n        make_clip(input_file_path=fpath, \n                  output_folder_path=parent_dir,\n                  row = df.iloc[x]\n                 )\n    return df\n\n\n\n\nCode\nfrom fastai.vision.all import *\nfrom auto_clipper import *\n\n\n\n\nCode\nbase_path = '../../../data/full_videos'\n#swing_days = ['jun8', 'aug9', 'sep14']\nfiles = get_files(f'{base_path}/david', extensions='.MOV')\nfiles\n\n\n(#6) [Path('../../../data/full_videos/david/IMG_3857.MOV'),Path('../../../data/full_videos/david/IMG_3853.MOV'),Path('../../../data/full_videos/david/IMG_3854.MOV'),Path('../../../data/full_videos/david/IMG_3855.MOV'),Path('../../../data/full_videos/david/IMG_3856.MOV'),Path('../../../data/full_videos/david/IMG_3858.MOV')]\n\n\n\n\nCode\ndef detect_then_label(files):\n    [end_to_end_detect(file) for file in files]\n    #[lbl_clips(file) for file in files]\n\n\n\n\nCode\n#detect_then_label(files)\n\n\n\n\nCode\n#end_to_end_detect(files[2])\n#end_to_end_detect(files[7])\n\n\n\n\nCode\ndef lbl_clips(fpath):\n    fname = fpath.name.split('.')[0]\n    parent_dir = fpath.parent\n    clips_folder_path = f'{parent_dir}/{fname}'\n    clipped_videos = [x.name for x in get_files(clips_folder_path, extensions='.mp4') if x.name[:3] == 'IMG']\n    for video in clipped_videos:\n        clip_video_path = f'{clips_folder_path}/{video}'\n        process_label_video(clip_video_path, \n                    out_dir=f'{clips_folder_path}/keypoints')\n\n\n\n\nCode\ndef get_output_folder(fpath):\n    return f'{fpath.parent}/{fpath.name.split(\".\")[0]}'\nget_output_folder(files[0])\n\n\n'../../../data/full_videos/david/IMG_3857'\n\n\n\n\nCode\nfor x in range(len(files)):\n    process_label_video(files[x], out_dir=get_output_folder(files[x]))\n\n\nLoads checkpoint by http backend from path: https://download.openmmlab.com/mmpose/v1/body_2d_keypoint/topdown_heatmap/coco/td-hm_ViTPose-huge_8xb64-210e_coco-256x192-e32adcd4_20230314.pth\nThe model and loaded state dict do not match exactly\n\nunexpected key in source state_dict: backbone.cls_token\n\n\n\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/importlib/__init__.py:169: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools&lt;81.\n  _bootstrap._exec(spec, module)\n\n\nLoads checkpoint by http backend from path: https://download.openmmlab.com/mmpose/v1/projects/rtmposev1/rtmdet_m_8xb32-100e_coco-obj365-person-235e8209.pth\n\n\n0it [00:00, ?it/s]/home/azaidi/Desktop/golf/tools/mmdetection/mmdet/models/layers/se_layer.py:158: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=False):\n/home/azaidi/Desktop/golf/tools/mmdetection/mmdet/models/backbones/csp_darknet.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=False):\n1255it [01:31, 13.87it/s]\n\n\n\n11/15 23:06:36 - mmengine - INFO - the output video has been saved at ../../../data/full_videos/david/IMG_3857/IMG_3857.MOV\n\n\n\n\n1256it [01:31, 13.76it/s]\n\n\nLoads checkpoint by http backend from path: https://download.openmmlab.com/mmpose/v1/body_2d_keypoint/topdown_heatmap/coco/td-hm_ViTPose-huge_8xb64-210e_coco-256x192-e32adcd4_20230314.pth\nThe model and loaded state dict do not match exactly\n\nunexpected key in source state_dict: backbone.cls_token\n\n\n\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/importlib/__init__.py:169: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools&lt;81.\n  _bootstrap._exec(spec, module)\n\n\nLoads checkpoint by http backend from path: https://download.openmmlab.com/mmpose/v1/projects/rtmposev1/rtmdet_m_8xb32-100e_coco-obj365-person-235e8209.pth\n\n\n0it [00:00, ?it/s]/home/azaidi/Desktop/golf/tools/mmdetection/mmdet/models/layers/se_layer.py:158: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=False):\n/home/azaidi/Desktop/golf/tools/mmdetection/mmdet/models/backbones/csp_darknet.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=False):\n879it [01:04, 13.44it/s]\n\n\n\n11/15 23:07:45 - mmengine - INFO - the output video has been saved at ../../../data/full_videos/david/IMG_3853/IMG_3853.MOV\n\n\n\n\n880it [01:04, 13.58it/s]\n\n\nLoads checkpoint by http backend from path: https://download.openmmlab.com/mmpose/v1/body_2d_keypoint/topdown_heatmap/coco/td-hm_ViTPose-huge_8xb64-210e_coco-256x192-e32adcd4_20230314.pth\nThe model and loaded state dict do not match exactly\n\nunexpected key in source state_dict: backbone.cls_token\n\n\n\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/importlib/__init__.py:169: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools&lt;81.\n  _bootstrap._exec(spec, module)\n\n\nLoads checkpoint by http backend from path: https://download.openmmlab.com/mmpose/v1/projects/rtmposev1/rtmdet_m_8xb32-100e_coco-obj365-person-235e8209.pth\n\n\n0it [00:00, ?it/s]/home/azaidi/Desktop/golf/tools/mmdetection/mmdet/models/layers/se_layer.py:158: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=False):\n/home/azaidi/Desktop/golf/tools/mmdetection/mmdet/models/backbones/csp_darknet.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=False):\n927it [01:12, 13.54it/s]\n\n\n\n11/15 23:09:01 - mmengine - INFO - the output video has been saved at ../../../data/full_videos/david/IMG_3854/IMG_3854.MOV\n\n\n\n\n927it [01:12, 12.84it/s]\n\n\nLoads checkpoint by http backend from path: https://download.openmmlab.com/mmpose/v1/body_2d_keypoint/topdown_heatmap/coco/td-hm_ViTPose-huge_8xb64-210e_coco-256x192-e32adcd4_20230314.pth\nThe model and loaded state dict do not match exactly\n\nunexpected key in source state_dict: backbone.cls_token\n\n\n\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/importlib/__init__.py:169: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools&lt;81.\n  _bootstrap._exec(spec, module)\n\n\nLoads checkpoint by http backend from path: https://download.openmmlab.com/mmpose/v1/projects/rtmposev1/rtmdet_m_8xb32-100e_coco-obj365-person-235e8209.pth\n\n\n0it [00:00, ?it/s]/home/azaidi/Desktop/golf/tools/mmdetection/mmdet/models/layers/se_layer.py:158: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=False):\n/home/azaidi/Desktop/golf/tools/mmdetection/mmdet/models/backbones/csp_darknet.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=False):\n1017it [01:14, 13.45it/s]\n\n\n\n11/15 23:10:19 - mmengine - INFO - the output video has been saved at ../../../data/full_videos/david/IMG_3855/IMG_3855.MOV\n\n\n\n\n1017it [01:14, 13.61it/s]\n\n\nLoads checkpoint by http backend from path: https://download.openmmlab.com/mmpose/v1/body_2d_keypoint/topdown_heatmap/coco/td-hm_ViTPose-huge_8xb64-210e_coco-256x192-e32adcd4_20230314.pth\nThe model and loaded state dict do not match exactly\n\nunexpected key in source state_dict: backbone.cls_token\n\n\n\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/importlib/__init__.py:169: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools&lt;81.\n  _bootstrap._exec(spec, module)\n\n\nLoads checkpoint by http backend from path: https://download.openmmlab.com/mmpose/v1/projects/rtmposev1/rtmdet_m_8xb32-100e_coco-obj365-person-235e8209.pth\n\n\n0it [00:00, ?it/s]/home/azaidi/Desktop/golf/tools/mmdetection/mmdet/models/layers/se_layer.py:158: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=False):\n/home/azaidi/Desktop/golf/tools/mmdetection/mmdet/models/backbones/csp_darknet.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=False):\n895it [01:05, 13.57it/s]\n\n\n\n11/15 23:11:29 - mmengine - INFO - the output video has been saved at ../../../data/full_videos/david/IMG_3856/IMG_3856.MOV\n\n\n\n\n895it [01:05, 13.62it/s]\n\n\nLoads checkpoint by http backend from path: https://download.openmmlab.com/mmpose/v1/body_2d_keypoint/topdown_heatmap/coco/td-hm_ViTPose-huge_8xb64-210e_coco-256x192-e32adcd4_20230314.pth\nThe model and loaded state dict do not match exactly\n\nunexpected key in source state_dict: backbone.cls_token\n\n\n\n/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/importlib/__init__.py:169: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools&lt;81.\n  _bootstrap._exec(spec, module)\n\n\nLoads checkpoint by http backend from path: https://download.openmmlab.com/mmpose/v1/projects/rtmposev1/rtmdet_m_8xb32-100e_coco-obj365-person-235e8209.pth\n\n\n0it [00:00, ?it/s]/home/azaidi/Desktop/golf/tools/mmdetection/mmdet/models/layers/se_layer.py:158: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=False):\n/home/azaidi/Desktop/golf/tools/mmdetection/mmdet/models/backbones/csp_darknet.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=False):\n987it [01:12, 13.44it/s]\n\n\n\n11/15 23:12:45 - mmengine - INFO - the output video has been saved at ../../../data/full_videos/david/IMG_3858/IMG_3858.MOV\n\n\n\n\n987it [01:12, 13.64it/s]"
  },
  {
    "objectID": "posts/exploratory-data-analysis/eda_nb.html",
    "href": "posts/exploratory-data-analysis/eda_nb.html",
    "title": "Initial Video Analysis",
    "section": "",
    "text": "we have 28 total videos & the file names are: \n['IMG_1014', 'IMG_1017', 'IMG_1015', 'IMG_1018', 'IMG_1023', 'IMG_1016', 'IMG_1019', 'IMG_0851', 'IMG_0855', 'IMG_0856', 'IMG_0849', 'IMG_0860', 'IMG_0857', 'IMG_0852', 'IMG_0853', 'IMG_0858', 'IMG_0859', 'IMG_0854', 'IMG_0848', 'IMG_0861', 'IMG_1090', 'IMG_1087', 'IMG_1088', 'IMG_1092', 'IMG_1086', 'IMG_1093', 'IMG_1091', 'IMG_1089']\n\n\n\n\n\n\n\n177M    ../../../data/full_videos/jun8/IMG_0856.MOV\n4.0M    ../../../data/clips/accurate/IMG_0856_swing_3_score_2.mp4\n\n\n\n\n\n\n\nCode\nclass video_metadata():\n    def __init__(self, file_path):\n        self.file_path = file_path\n        self.metadata = self.get_metadata(self.file_path)\n        self.height = self.metadata['height']\n        self.width = self.metadata['width']\n        self.fps = self.get_fps(self.metadata)\n        self.minutes = self.get_duration(self.metadata, minutes=True)\n        self.seconds = self.get_duration(self.metadata)\n        self.bitrate = self.get_bitrate(self.metadata)\n\n    def aggregate_metadata(self):\n        return {'file_name': str(self.file_path).split('/')[-1],\n                'fps': self.fps,\n                'height': self.height,\n                'width': self.width,\n                'minutes': self.minutes,\n                'seconds': self.seconds,\n                'bitrate': self.bitrate,\n                'file_path': self.file_path,\n                }\n    def get_metadata(self, file_path):\n        '''\n        Sometimes the video metadata is not in the first stream??\n        '''\n        meta_list = ffmpeg.probe(file_path)['streams']\n        for meta in meta_list:\n            try: \n                meta['height']\n                return meta\n            except:\n                pass\n                 \n    def get_fps(self, metadata):\n        fps = metadata['r_frame_rate']\n        return round(eval(fps))\n\n    def get_duration(self, metadata, minutes=False):\n        seconds = round(float(metadata['duration']))\n        # returns time in minutes\n        if minutes: \n            return seconds / 60\n        else: return seconds\n\n    def get_bitrate(self, metadata):\n        ### returns bit rate in megabyte -- divide by 1000 for Kbs and once more for Mbs\n        bitrate = int(metadata['bit_rate']) / 1000 / 1000\n        return bitrate\n\n\n\n\nCode\nvideo_metadata(video_paths[12]).aggregate_metadata()\n\n\n{'file_name': 'IMG_0857.MOV',\n 'fps': 30,\n 'height': 1080,\n 'width': 1920,\n 'minutes': 2.55,\n 'seconds': 153,\n 'bitrate': 8.605271,\n 'file_path': Path('../../../data/full_videos/jun8/IMG_0857.MOV')}\n\n\n\n\n\n\n\n\n\n\n\nfile_name\nfps\nheight\nwidth\nminutes\nseconds\nbitrate\nfile_path\n\n\n\n\n0\nIMG_0848.MOV\n30\n1080\n1920\n4.383333\n263\n8.610146\n../../../data/full_videos/jun8/IMG_0848.MOV\n\n\n1\nIMG_0849.MOV\n30\n1080\n1920\n9.200000\n552\n8.583966\n../../../data/full_videos/jun8/IMG_0849.MOV\n\n\n2\nIMG_0851.MOV\n30\n960\n540\n2.866667\n172\n4.692317\n../../../data/full_videos/jun8/IMG_0851.MOV\n\n\n3\nIMG_0852.MOV\n30\n540\n960\n2.950000\n177\n1.370111\n../../../data/full_videos/jun8/IMG_0852.MOV\n\n\n4\nIMG_0853.MOV\n30\n540\n960\n2.716667\n163\n1.367803\n../../../data/full_videos/jun8/IMG_0853.MOV\n\n\n5\nIMG_0854.MOV\n30\n1080\n1920\n2.616667\n157\n8.607743\n../../../data/full_videos/jun8/IMG_0854.MOV\n\n\n6\nIMG_0855.MOV\n30\n1080\n1920\n2.966667\n178\n8.598368\n../../../data/full_videos/jun8/IMG_0855.MOV\n\n\n7\nIMG_0856.MOV\n30\n1080\n1920\n2.783333\n167\n8.588547\n../../../data/full_videos/jun8/IMG_0856.MOV\n\n\n8\nIMG_0857.MOV\n30\n1080\n1920\n2.550000\n153\n8.605271\n../../../data/full_videos/jun8/IMG_0857.MOV\n\n\n9\nIMG_0858.MOV\n30\n568\n320\n3.050000\n183\n1.865664\n../../../data/full_videos/jun8/IMG_0858.MOV\n\n\n10\nIMG_0859.MOV\n30\n1080\n1920\n2.516667\n151\n8.624519\n../../../data/full_videos/jun8/IMG_0859.MOV\n\n\n11\nIMG_0860.MOV\n30\n1920\n1080\n1.800000\n108\n10.544283\n../../../data/full_videos/jun8/IMG_0860.MOV\n\n\n12\nIMG_0861.MOV\n30\n1080\n1920\n7.216667\n433\n8.584579\n../../../data/full_videos/jun8/IMG_0861.MOV\n\n\n13\nIMG_1014.MOV\n60\n1080\n1920\n7.400000\n444\n13.103602\n../../../data/full_videos/aug9/IMG_1014.MOV\n\n\n14\nIMG_1015.MOV\n60\n1080\n1920\n6.550000\n393\n13.103961\n../../../data/full_videos/aug9/IMG_1015.MOV\n\n\n15\nIMG_1016.MOV\n60\n1080\n1920\n5.483333\n329\n13.110048\n../../../data/full_videos/aug9/IMG_1016.MOV\n\n\n16\nIMG_1017.MOV\n60\n1080\n1920\n2.866667\n172\n13.134301\n../../../data/full_videos/aug9/IMG_1017.MOV\n\n\n17\nIMG_1018.MOV\n30\n2160\n3840\n5.250000\n315\n25.100516\n../../../data/full_videos/aug9/IMG_1018.MOV\n\n\n18\nIMG_1019.MOV\n60\n2160\n3840\n4.650000\n279\n53.182729\n../../../data/full_videos/aug9/IMG_1019.MOV\n\n\n19\nIMG_1023.MOV\n60\n2160\n3840\n6.883333\n413\n56.143823\n../../../data/full_videos/aug9/IMG_1023.MOV\n\n\n20\nIMG_1086.MOV\n60\n1920\n1080\n2.883333\n173\n15.800221\n../../../data/full_videos/sep14/IMG_1086.MOV\n\n\n21\nIMG_1087.MOV\n60\n1920\n1080\n2.833333\n170\n15.820864\n../../../data/full_videos/sep14/IMG_1087.MOV\n\n\n22\nIMG_1088.MOV\n60\n1920\n1080\n2.433333\n146\n15.823184\n../../../data/full_videos/sep14/IMG_1088.MOV\n\n\n23\nIMG_1089.MOV\n60\n1920\n1080\n4.200000\n252\n15.795585\n../../../data/full_videos/sep14/IMG_1089.MOV\n\n\n24\nIMG_1090.MOV\n60\n1920\n1080\n3.383333\n203\n15.800890\n../../../data/full_videos/sep14/IMG_1090.MOV\n\n\n25\nIMG_1091.MOV\n60\n1920\n1080\n3.750000\n225\n15.787499\n../../../data/full_videos/sep14/IMG_1091.MOV\n\n\n26\nIMG_1092.MOV\n60\n1920\n1080\n3.200000\n192\n15.800213\n../../../data/full_videos/sep14/IMG_1092.MOV\n\n\n27\nIMG_1093.MOV\n60\n1920\n1080\n3.200000\n192\n15.792813\n../../../data/full_videos/sep14/IMG_1093.MOV\n\n\n\n\n\n\n\nNow we have a quick and easily understandable way to extract all the metadata relative to our videos and get a better understaning of where outliers may lie with respect to data quality or frame rate and also to better understand the overall distribution we have amongst our data"
  },
  {
    "objectID": "posts/exploratory-data-analysis/eda_nb.html#lets-take-a-look-at-our-full-videos-and-pull-some-metadata-from-them-in-case-we-need-this-information-later-on",
    "href": "posts/exploratory-data-analysis/eda_nb.html#lets-take-a-look-at-our-full-videos-and-pull-some-metadata-from-them-in-case-we-need-this-information-later-on",
    "title": "Initial Video Analysis",
    "section": "",
    "text": "we have 28 total videos & the file names are: \n['IMG_1014', 'IMG_1017', 'IMG_1015', 'IMG_1018', 'IMG_1023', 'IMG_1016', 'IMG_1019', 'IMG_0851', 'IMG_0855', 'IMG_0856', 'IMG_0849', 'IMG_0860', 'IMG_0857', 'IMG_0852', 'IMG_0853', 'IMG_0858', 'IMG_0859', 'IMG_0854', 'IMG_0848', 'IMG_0861', 'IMG_1090', 'IMG_1087', 'IMG_1088', 'IMG_1092', 'IMG_1086', 'IMG_1093', 'IMG_1091', 'IMG_1089']\n\n\n\n\n\n\n\n177M    ../../../data/full_videos/jun8/IMG_0856.MOV\n4.0M    ../../../data/clips/accurate/IMG_0856_swing_3_score_2.mp4\n\n\n\n\n\n\n\nCode\nclass video_metadata():\n    def __init__(self, file_path):\n        self.file_path = file_path\n        self.metadata = self.get_metadata(self.file_path)\n        self.height = self.metadata['height']\n        self.width = self.metadata['width']\n        self.fps = self.get_fps(self.metadata)\n        self.minutes = self.get_duration(self.metadata, minutes=True)\n        self.seconds = self.get_duration(self.metadata)\n        self.bitrate = self.get_bitrate(self.metadata)\n\n    def aggregate_metadata(self):\n        return {'file_name': str(self.file_path).split('/')[-1],\n                'fps': self.fps,\n                'height': self.height,\n                'width': self.width,\n                'minutes': self.minutes,\n                'seconds': self.seconds,\n                'bitrate': self.bitrate,\n                'file_path': self.file_path,\n                }\n    def get_metadata(self, file_path):\n        '''\n        Sometimes the video metadata is not in the first stream??\n        '''\n        meta_list = ffmpeg.probe(file_path)['streams']\n        for meta in meta_list:\n            try: \n                meta['height']\n                return meta\n            except:\n                pass\n                 \n    def get_fps(self, metadata):\n        fps = metadata['r_frame_rate']\n        return round(eval(fps))\n\n    def get_duration(self, metadata, minutes=False):\n        seconds = round(float(metadata['duration']))\n        # returns time in minutes\n        if minutes: \n            return seconds / 60\n        else: return seconds\n\n    def get_bitrate(self, metadata):\n        ### returns bit rate in megabyte -- divide by 1000 for Kbs and once more for Mbs\n        bitrate = int(metadata['bit_rate']) / 1000 / 1000\n        return bitrate\n\n\n\n\nCode\nvideo_metadata(video_paths[12]).aggregate_metadata()\n\n\n{'file_name': 'IMG_0857.MOV',\n 'fps': 30,\n 'height': 1080,\n 'width': 1920,\n 'minutes': 2.55,\n 'seconds': 153,\n 'bitrate': 8.605271,\n 'file_path': Path('../../../data/full_videos/jun8/IMG_0857.MOV')}\n\n\n\n\n\n\n\n\n\n\n\nfile_name\nfps\nheight\nwidth\nminutes\nseconds\nbitrate\nfile_path\n\n\n\n\n0\nIMG_0848.MOV\n30\n1080\n1920\n4.383333\n263\n8.610146\n../../../data/full_videos/jun8/IMG_0848.MOV\n\n\n1\nIMG_0849.MOV\n30\n1080\n1920\n9.200000\n552\n8.583966\n../../../data/full_videos/jun8/IMG_0849.MOV\n\n\n2\nIMG_0851.MOV\n30\n960\n540\n2.866667\n172\n4.692317\n../../../data/full_videos/jun8/IMG_0851.MOV\n\n\n3\nIMG_0852.MOV\n30\n540\n960\n2.950000\n177\n1.370111\n../../../data/full_videos/jun8/IMG_0852.MOV\n\n\n4\nIMG_0853.MOV\n30\n540\n960\n2.716667\n163\n1.367803\n../../../data/full_videos/jun8/IMG_0853.MOV\n\n\n5\nIMG_0854.MOV\n30\n1080\n1920\n2.616667\n157\n8.607743\n../../../data/full_videos/jun8/IMG_0854.MOV\n\n\n6\nIMG_0855.MOV\n30\n1080\n1920\n2.966667\n178\n8.598368\n../../../data/full_videos/jun8/IMG_0855.MOV\n\n\n7\nIMG_0856.MOV\n30\n1080\n1920\n2.783333\n167\n8.588547\n../../../data/full_videos/jun8/IMG_0856.MOV\n\n\n8\nIMG_0857.MOV\n30\n1080\n1920\n2.550000\n153\n8.605271\n../../../data/full_videos/jun8/IMG_0857.MOV\n\n\n9\nIMG_0858.MOV\n30\n568\n320\n3.050000\n183\n1.865664\n../../../data/full_videos/jun8/IMG_0858.MOV\n\n\n10\nIMG_0859.MOV\n30\n1080\n1920\n2.516667\n151\n8.624519\n../../../data/full_videos/jun8/IMG_0859.MOV\n\n\n11\nIMG_0860.MOV\n30\n1920\n1080\n1.800000\n108\n10.544283\n../../../data/full_videos/jun8/IMG_0860.MOV\n\n\n12\nIMG_0861.MOV\n30\n1080\n1920\n7.216667\n433\n8.584579\n../../../data/full_videos/jun8/IMG_0861.MOV\n\n\n13\nIMG_1014.MOV\n60\n1080\n1920\n7.400000\n444\n13.103602\n../../../data/full_videos/aug9/IMG_1014.MOV\n\n\n14\nIMG_1015.MOV\n60\n1080\n1920\n6.550000\n393\n13.103961\n../../../data/full_videos/aug9/IMG_1015.MOV\n\n\n15\nIMG_1016.MOV\n60\n1080\n1920\n5.483333\n329\n13.110048\n../../../data/full_videos/aug9/IMG_1016.MOV\n\n\n16\nIMG_1017.MOV\n60\n1080\n1920\n2.866667\n172\n13.134301\n../../../data/full_videos/aug9/IMG_1017.MOV\n\n\n17\nIMG_1018.MOV\n30\n2160\n3840\n5.250000\n315\n25.100516\n../../../data/full_videos/aug9/IMG_1018.MOV\n\n\n18\nIMG_1019.MOV\n60\n2160\n3840\n4.650000\n279\n53.182729\n../../../data/full_videos/aug9/IMG_1019.MOV\n\n\n19\nIMG_1023.MOV\n60\n2160\n3840\n6.883333\n413\n56.143823\n../../../data/full_videos/aug9/IMG_1023.MOV\n\n\n20\nIMG_1086.MOV\n60\n1920\n1080\n2.883333\n173\n15.800221\n../../../data/full_videos/sep14/IMG_1086.MOV\n\n\n21\nIMG_1087.MOV\n60\n1920\n1080\n2.833333\n170\n15.820864\n../../../data/full_videos/sep14/IMG_1087.MOV\n\n\n22\nIMG_1088.MOV\n60\n1920\n1080\n2.433333\n146\n15.823184\n../../../data/full_videos/sep14/IMG_1088.MOV\n\n\n23\nIMG_1089.MOV\n60\n1920\n1080\n4.200000\n252\n15.795585\n../../../data/full_videos/sep14/IMG_1089.MOV\n\n\n24\nIMG_1090.MOV\n60\n1920\n1080\n3.383333\n203\n15.800890\n../../../data/full_videos/sep14/IMG_1090.MOV\n\n\n25\nIMG_1091.MOV\n60\n1920\n1080\n3.750000\n225\n15.787499\n../../../data/full_videos/sep14/IMG_1091.MOV\n\n\n26\nIMG_1092.MOV\n60\n1920\n1080\n3.200000\n192\n15.800213\n../../../data/full_videos/sep14/IMG_1092.MOV\n\n\n27\nIMG_1093.MOV\n60\n1920\n1080\n3.200000\n192\n15.792813\n../../../data/full_videos/sep14/IMG_1093.MOV\n\n\n\n\n\n\n\nNow we have a quick and easily understandable way to extract all the metadata relative to our videos and get a better understaning of where outliers may lie with respect to data quality or frame rate and also to better understand the overall distribution we have amongst our data"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Eagle Swing Takes Off",
    "section": "",
    "text": "This is the first post in the R&D page for Eagle Swing. Welcome!\n\nThe idea behind Eagle Swing is simple, some days you have a good day at the range and sometimes you can’t figure out all the things you’re off on. Here, we take in a recorded video of a driving range session and then after processing the video with our models –&gt; we can generate insights into what you are doing when you hit your best swing compared to those swings where you can’t seem to connect.\nThis repo and website will be organized in a specific fashion, in creating the end product, we’ll run into a ton of questions along the way that need to be answered. In this pursuit, each notebook/post will be featuring a specific problem that needs further exploration, sometimes code will be generated within the notebook for further use, while sometimes that code will be only useful for the small and specific purpose of the task at hand."
  },
  {
    "objectID": "posts/swing_dataclass/index.html",
    "href": "posts/swing_dataclass/index.html",
    "title": "Swing DataClass",
    "section": "",
    "text": "- The angle of the hips and shoulders\n- The angle of joints (wrist, elbow + hand)\n- Club head information\n\n\n\n\nCode\nfrom typing import TypeVar, Generic, List, Optional, Callable\nfrom dataclasses import dataclass, field\nimport numpy as np\nimport pickle\nimport cv2\n\n\n\n\nCode\nclass SwingMetaData:\n    \"\"\"Data Container for a swings video metadata\n    \"\"\"\n    def __init__(self,\n                 path: str,\n                 get_swing_idx=False,\n                 get_score=False,\n                 ):\n        \"\"\"\n        Initialize the swing data and associated metadata\n        \n        Args:\n            path: file_path to data\n        \"\"\"\n        self.path = path\n        self.str_path = self.get_str_path()\n        self.video_path = f'{self.str_path.split(\".\")[-2]}.mp4'\n        self.file_name = self.str_path.split('/')[-1].split('.')[0]\n        if get_swing_idx:\n            self.swing_idx = int(self.file_name.split('_')[-3])\n        if get_score:\n            self.score = self.file_name.split('_')[-1].split('.')[0]\n\n    def get_str_path(self):\n        # Just making sure the path being used is a str + not path object\n        return str(self.path)\n\n    def get_video_name(self):\n        video = '_'.join(self.str_path.split('/')[1].split('_')[:2])\n        return video\n\n\n\n\nCode\nswing_meta.str_path.split('.')[-2]\n\n\n'/data/full_videos/ymirza/sep14/IMG_1093/keypoints/IMG_1093_swing_6_score_None'\n\n\n\n\nCode\nswing_meta = SwingMetaData(files[0], get_swing_idx=True, get_score=True)\nprint(f'Our meta class can store useful information like the filename \\n ---&gt;\\\n {swing_meta.file_name}')\nprint(f'Also the swing index \\n ---&gt;\\\n {swing_meta.swing_idx}')\nprint(f'And the score (when added) \\n ---&gt;\\\n {swing_meta.score}')\nprint(f'For plotting and output purposes, a path to our labeled video is also available')\n\n\nOur meta class can store useful information like the filename \n ---&gt; IMG_1093_swing_6_score_None\nAlso the swing index \n ---&gt; 6\nAnd the score (when added) \n ---&gt; None\nFor plotting and output purposes, a path to our labeled video is also available\n\n\n\n\nCode\nclass SwingKeypointData(SwingMetaData):\n    \"\"\"\n    Class to handle keypoint data\n    Will take a videos metadata and pull down keypoint values and scores\n    \"\"\"\n    \n    def __init__(self, video_path):\n        super().__init__(video_path)\n        #self.metadata = metadata\n        self.kp_dicts = self.get_kp_dicts()\n        self.key_points = self.get_keypoints()\n        self.scores = self.get_scores()\n        self.kps = np.concatenate([self.key_points, np.expand_dims(self.scores, -1)], axis=2)\n\n\n    def get_kp_dicts(self):\n        # Get the frame by frame output dicts from pose estimation models\n        with open(self.str_path, 'rb') as f:\n            loaded_dicts = pickle.load(f)\n        return loaded_dicts\n\n        \n    def get_keypoints(self):\n        kp_dicts = self.kp_dicts\n        return np.stack([self.kp_dicts[key]['keypoints'] for key in kp_dicts.keys()])\n        \n        \n    def get_scores(self):\n        kp_dicts = self.kp_dicts\n        return np.stack([self.kp_dicts[key]['keypoint_scores'] for key in kp_dicts.keys()])\n\n\n    def get_frame(self, idx):\n        ''' Just grabs a single frames keypoints and scores\n        '''\n        kps = self.key_points[idx]\n        scores = self.scores[idx]\n        return np.column_stack((kps, scores))\n\n    \n    def get_frames(self, indexes):\n        '''\n        num_idxs = len(Indexes)\n        Takes a list of indexes and returns an array wof [num_idxs, 17, 3]\n        [1] 17 keypoint markers\n        [2] 3 keypoint values/certaintainty (X, Y, Score)\n        '''\n        return np.stack([self.get_frame(idx) for idx in indexes])\n\n    \n    def __len__(self):\n        return len(self.key_points)\n\n\n\n\nwith our SwingKeyPointData class, we can store the raw keypoint values\nA swings full keypoints/confidence array would have shape: (180, 17, 3)\nIf we want to access just the keypoints we can we can access \n    the \"key_points\" attribute: (180, 17, 2)\nIf we are interested in seeing just confidence values we can access \n    the \"scores\" attribute: (180, 17)"
  },
  {
    "objectID": "posts/swing_dataclass/index.html#after-normalization-our-get_distance-returns-values-like-0.99-99-of-torso-length-instead-of-158-pixels",
    "href": "posts/swing_dataclass/index.html#after-normalization-our-get_distance-returns-values-like-0.99-99-of-torso-length-instead-of-158-pixels",
    "title": "Swing DataClass",
    "section": "After normalization, our get_distance() returns values like 0.99 (99% of torso length) instead of 158 pixels",
    "text": "After normalization, our get_distance() returns values like 0.99 (99% of torso length) instead of 158 pixels\n\nEnabling direct comparison between different recording setups\n\n\nCode\ndef normalize_by_torso_diagonal(kps, l_sh_to_r_hip=True):\n    if l_sh_to_r_hip: #left shoulder to right hip\n        shoulder = kps.l_sh\n        hip = kps.r_hi\n    else:\n        shoulder = kps.r_sh\n        hip = kps.l_hi\n    \n    torso_diagonal = np.sqrt(np.sum((shoulder - hip)**2, axis=1))\n    normalized_kps = kps.kps / torso_diagonal[:, np.newaxis, np.newaxis]\n    \n    return normalized_kps\n\n\n\n\nCode\nleft_to_right = normalize_by_torso_diagonal(kp_0, l_sh_to_r_hip=True)\n#right_to_left = normalize_by_torso_diagonal(kp_0, l_sh_to_r_hip=False)\n\n\n\n\nCode\ndef normalize_by_average_torso(kps):\n    left_shoulder = kps.l_sh\n    right_shoulder = kps.r_sh\n    left_hip = kps.l_hi\n    right_hip = kps.r_hi\n    \n    diagonal1 = np.sqrt(np.sum((left_shoulder - right_hip)**2, axis=1))\n    diagonal2 = np.sqrt(np.sum((right_shoulder - left_hip)**2, axis=1))\n    avg_torso = (diagonal1 + diagonal2) / 2.0\n    return kps.kps / avg_torso[:, np.newaxis, np.newaxis]\n\nnormalize_by_average_torso(kp_0).shape\n\n\n(180, 17, 3)\n\n\n\n\nOk so we have some distance and angle functionality and we also have a way to normalize our keypoints so lets add the potential for some additional geometric relationships\n\nVector level features between two points with a unit vector\n\ntells you where second point is relative to the first  ** Independent of distance\n\nAngle between segments –&gt; use joint angles ABC to find angle @ B\n\nelbow angle (shoulder, elbow, wrist)\nwrist cock (forearm - club shaft angle)\nspine angle (hip - shoulder - head)\n\nPose relative / frame-relative geormetry\n\nInstead of absolute coordianates, make everything relative to some anchor \n\nsubtract pelvis/hip center from all key points \nOPTIONALLY: rotate coordinates so shoulders define a horizontal “body x-axis”   * Gives us features that are:  \ntranslation-invariant (location in frame irrelevant)\ncloser to “true” body pose, especially if the camera jitters \n\n\nSigned area / “rotation” type features (points ABC)\n\nSigned area + cross product tells us: - How “curved” or rotated the triplet is - On which side one point lies relative to a line ** Will help when detecting: **\nopen vs closed shoulders/hips\nleft vs right tilt etc\n\n\n\n\nAll of that is useful but since we’re working with sequence data of a video, we can’t leave out changes over time of how these keypoints evolve in the swing\n- Velocity of distance\n    - how fast two points are moving apart and closer\n- Velocity of angle\n    - Angular speed of a joint -- is the right elbow hitting 90 degrees faster on a 5 swing that a 1 swing?\n- Acceleration of distance and angle:\n    - the second derivative tells you the rate of change of velocity, could be useful at transition points and much more\n    --&gt; https://www.perplexity.ai/search/58255efe-03e6-48b0-87c3-0ffdc6c75edf"
  },
  {
    "objectID": "posts/analyze/analysis.html",
    "href": "posts/analyze/analysis.html",
    "title": "Kinematic Analysis",
    "section": "",
    "text": "We have 47 total swings from sep14\n\n\n\n\nCode\ndef get_kps(folder):\n    all_files = get_files(folder, extensions='.pkl')\n    clip_files = [file for file in all_files if file.name[:3] == 'IMG']\n    return clip_files\n\n\ndef flatten_stacked_list(nonflat_list):\n    flattened_list = list(chain.from_iterable(nonflat_list))\n    return flattened_list\n\n\ndef get_all_swings_df(flat_kp_path_list):\n    path_list_series =  pd.Series(flat_kp_path_list)\n    kp_fname = path_list_series.map(lambda x: str(x).split('/')[-1])\n    video_name = kp_fname.map(lambda x: '_'.join(str(x).split('_')[:2]))\n    swing_idx = kp_fname.map(lambda x: str(x).split('_')[3])\n    df = pd.DataFrame([video_name, swing_idx, \n                       kp_fname, path_list_series],\n                      index=['video_name','swing_idx', \n                             'kp_fname', 'kp_fpath']\n                      ).T\n    return df\n\n\n\n\nCode\nall_swings_df = get_all_swings_df(flat_kp_file_list)\nall_swings_df.head(3)\n\n\n\n\n\n\n\n\n\nvideo_name\nswing_idx\nkp_fname\nkp_fpath\n\n\n\n\n0\nIMG_1093\n6\nIMG_1093_swing_6_score_None.pkl\n../../../data/full_videos/ymirza/sep14/IMG_1093/keypoints/IMG_1093_swing_6_score_None.pkl\n\n\n1\nIMG_1093\n5\nIMG_1093_swing_5_score_None.pkl\n../../../data/full_videos/ymirza/sep14/IMG_1093/keypoints/IMG_1093_swing_5_score_None.pkl\n\n\n2\nIMG_1093\n4\nIMG_1093_swing_4_score_None.pkl\n../../../data/full_videos/ymirza/sep14/IMG_1093/keypoints/IMG_1093_swing_4_score_None.pkl\n\n\n\n\n\n\n\n\n\nCode\n### 99 —&gt; prctice swing w/o score\nsep14_scores = {\n    \"IMG_1086\" : [2, 1, 1, 5, 5], #5\n    \"IMG_1087\" : [4, 5, 2, 1, 2],# 5\n    \"IMG_1088\" : [1, 1, 3, 3, 2],# 5\n    \"IMG_1089\" : [4, 3, 3, 4, 3, 4, 3], #7\n    \"IMG_1090\" : [4, 1, 4, 1, 1, 1], #6\n    \"IMG_1091\" : [2, 2, 5, 2, 4, 1], \n                #6 - 7 w/practice --&gt; start 30 seconds in\n    \"IMG_1092\" : [4, 1, 4, 1, 1, 1,], # 6\n    \"IMG_1093\" : [1, 3, 1, 2, 1, 99, 2],\n    # 6 - 7 w/practice --&gt; just drop second to last clip\n    }\n\n\n\nThere are two instances of practice swings without hitting the ball and without a score, they are marked below,\n\nIMG_1091 there is a practice swing at start of video\n- Easily taken care of by starting the autodetect function 30 seconds into the video -- no longer accounted for in the 47 total\n\n\nIMG_1093 there is a practice swing on the second to last swing\n- this doesn't interfere with autodetect finding last swting, so we can just ignore that second to last swing in our anaylsis (swing_idx 5)\n- therefore only 46 swings\n\n\n\nThis could maybe be easily tackled by also checking for a score hand (right hand up left hand below shoulder and then checking backwards towards a swing, if there’s no swing in between that next hand and this swing, you know this is not a practice swing)\n\n\nCode\nlist(range(1,6,1))\n\n\n[1, 2, 3, 4]\n\n\n\n\nMost of the swings on this day were scored 1\nscores\n1     17\n2      9\n4      9\n3      7\n5      4\n99     1\nName: count, dtype: int64\n\n\n\n\nCode\ntop_idxs = [get_frame_plot(x[30:])[0] + 30 for x in test_kps]\nlowest_frame_count = np.array([kp.shape[0] for kp in test_kps]).min()\nhighest_peak_frame = np.array(top_idxs).max()\ndiff = lowest_frame_count - highest_peak_frame\nstart_idx = highest_peak_frame - diff\nend_idx = highest_peak_frame + diff\nprint(f'The frame index where the straight arm is found \\\nin the backswing are: {top_idxs}')\nprint(f'The highest peak frame where this is found is: {highest_peak_frame}')\nprint(f'The lowest frame count in any of our clips is: {lowest_frame_count}')\nprint(f'We have a difference of {diff} frames between where this happens')\nprint(f'The indexes we will use to index all these videos are:\\n \\\nstart:{start_idx} and end:{end_idx}')\n\n\nThe frame index where the straight arm is found in the backswing are: [131, 138, 136, 133, 136, 141]\nThe highest peak frame where this is found is: 141\nThe lowest frame count in any of our clips is: 180\nWe have a difference of 39 frames between where this happens\nThe indexes we will use to index all these videos are:\n start:102 and end:180\n\n\n\n\nCode\n# code-fold:True\nfig, axes = plot_upper_body_comparison(\n    kps_list=[x[...,:2][10:45] for x in test_kps],\n    scores_list=[x[...,2][10:45] for x in test_kps],\n    labels=plot_lbls,\n    params=UpperPlotParams(handedness=\"right\", smooth_win=5, fps=60.0),\n    title=\"Swing Comparison - Upper Body\"\n)\n\n\n\n\n\n\n\n\n\n\n\nCode\nfig, axes = plot_lower_body_detailed(\n    kps_list=[x[...,:2][10:45] for x in test_kps],\n    scores_list=[x[...,2][10:45] for x in test_kps],\n    labels=plot_lbls,\n    params=PlotParams(handedness=\"right\", smooth_win=5, fps=60.0),\n    title=\"Swing Comparison - Lower Body\"\n)"
  },
  {
    "objectID": "posts/manual_clipping/00a_data_clipping.html",
    "href": "posts/manual_clipping/00a_data_clipping.html",
    "title": "Video Clipping",
    "section": "",
    "text": "1) csv with the appropriate information about original videos, swings\n2) ffmpeg commands that will dictate how the video is decoded/encoded to generate the clips\n     - Since videos are from an iphone --&gt; there are some peculiarities to consider: \n         - https://www.perplexity.ai/search/8176d69e-475a-4e7f-ba07-0b762adb7c65\nWe'll then create an appropriate clipped folder within folder holding all the full videos from a specific date\n\n\nCode\nbase_path = '../../../data/full_videos'\nswing_days = ['jun8', 'aug9', 'sep14']\nfiles = get_files(f'{base_path}/{swing_days[0]}', extensions='.MOV')\nlen(files), files[0]\n\n\n(13, Path('../../../data/full_videos/jun8/IMG_0851.MOV'))\n\n\n\n\nCode\ndf_jun8 = pd.read_csv(f'{base_path}/{swing_days[0]}/cleaned.csv').reset_index(drop=True)\ndf_aug9 = pd.read_csv(f'{base_path}/{swing_days[1]}/cleaned.csv').reset_index(drop=True)\ndf_sep14 = pd.read_csv(f'{base_path}/{swing_days[2]}/cleaned.csv').reset_index(drop=True)\ndf_jun8.head(1)\n\n\n\n\n\n\n\n\n\ninput_file\nswing_index\nscore\nstart\nend\noutput_file\n\n\n\n\n0\nIMG_0848.MOV\n0\n2\n00:20\n00:23\nIMG_0848_swing_0_score_2.mp4\n\n\n\n\n\n\n\n\n\nCode\n# just checking that the dataframe columns are the same\nassert((df_aug9.columns == df_jun8.columns).sum() == len(df_aug9.columns))\nassert((df_aug9.columns == df_sep14.columns).sum() == len(df_aug9.columns))\n\n\n\n\nCode\n## All the necessary code to take a dataframe and clip the videos however we need\n\ndef clip_videos(df, \n                input_path, \n                crf='18',\n                video_encoder='copy',\n                debug=False):\n    output_folder_path = f'{input_path}/crf_{crf}_vcodec_{video_encoder}'\n    for idx in range(len(df)):\n        make_clip(input_folder_path=input_path, \n                  output_folder_path=output_folder_path,\n                  row=df.iloc[idx],\n                 crf=crf,\n                 vcodec=video_encoder)\n        if debug: break\n    assert(len(os.listdir(output_folder_path)) == len(df))\n\ndef make_output_filename(row):\n    return f'{row.input_file.split(\".\")[0]}_swing_{row.swing_index}_score_{row.score}.mp4'\n\ndef make_clip(input_folder_path, \n              output_folder_path,\n              row, \n              time='0:03',\n              crf='18',\n              vcodec='copy'):\n    input_file_name = row.input_file\n    output_file_name = make_output_filename(row)\n    start = row.start\n    input_file_path = f'{input_folder_path}/{input_file_name}'\n    output_file_path = f'{output_folder_path}/{output_file_name}'\n    if os.path.isdir(output_folder_path) is False:\n        os.mkdir(output_folder_path)\n    ffmpeg.input(input_file_path, \n                 ss=start)\\\n        .output(output_file_path, \n                t=time, \n                vcodec=vcodec,\n                crf=crf, \n                acodec='aac',\n                y=None) \\\n        .global_args('-movflags', '+faststart') \\\n        .run()\n\n\n\n\nCode\n#clip_videos(df_sep14, input_path=f'{base_path}/{swing_days[2]}', video_encoder='libx264', crf=0)\n\n\n\n\nCode\n## clip_videos(df_aug9, input_path=f'{base_path}/{swing_days[1]}', video_encoder='libx264', crf=0)\n\n\n\n\nCode\n! python\n\n\nPython 3.10.11 (main, May 16 2023, 00:28:57) [GCC 11.2.0] on linux\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n&gt;&gt;&gt; \nTraceback (most recent call last):\n  File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\nKeyboardInterrupt\n&gt;&gt;&gt; \n\n\n\n\nCode\n#clip_videos(df_aug9, input_path=f'{base_path}/{swing_days[1]}')\n\n\n\n\nCode\n#clip_videos(df_sep14, input_path=f'{base_path}/{swing_days[2]}')"
  },
  {
    "objectID": "posts/manual_clipping/00a_data_clipping.html#lets-work-on-creating-a-programmatic-way-to-receive-clip-full-videos-into-clips-of-individual-swings",
    "href": "posts/manual_clipping/00a_data_clipping.html#lets-work-on-creating-a-programmatic-way-to-receive-clip-full-videos-into-clips-of-individual-swings",
    "title": "Video Clipping",
    "section": "",
    "text": "1) csv with the appropriate information about original videos, swings\n2) ffmpeg commands that will dictate how the video is decoded/encoded to generate the clips\n     - Since videos are from an iphone --&gt; there are some peculiarities to consider: \n         - https://www.perplexity.ai/search/8176d69e-475a-4e7f-ba07-0b762adb7c65\nWe'll then create an appropriate clipped folder within folder holding all the full videos from a specific date\n\n\nCode\nbase_path = '../../../data/full_videos'\nswing_days = ['jun8', 'aug9', 'sep14']\nfiles = get_files(f'{base_path}/{swing_days[0]}', extensions='.MOV')\nlen(files), files[0]\n\n\n(13, Path('../../../data/full_videos/jun8/IMG_0851.MOV'))\n\n\n\n\nCode\ndf_jun8 = pd.read_csv(f'{base_path}/{swing_days[0]}/cleaned.csv').reset_index(drop=True)\ndf_aug9 = pd.read_csv(f'{base_path}/{swing_days[1]}/cleaned.csv').reset_index(drop=True)\ndf_sep14 = pd.read_csv(f'{base_path}/{swing_days[2]}/cleaned.csv').reset_index(drop=True)\ndf_jun8.head(1)\n\n\n\n\n\n\n\n\n\ninput_file\nswing_index\nscore\nstart\nend\noutput_file\n\n\n\n\n0\nIMG_0848.MOV\n0\n2\n00:20\n00:23\nIMG_0848_swing_0_score_2.mp4\n\n\n\n\n\n\n\n\n\nCode\n# just checking that the dataframe columns are the same\nassert((df_aug9.columns == df_jun8.columns).sum() == len(df_aug9.columns))\nassert((df_aug9.columns == df_sep14.columns).sum() == len(df_aug9.columns))\n\n\n\n\nCode\n## All the necessary code to take a dataframe and clip the videos however we need\n\ndef clip_videos(df, \n                input_path, \n                crf='18',\n                video_encoder='copy',\n                debug=False):\n    output_folder_path = f'{input_path}/crf_{crf}_vcodec_{video_encoder}'\n    for idx in range(len(df)):\n        make_clip(input_folder_path=input_path, \n                  output_folder_path=output_folder_path,\n                  row=df.iloc[idx],\n                 crf=crf,\n                 vcodec=video_encoder)\n        if debug: break\n    assert(len(os.listdir(output_folder_path)) == len(df))\n\ndef make_output_filename(row):\n    return f'{row.input_file.split(\".\")[0]}_swing_{row.swing_index}_score_{row.score}.mp4'\n\ndef make_clip(input_folder_path, \n              output_folder_path,\n              row, \n              time='0:03',\n              crf='18',\n              vcodec='copy'):\n    input_file_name = row.input_file\n    output_file_name = make_output_filename(row)\n    start = row.start\n    input_file_path = f'{input_folder_path}/{input_file_name}'\n    output_file_path = f'{output_folder_path}/{output_file_name}'\n    if os.path.isdir(output_folder_path) is False:\n        os.mkdir(output_folder_path)\n    ffmpeg.input(input_file_path, \n                 ss=start)\\\n        .output(output_file_path, \n                t=time, \n                vcodec=vcodec,\n                crf=crf, \n                acodec='aac',\n                y=None) \\\n        .global_args('-movflags', '+faststart') \\\n        .run()\n\n\n\n\nCode\n#clip_videos(df_sep14, input_path=f'{base_path}/{swing_days[2]}', video_encoder='libx264', crf=0)\n\n\n\n\nCode\n## clip_videos(df_aug9, input_path=f'{base_path}/{swing_days[1]}', video_encoder='libx264', crf=0)\n\n\n\n\nCode\n! python\n\n\nPython 3.10.11 (main, May 16 2023, 00:28:57) [GCC 11.2.0] on linux\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n&gt;&gt;&gt; \nTraceback (most recent call last):\n  File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\nKeyboardInterrupt\n&gt;&gt;&gt; \n\n\n\n\nCode\n#clip_videos(df_aug9, input_path=f'{base_path}/{swing_days[1]}')\n\n\n\n\nCode\n#clip_videos(df_sep14, input_path=f'{base_path}/{swing_days[2]}')"
  },
  {
    "objectID": "posts/manual_clipping/00a_data_clipping.html#now-some-code-to-pull-down-the-frames",
    "href": "posts/manual_clipping/00a_data_clipping.html#now-some-code-to-pull-down-the-frames",
    "title": "Video Clipping",
    "section": "Now some code to pull down the frames",
    "text": "Now some code to pull down the frames\n\n\nCode\ndef get_frames(swing_path, \n               resize=True, \n               width=256, \n               height=256,\n               debug=False):\n    capture = cv2.VideoCapture(swing_path)\n    frame_count = int(capture.get(cv2.CAP_PROP_FRAME_COUNT))\n    frame_width = int(capture.get(cv2.CAP_PROP_FRAME_WIDTH))\n    frame_height = int(capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n    video_array = np.empty((frame_count, frame_height, frame_width, 3), dtype=np.uint8)\n    idx = 0\n    while idx &lt; frame_count:\n        ret, frame = capture.read()\n        if not ret:\n            break\n        video_array[idx] = frame\n        idx += 1\n\n    capture.release()\n    if debug:\n        print(video_array.shape)\n    video_array = [convert_rgb(frame) for frame in video_array]\n    if resize:\n        video_array = np.array([resize_frame(frame, width, height) for frame in video_array])\n    return video_array\n\ndef resize_frame(frame, width=256, height=256):\n    return cv2.resize(frame, (width, height))\n\ndef convert_rgb(frame):\n    return cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n\ndef plot_three(image1, image2, image3=None):\n    # Create figure with 1 row, 3 columns of subplots\n    if image3 is None:\n        fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n    else:\n        fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n\n    # Plot each image on its respective axis\n    axes[0].imshow(image1)\n    axes[0].set_title('Frame 1')\n    axes[0].axis('off')  # Remove axis ticks and labels\n\n    axes[1].imshow(image2)\n    axes[1].set_title('Frame 2')\n    axes[1].axis('off')\n\n    if image3 is not None:\n        axes[2].imshow(image3)\n        axes[2].set_title('Frame 3 or Diff')\n        axes[2].axis('off')\n\n    plt.tight_layout()  # Adjust spacing between subplots\n    plt.show()\n\n\n\n\nCode\njun8_files = get_files(f'{base_path}/jun8/crf_18_vcodec_copy')\naug19_files = get_files(f'{base_path}/aug9/crf_18_vcodec_copy')\nsep14_files = get_files(f'{base_path}/sep14/crf_18_vcodec_copy')\nlen(jun8_files), len(aug19_files), len(sep14_files)\n\n\n(85, 78, 46)\n\n\n\n\nCode\njun_files_18 = get_files(f'{base_path}/jun8/crf_18_vcodec_copy')\njun_files_0 = get_files(f'{base_path}/jun8/crf_0_vcodec_libx264')\n\n\n\n\nCode\njun_files_18[0], jun_files_0[0]\n\n\n(Path('../../../data/full_videos/jun8/crf_18_vcodec_copy/IMG_0848_swing_0_score_2.mp4'),\n Path('../../../data/full_videos/jun8/crf_0_vcodec_libx264/IMG_0848_swing_0_score_2.mp4'))\n\n\n\n\nCode\naug19_files\n\n\n(#78) [Path('../../../data/full_videos/aug9/crf_18_vcodec_copy/IMG_1014_swing_10_score_1.mp4'),Path('../../../data/full_videos/aug9/crf_18_vcodec_copy/IMG_1023_swing_4_score_5.mp4'),Path('../../../data/full_videos/aug9/crf_18_vcodec_copy/IMG_1015_swing_10_score_4.mp4'),Path('../../../data/full_videos/aug9/crf_18_vcodec_copy/IMG_1015_swing_6_score_1.mp4'),Path('../../../data/full_videos/aug9/crf_18_vcodec_copy/IMG_1018_swing_0_score_4.mp4'),Path('../../../data/full_videos/aug9/crf_18_vcodec_copy/IMG_1023_swing_0_score_1.mp4'),Path('../../../data/full_videos/aug9/crf_18_vcodec_copy/IMG_1023_swing_13_score_3.mp4'),Path('../../../data/full_videos/aug9/crf_18_vcodec_copy/IMG_1017_swing_2_score_4.mp4'),Path('../../../data/full_videos/aug9/crf_18_vcodec_copy/IMG_1014_swing_5_score_3.mp4'),Path('../../../data/full_videos/aug9/crf_18_vcodec_copy/IMG_1023_swing_12_score_1.mp4'),Path('../../../data/full_videos/aug9/crf_18_vcodec_copy/IMG_1019_swing_7_score_1.mp4'),Path('../../../data/full_videos/aug9/crf_18_vcodec_copy/IMG_1014_swing_6_score_2.mp4'),Path('../../../data/full_videos/aug9/crf_18_vcodec_copy/IMG_1015_swing_1_score_1.mp4'),Path('../../../data/full_videos/aug9/crf_18_vcodec_copy/IMG_1018_swing_3_score_2.mp4'),Path('../../../data/full_videos/aug9/crf_18_vcodec_copy/IMG_1023_swing_5_score_5.mp4'),Path('../../../data/full_videos/aug9/crf_18_vcodec_copy/IMG_1015_swing_8_score_1.mp4'),Path('../../../data/full_videos/aug9/crf_18_vcodec_copy/IMG_1018_swing_9_score_5.mp4'),Path('../../../data/full_videos/aug9/crf_18_vcodec_copy/IMG_1014_swing_13_score_3.mp4'),Path('../../../data/full_videos/aug9/crf_18_vcodec_copy/IMG_1017_swing_4_score_5.mp4'),Path('../../../data/full_videos/aug9/crf_18_vcodec_copy/IMG_1016_swing_0_score_4.mp4')...]\n\n\n\n\nCode\nVideo(aug19_files[0], width=200, height=300)\n\n\n\n      Your browser does not support the video element.\n    \n\n\n\n\nCode\nVideo(jun8_files[0], width=200, height=300)\n\n\n\n      Your browser does not support the video element.\n    \n\n\n\n\nCode\n#Video??"
  },
  {
    "objectID": "posts/init_auto_swing_extraction/init_exploration.html",
    "href": "posts/init_auto_swing_extraction/init_exploration.html",
    "title": "Initial forays into auto-detect function of longer videos",
    "section": "",
    "text": "1) 2d keypoints of a full video\n2) Find the most relevant frames that correspond to a swing\n3) Crop and extract a corresponding video for each swing\n\n\n\n\n\nThe start times of every swing in IMG_1090.MOV are:\n ['0:28', '0:53', '1:27', '1:54', '2:25', '3:01']\n\n\n\n\n\n\nCode\nprint(f'Grabbing a clip from {files[0].name}')\nframes, fps = get_frames(files[0], \n                         per_second=False, # only grab every fps frame\n                         start_idx=600, # start 10 seconds in\n                         #start_idx=1200, # start 20 seconds in\n                         num_frames=1500, # only pull down 25 seconds of video\n                         #num_frames=250, # only pull down 4ish seconds of video)\n                         resize_dim=(256,256),\n                         show_progress=True\n                        )\nsave_frames(frames=frames, fps=fps, fname='useless_frames.mp4')\n\n\nGrabbing a clip from IMG_1090.MOV\n\n\n100%|████████████████████████████████████████████████████████████████████████████| 1500/1500 [02:34&lt;00:00,  9.68it/s]\n\n\n\n\n\n\n\n\nFirst 10 seconds are useless and not included\nOnly about 3 seconds of the first 35 seconds is relevant\nThe full video has 6 swings and is over 3 minutes long!\n\n\n\n\n\nI tried a few different approaches that did not work very consistently or well at all\nAfter a few days lets see if a simple approach will get the job done\nWe only want a close approximation of something in the middle of the swing frames themselves, once we have it, we can just pull 1-2 seconds before and after this middle frame\n\n\nusing our existing physics code to normalize the swings around the peak of the backswing like we’ve already fleshed out (shown to work)\n\n\n\n\n\n\nThe simple extraction method will be to use a filter on 2d keypoints and say yes to any frame where both hands are above the shoulder\n\nIf both hands are above the shoulders, we know we’re inside of a swing frames\nWhen giving the score, one hand is above the shoulder, so we need BOTH above\n\n\n\n\nCode\n# logger = MMLogger.get_instance('mmpose')\n# logger.setLevel('ERROR')  # or 'ERROR' for even less output\n# labeler = get_labeler('vit');\n# generate_labels(labeler, 'useless_frames.mp4', out_dir='keypoints');\n\n\n\n\n\n\n\nFirst\nOnly\nThe\n\n\n\nCode\nfrom swing_data import *\nkps = KpExtractor('keypoints/useless_frames.pkl').keypoint_data.kps\nkps.shape, kps[0,9]\n\n\n\n\nCode\nl_shoulder = kps[:, 5, 1] # Left Wrist KP\nr_shoulder = kps[:, 6, 1] # Right Wrist KP\nl_elbow = kps[:, 7, 1] # Left Elbow KP\nr_elbow = kps[:, 8, 1] # Right Elbow KP\nl_wrist = kps[:, 9, 1] # Left Wrist KP\nr_wrist = kps[:, 10, 1] # Right Wrist KP\n# less than is above\nleft_wrist_above_elbow = l_wrist &lt; l_elbow\nright_wrist_above_elbow = r_wrist &lt; r_elbow\nleft_wrist_above_sh = l_wrist &lt; l_shoulder\nright_wrist_above_sh = r_wrist &lt; r_shoulder\n\n\n\n\nCode\ncombined_true = left_wrist_above_elbow & right_wrist_above_elbow & left_wrist_above_sh & right_wrist_above_sh\nhigher_idxs = np.where(combined_true)[0]\nprint(f'There are {len(higher_idxs)} frames with the wrists above the elbow and shoulders')\n\n\nThere are 77 frames with the wrists above the elbow and shoulders\n\n\n\n\nCode\nhigher_frames = np.stack([frames[idx] for idx in higher_idxs])\nsave_frames(fname='higher_frames.mp4', frames=higher_frames)\nhigher_frames.shape\n\n\n(77, 256, 256, 3)\n\n\n\n\n\n\n\n…\n\n\n\nCode\nfirst_high_idx = higher_idxs[0]\nfirst_high_idx\n\n\n1150\n\n\n\n\nCode\n# get 1.5 seconds before and after first high index\ninit_idx = first_high_idx - 90\nfinal_idx = first_high_idx + 90\ninit_idx, final_idx\n\n\n(1060, 1240)\n\n\n\n\n\n\n\n…\n\nFirst 90 seconds of video\n\n…\nFirst 90 seconds of video clipped!\n\n…"
  },
  {
    "objectID": "posts/init_auto_swing_extraction/init_exploration.html#ive-been-hand-labeling-the-videos-and-then-extracting-clips-from-my-own-labels-this-is-not-feasible-to-do-in-a-timely-manner-and-requires-alot-of-manual-labor.-lets-find-a-way-to",
    "href": "posts/init_auto_swing_extraction/init_exploration.html#ive-been-hand-labeling-the-videos-and-then-extracting-clips-from-my-own-labels-this-is-not-feasible-to-do-in-a-timely-manner-and-requires-alot-of-manual-labor.-lets-find-a-way-to",
    "title": "Initial forays into auto-detect function of longer videos",
    "section": "",
    "text": "1) 2d keypoints of a full video\n2) Find the most relevant frames that correspond to a swing\n3) Crop and extract a corresponding video for each swing\n\n\n\n\n\nThe start times of every swing in IMG_1090.MOV are:\n ['0:28', '0:53', '1:27', '1:54', '2:25', '3:01']\n\n\n\n\n\n\nCode\nprint(f'Grabbing a clip from {files[0].name}')\nframes, fps = get_frames(files[0], \n                         per_second=False, # only grab every fps frame\n                         start_idx=600, # start 10 seconds in\n                         #start_idx=1200, # start 20 seconds in\n                         num_frames=1500, # only pull down 25 seconds of video\n                         #num_frames=250, # only pull down 4ish seconds of video)\n                         resize_dim=(256,256),\n                         show_progress=True\n                        )\nsave_frames(frames=frames, fps=fps, fname='useless_frames.mp4')\n\n\nGrabbing a clip from IMG_1090.MOV\n\n\n100%|████████████████████████████████████████████████████████████████████████████| 1500/1500 [02:34&lt;00:00,  9.68it/s]\n\n\n\n\n\n\n\n\nFirst 10 seconds are useless and not included\nOnly about 3 seconds of the first 35 seconds is relevant\nThe full video has 6 swings and is over 3 minutes long!\n\n\n\n\n\nI tried a few different approaches that did not work very consistently or well at all\nAfter a few days lets see if a simple approach will get the job done\nWe only want a close approximation of something in the middle of the swing frames themselves, once we have it, we can just pull 1-2 seconds before and after this middle frame\n\n\nusing our existing physics code to normalize the swings around the peak of the backswing like we’ve already fleshed out (shown to work)\n\n\n\n\n\n\nThe simple extraction method will be to use a filter on 2d keypoints and say yes to any frame where both hands are above the shoulder\n\nIf both hands are above the shoulders, we know we’re inside of a swing frames\nWhen giving the score, one hand is above the shoulder, so we need BOTH above\n\n\n\n\nCode\n# logger = MMLogger.get_instance('mmpose')\n# logger.setLevel('ERROR')  # or 'ERROR' for even less output\n# labeler = get_labeler('vit');\n# generate_labels(labeler, 'useless_frames.mp4', out_dir='keypoints');\n\n\n\n\n\n\n\nFirst\nOnly\nThe\n\n\n\nCode\nfrom swing_data import *\nkps = KpExtractor('keypoints/useless_frames.pkl').keypoint_data.kps\nkps.shape, kps[0,9]\n\n\n\n\nCode\nl_shoulder = kps[:, 5, 1] # Left Wrist KP\nr_shoulder = kps[:, 6, 1] # Right Wrist KP\nl_elbow = kps[:, 7, 1] # Left Elbow KP\nr_elbow = kps[:, 8, 1] # Right Elbow KP\nl_wrist = kps[:, 9, 1] # Left Wrist KP\nr_wrist = kps[:, 10, 1] # Right Wrist KP\n# less than is above\nleft_wrist_above_elbow = l_wrist &lt; l_elbow\nright_wrist_above_elbow = r_wrist &lt; r_elbow\nleft_wrist_above_sh = l_wrist &lt; l_shoulder\nright_wrist_above_sh = r_wrist &lt; r_shoulder\n\n\n\n\nCode\ncombined_true = left_wrist_above_elbow & right_wrist_above_elbow & left_wrist_above_sh & right_wrist_above_sh\nhigher_idxs = np.where(combined_true)[0]\nprint(f'There are {len(higher_idxs)} frames with the wrists above the elbow and shoulders')\n\n\nThere are 77 frames with the wrists above the elbow and shoulders\n\n\n\n\nCode\nhigher_frames = np.stack([frames[idx] for idx in higher_idxs])\nsave_frames(fname='higher_frames.mp4', frames=higher_frames)\nhigher_frames.shape\n\n\n(77, 256, 256, 3)\n\n\n\n\n\n\n\n…\n\n\n\nCode\nfirst_high_idx = higher_idxs[0]\nfirst_high_idx\n\n\n1150\n\n\n\n\nCode\n# get 1.5 seconds before and after first high index\ninit_idx = first_high_idx - 90\nfinal_idx = first_high_idx + 90\ninit_idx, final_idx\n\n\n(1060, 1240)\n\n\n\n\n\n\n\n…\n\nFirst 90 seconds of video\n\n…\nFirst 90 seconds of video clipped!\n\n…"
  },
  {
    "objectID": "posts/camera_shake/index.html",
    "href": "posts/camera_shake/index.html",
    "title": "Lets look at a new persons swings",
    "section": "",
    "text": "We have the following original videos: \n['IMG_3853', 'IMG_3854', 'IMG_3856', 'IMG_3857', 'IMG_3855', 'IMG_3858'] \nin this set of swings\n\n\n\n\nCode\ndavid_df.kps[0].shape\n\n\n(880, 17, 3)\n\n\n\n\nCode\ndavid_df.kps[0].shape\n\n\n(880, 17, 3)\n\n\n\n\nCode\n# #| echo: false\n# fig, axes = plot_lower_body_detailed(\n#     kps_list=david_df.kps.values[...,:2],\n#     scores_list=[david_df.kps.values[...,2]],\n#     labels=david_df.video_name.map(lambda x: x.split('.')[0]),\n#     params=PlotParams(handedness=\"right\", smooth_win=5, fps=60.0),\n#     title=\"Swing Comparison - Lower Body\"\n# );\n\n\n\n\nCode\n'''So only 41 frame runway after peak on one video, lets just do 41 on front side. \n    will only end up being 1.3 seconds total but lets see how it looks\n'''\ntop_idxs = [get_frame_plot(x[30:])[0] + 30 for x in david_df.kps]\nlowest_frame_count = np.array([kp.shape[0] for kp in david_df.kps]).min()\nhighest_peak_frame = np.array(top_idxs).max()\ndiff = lowest_frame_count - highest_peak_frame\nstart_idx = highest_peak_frame - diff\nend_idx = highest_peak_frame + diff\nprint(f'The frame index where the straight arm is found \\\nin the backswing are:\\n {top_idxs}')\nprint(f'The highest peak frame where this is found is: {highest_peak_frame}')\nprint(f'The lowest frame count in any of our clips is: {lowest_frame_count}')\nprint(f'We have a difference of {diff} frames between where this happens')\nprint(f'The indexes we will use to index all these videos are:\\n \\\nstart:{start_idx} and end:{end_idx}')\n\n\nThe frame index where the straight arm is found in the backswing are:\n [624, 667, 693, 958, 779, 658]\nThe highest peak frame where this is found is: 958\nThe lowest frame count in any of our clips is: 880\nWe have a difference of -78 frames between where this happens\nThe indexes we will use to index all these videos are:\n start:1036 and end:880\n\n\n\n\nCode\nidx_bounds = [(top_idxs[x]-40, top_idxs[x] + 40)for x in range(len(david_df.kps))]\ntest_kps = [david_df.kps[x][idx_bounds[x][0]:idx_bounds[x][1]] for x in range(len(idx_bounds))]\nidx_bounds\n\n\n[(584, 664), (627, 707), (653, 733), (918, 998), (739, 819), (618, 698)]\n\n\n\n\nCode\nfig, axes = plot_lower_body_detailed(\n    kps_list=[x[...,:2][10:45] for x in test_kps],\n    scores_list=[x[...,2][10:45] for x in test_kps],\n    labels=david_df.scores, #david_df.video_name.map(lambda x: x.split('.')[0]),\n    params=PlotParams(handedness=\"right\", smooth_win=5, fps=60.0),\n    title=\"Swing Comparison - Lower Body\"\n)\n\n\n\n\n\n\n\n\n\n\n\nCode\nfrom scipy.signal import savgol_filter\n\n\ndef get_derivative(np_array, axis=0, order=1):\n    tns = torch.tensor(np_array).to('cuda')\n    derivative = torch.diff(tns, axis=axis, n=order)\n    np_derivative = derivative.cpu().numpy()\n    return np_derivative\n\n\n\nwindow_size = 21  # must be odd\npoly_order = 3    # polynomial degree (typically 2-4)\n\ndef savgol_smooth(kps, window_size=10):\n    window_len = window_size * 2 + 1\n    smoothed = savgol_filter(kps, window_length=window_len, polyorder=3, axis=0)    \n    return smoothed\n#smoothed = savgol_filter(test_kps[0], window_length=21, polyorder=3, axis=0)\nsmooth_kps = [savgol_smooth(x) for x in test_kps]\nfirst_order_smooth = [get_derivative(kps) for kps in smooth_kps]\nsecond_order_smooth = [get_derivative(kps, order=2) for kps in smooth_kps]\n\n\n\n\nCode\nfig, axes = plot_lower_body_detailed(\n    kps_list=[x[...,:2][10:45] for x in smooth_kps],\n    scores_list=[x[...,2][10:45] for x in smooth_kps],\n    labels=david_df.scores, #david_df.video_name.map(lambda x: x.split('.')[0]),\n    params=PlotParams(handedness=\"right\", smooth_win=5, fps=60.0),\n    title=\"Swing Comparison - Lower Body -- Smoothed out\"\n)\n\n\n\n\n\n\n\n\n\n\n\nCode\nfig, axes = plot_upper_body_comparison(\n    kps_list=[x[...,:2][10:45] for x in smooth_kps],\n    scores_list=[x[...,2][10:45] for x in smooth_kps],\n    labels=david_df.scores,\n    params=UpperPlotParams(handedness=\"right\", smooth_win=5, fps=60.0),\n    title=\"Swing Comparison - Upper Body\"\n)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "eagle-swing",
    "section": "",
    "text": "Swing DataClass\n\n\n\nData Engineering\n\n\n\nNow that we have the resources to find the clipping indexes for a videos, lets expand the capacity by introducing a dataclass that can handle and organize alot of this inforamtion\n\n\n\n\n\nNov 17, 2025\n\n\nAli Zaidi\n\n\n\n\n\n\n\n\n\n\n\n\nLets look at a new persons swings\n\n\n\nData Visualization\n\n\n\nA moving camera and a single swing per video are now in play\n\n\n\n\n\nNov 16, 2025\n\n\nAli Zaidi\n\n\n\n\n\n\n\n\n\n\n\n\nKinematic Analysis\n\n\n\nData Visualization\n\n\n\nNow that we have our labeled clips, lets run some preliminary analysis over each of their keypoints and see what we can extract\n\n\n\n\n\nNov 15, 2025\n\n\nAli Zaidi\n\n\n\n\n\n\n\n\n\n\n\n\nAuto Clipping\n\n\n\nData Engineering\n\n\n\nEnd to end clipping and saving of multiswing videos to their component clips\n\n\n\n\n\nNov 13, 2025\n\n\nAli Zaidi\n\n\n\n\n\n\n\n\n\n\n\n\nInitial forays into auto-detect function of longer videos\n\n\n\nData Engineering\n\n\n\nFleshing out a way to find a consistent point in the swing to use for autodetection of swings\n\n\n\n\n\nNov 10, 2025\n\n\nAli Zaidi\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Clipping\n\n\n\nData Engineering\n\n\n\nA manual approach to hand labeling clipping videos\n\n\n\n\n\nSep 25, 2025\n\n\nAli Zaidi\n\n\n\n\n\n\n\n\n\n\n\n\nInitial Video Analysis\n\n\n\nEDA\n\n\n\n\n\n\n\n\n\nSep 22, 2025\n\n\nAli Zaidi\n\n\n\n\n\n\n\n\n\n\n\n\nEagle Swing Takes Off\n\n\n\nnews\n\n\n\n\n\n\n\n\n\nSep 19, 2025\n\n\nAli Zaidi\n\n\n\n\n\nNo matching items"
  }
]