{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "164f4190-8c1e-4833-ba86-eac80c5e351c",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Swing Normalization\"\n",
    "author: \"Ali Zaidi\"\n",
    "date: \"2025-11-18\"\n",
    "categories: [Data Engineering]\n",
    "description: \"Now that we have an appropriate dataclass for our swings lets work on normalizing swings so that we can handle camera perturbations\"\n",
    "format:\n",
    "  html:\n",
    "    code-fold: true\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "251f69cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "from fastai.vision.all import *\n",
    "#from swing_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2908b21b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| include: false\n",
    "base_path = '../../../data/full_videos/ymirza'\n",
    "swing_days = ['jun8', 'aug9', 'sep14']\n",
    "parent_dir = f'{base_path}/{swing_days[-1]}'\n",
    "files = [file for file in get_files(parent_dir, extensions='.pkl') if file.name[:3] == 'IMG']\n",
    "file_names = [file.name.split('.')[0] for file in files]\n",
    "len(file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c002fe76-17ae-47a5-9e6a-3c5e4ec19f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_sh = kp_0.l_sh\n",
    "r_sh = kp_0.r_sh\n",
    "l_wr = kp_0.l_wr\n",
    "r_wr = kp_0.r_wr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2baa7df-c7ec-483d-8f7a-86b23952eaae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((180, 3), (180,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_sh.shape, l_sh[:, 0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2021239-f28f-41f4-942a-7a59ca7b0488",
   "metadata": {},
   "source": [
    "## Lets flesh out some functions to derive useful distance and degree relationships\n",
    "\n",
    "*** must keep in mind the following:\n",
    "    - x increases to the right → same as normal.\n",
    "    - y usually increases downwards, opposite of standard Cartesian.\n",
    "    - If we want “upwards” to be positive angle (like in usual math diagrams),\n",
    "         arctan2 angles will be flipped vertically compared to that intuition.\n",
    "    - If we want a more “math-like” angle where up is positive y --> negate dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acb567f1-d14c-4037-91f9-a037d8f4cf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kp_xy_components(kps):\n",
    "    # [0] index is horizontal value (x) and [1] is vertical (y)\n",
    "    x_component = kps[:, 0]\n",
    "    y_component = kps[:, 1]\n",
    "    return x_component, y_component\n",
    "    \n",
    "def get_angle_degree(first_kps, second_kps):\n",
    "    first_x_arr, first_y_arr = get_kp_xy_components(first_kps)\n",
    "    second_x_arr, second_y_arr = get_kp_xy_components(second_kps)\n",
    "    dx = first_x_arr - second_x_arr\n",
    "    dy = first_y_arr - second_y_arr\n",
    "    angle_radians = np.arctan2(dy, dx)\n",
    "    angle_degree = np.degrees(angle_radians)\n",
    "    return angle_degree\n",
    "\n",
    "def get_kps_distance(first_kps, second_kps):\n",
    "    first_x_arr, first_y_arr = get_kp_xy_components(first_kps)\n",
    "    second_x_arr, second_y_arr = get_kp_xy_components(second_kps)\n",
    "    dx = first_x_arr - second_x_arr\n",
    "    dy = first_y_arr - second_y_arr\n",
    "    distance = np.sqrt(dx**2 + dy**2)\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85085e3a-fa7e-4569-8f35-70b81474402b",
   "metadata": {},
   "source": [
    "From Claude: <br>\n",
    "** Image Coordinate System ** <br>\n",
    "    --> In video/image coordinates, the y-axis increases downward (not upward like mathematical convention). This means: <br>\n",
    "\t•\tAn angle of 0° points right <br>\n",
    "\t•\tAn angle of 90° points down (not up) <br>\n",
    "\t•\tAn angle of -90° points up (not down) <br>\n",
    " \n",
    "** Angle Range ** <br>\n",
    "    --> The function returns angles in [-180, 180], where negative angles represent clockwise rotation from the positive x-axis and positive angles represent counter-clockwise rotation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcc1013-a63c-4ca7-84e7-6b7535a03016",
   "metadata": {},
   "source": [
    "### We need to account for potential perturbations -- such as from the camera orientation and also potenital shake in the camera itself, a simple way to manage this is to normalize the coordinates relative to something within the body\n",
    "    - This way absolute position values won't matter --> if the camera moves up, the height values of the feet will have shifted in the frame, but the player did not move up in the vertical dimension\n",
    "    - Can be done by dividing all keypoint values by a refernce distance that remains anatomically stable frame by frame\n",
    "    - These people tried out a bunch of different normalization techniques and a bunch worked well:\n",
    "        - https://www.mdpi.com/1424-8220/22/11/4245\n",
    "        - Look at the points separated in their own space once normalized on right!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3578b7df-7d5b-4491-bf83-556b091b98d0",
   "metadata": {},
   "source": [
    "![](paper_img.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ff2c8b-f877-43d4-888c-1196d800937d",
   "metadata": {},
   "source": [
    "### Why is this important?\n",
    "\n",
    "#### Camera distance, focal length, and resolution create different pixel-space scales for the same physical movements. Normalization converts absolute pixel distances into scale-invariant relative proportions, making measurements comparable across videos. For example, torso-based normalization maintains consistent body proportions while allowing limb movements to vary naturally"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9811d0-fd51-40ec-9659-81d78ebd6dc5",
   "metadata": {},
   "source": [
    "## After normalization, our get_distance() returns values like 0.99 (99% of torso length) instead of 158 pixels\n",
    "### Enabling direct comparison between different recording setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9639d276-15d1-4ea8-ac8f-58f5d5e9cdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use one diagonal to normalize\n",
    "def normalize_by_torso_diagonal(kps, l_sh_to_r_hip=True):\n",
    "    if l_sh_to_r_hip: #left shoulder to right hip\n",
    "        shoulder = kps.l_sh\n",
    "        hip = kps.r_hi\n",
    "    else:\n",
    "        shoulder = kps.r_sh\n",
    "        hip = kps.l_hi\n",
    "    \n",
    "    torso_diagonal = np.sqrt(np.sum((shoulder - hip)**2, axis=1))\n",
    "    normalized_kps = kps.kps / torso_diagonal[:, np.newaxis, np.newaxis]\n",
    "    \n",
    "    return normalized_kps\n",
    "\n",
    "# Use BOTH diagonals to normalize\n",
    "def normalize_by_average_torso(kps):\n",
    "    left_shoulder = kps.l_sh\n",
    "    right_shoulder = kps.r_sh\n",
    "    left_hip = kps.l_hi\n",
    "    right_hip = kps.r_hi\n",
    "    \n",
    "    diagonal1 = np.sqrt(np.sum((left_shoulder - right_hip)**2, axis=1))\n",
    "    diagonal2 = np.sqrt(np.sum((right_shoulder - left_hip)**2, axis=1))\n",
    "    avg_torso = (diagonal1 + diagonal2) / 2.0\n",
    "    return kps.kps / avg_torso[:, np.newaxis, np.newaxis]\n",
    "\n",
    "#normalize_by_average_torso(kp_0).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7576f5-3e25-4bd8-a4bb-9b5943d6365c",
   "metadata": {},
   "source": [
    "### One more normalization technique.....\n",
    "\n",
    "Imagine you took a picture of your friend, but you held the camera crooked. Now your friend looks like they are leaning sideways, even though they were standing straight.\n",
    "\n",
    "If you wanted to measure how tall they are or where their hands are, it's hard to do because everything is tilted.\n",
    "\n",
    "This code fixes the picture.\n",
    "\n",
    "The Pin (Anchor Point): First, it takes a pin and sticks it through a specific spot on the photo (like their hip or the center of their chest) and pins it to the wall.\n",
    "\n",
    "The Shoulders: Then, it looks at their left shoulder and their right shoulder. It draws a line between them.\n",
    "\n",
    "The Spin: It grabs the picture and spins it on the wall until that shoulder line is perfectly flat (horizontal).\n",
    "\n",
    "The Result: Now, no matter how crooked the camera was originally, your friend is standing perfectly straight up and down in the data. This makes it much easier for the computer to compare this swing to the next swing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "745e1420-e6c6-42f9-9cbc-d2b6fbd79dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_to_body_frame(keypoints, left_shoulder, right_shoulder, anchor_point=None):\n",
    "    \"\"\"Rotate so shoulders are horizontal. Creates rotation + translation invariance.\n",
    "    \n",
    "    Returns keypoints in body-centric frame where:\n",
    "    - X-axis: along shoulder line\n",
    "    - Y-axis: perpendicular to shoulders\n",
    "    \"\"\"\n",
    "    if anchor_point is not None:\n",
    "        keypoints = make_relative_to_anchor(keypoints, anchor_point)\n",
    "        left_shoulder = left_shoulder - anchor_point\n",
    "        right_shoulder = right_shoulder - anchor_point\n",
    "    \n",
    "    shoulder_vec = left_shoulder - right_shoulder\n",
    "    angle = np.arctan2(shoulder_vec[..., 1], shoulder_vec[..., 0])\n",
    "    \n",
    "    cos_a = np.cos(-angle)\n",
    "    sin_a = np.sin(-angle)\n",
    "    \n",
    "    if keypoints.ndim == 2:\n",
    "        rotation_matrix = np.array([[cos_a, -sin_a], [sin_a, cos_a]])\n",
    "        return keypoints @ rotation_matrix.T\n",
    "    else:\n",
    "        rotation_matrices = np.array([[cos_a, -sin_a], [sin_a, cos_a]])\n",
    "        if rotation_matrices.ndim == 3:\n",
    "            rotation_matrices = np.transpose(rotation_matrices, (2, 0, 1))\n",
    "        return np.einsum('...ij,...jk->...ik', keypoints, rotation_matrices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693187e7-ad51-4316-a6fe-b0c43e39cf45",
   "metadata": {},
   "source": [
    "### Ok so we have some distance and angle functionality and we also have a way to normalize our keypoints so lets add the potential for some additional geometric relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4974d7ed-7093-4ac2-b738-f42e32e51a22",
   "metadata": {},
   "source": [
    "#### [1] Vector level features between two points with a unit vector\n",
    "   - tells you where second point is relative to the first <br>\n",
    "   ** Independent of distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39bb4eea-c154-4c1e-b04d-3dee161a4665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"get_unit_vector()\" function is useful becuase models often like separate  unit vectors in the x and y dimension rather than a single value\n"
     ]
    }
   ],
   "source": [
    "def get_unit_vector(first_kps, second_kps):\n",
    "    \"\"\"\n",
    "    Calculates unit vector from A to B.\n",
    "    Shape: Inputs (N, 2) -> Output (N, 2)\n",
    "    \"\"\"\n",
    "    vec = second_kps[...,:2] - first_kps[...,:2]\n",
    "    \n",
    "    # Manual norm is faster than np.linalg.norm\n",
    "    norm = np.sqrt(vec[..., 0]**2 + vec[..., 1]**2)\n",
    "    \n",
    "    # Avoid division by zero safely\n",
    "    norm = np.where(norm == 0, 1, norm)\n",
    "    \n",
    "    # Reshape norm to (N, 1) to allow broadcasting\n",
    "    return vec / norm[..., None]\n",
    "\n",
    "print(f'\"get_unit_vector()\" function is useful becuase models often like \\\n",
    "separate  unit vectors in the x and y dimension rather than a single \\\n",
    "value')\n",
    "#get_unit_vector(kp_0.l_sh, kp_0.l_el).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba509926-b5ef-40b3-9304-b95aa2c41029",
   "metadata": {},
   "source": [
    "#### [2] Angle between segments --> use joint angles ABC to find angle @ B\n",
    "   - elbow angle (shoulder, elbow, wrist)\n",
    "   - wrist cock (forearm - club shaft angle)\n",
    "   - spine angle (hip - shoulder - head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56fbafbd-7799-4f8d-a093-03ab4ceaaa3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angle_fast(A, B, C):\n",
    "    \"\"\"\n",
    "    Vectorized function to calculate angle at point B given A, B, C.\n",
    "    Inputs A, B, C can be shape (2,) or (N, 2).\n",
    "    Returns angle in degrees (0-180).\n",
    "    \"\"\"\n",
    "    # Create vectors BA and BC\n",
    "    ba = A - B\n",
    "    bc = C - B\n",
    "\n",
    "    # Calculate angle using arctan2 (returns radians between -pi and pi)\n",
    "    # arctan2(y, x) handles the quadrants correctly\n",
    "    ang_ba = np.arctan2(ba[..., 1], ba[..., 0])\n",
    "    ang_bc = np.arctan2(bc[..., 1], bc[..., 0])\n",
    "\n",
    "    # Calculate relative angle and convert to degrees\n",
    "    angle = np.abs(np.degrees(ang_ba - ang_bc))\n",
    "    \n",
    "    # Normalize to 0-180 (inner angle)\n",
    "    # E.g., if angle is 270, inner angle is 90.\n",
    "    angle = np.where(angle > 180, 360 - angle, angle)\n",
    "    \n",
    "    return angle\n",
    "\n",
    "#get_angle_fast(kp_0.l_sh, kp_0.l_el, kp_0.l_wr).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "111b39f8-fc21-4abb-87a7-c32ea931703d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elbow_angle(shoulder, elbow, wrist):\n",
    "    '''elbow angle (shoulder, elbow, wrist) '''\n",
    "    return get_angle_fast(shoulder, elbow, wrist)\n",
    "\n",
    "# def wrist_cock_angle(elbow, wrist, club_end):\n",
    "#     '''wrist cock (forearm - club shaft angle)'''\n",
    "#     return get_angle_fast(elbow, wrist, club_end)\n",
    "\n",
    "def spine_angle(hip, shoulder, head):\n",
    "    '''spine angle (hip - shoulder - head)'''\n",
    "    return get_angle_fast(hip, shoulder, head)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bf146d-27e5-43a6-8336-953eb322d4bd",
   "metadata": {},
   "source": [
    "#### [3] Pose relative / frame-relative geormetry\n",
    "   - Instead of absolute coordianates, make everything relative to some anchor <br>\n",
    "     - subtract pelvis/hip center from all key points <br>\n",
    "     - OPTIONALLY: rotate coordinates so shoulders define a horizontal “body x-axis” <br>\n",
    "<b> * Gives us features that are: <b> <br>\n",
    "     - translation-invariant (location in frame irrelevant)<br>\n",
    "     - closer to “true” body pose, especially if the camera jitters <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60171a87-6496-4f61-9de3-1625645ef2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_keypoints(kps, \n",
    "                        hip_idxs=(11, 12), \n",
    "                        shoulder_idxs=(5, 6), \n",
    "                        align_shoulders=False):\n",
    "    \"\"\"\n",
    "    Normalizes pose keypoints to be translation and (optionally) rotation invariant.\n",
    "    \n",
    "    Args:\n",
    "        kps (np.ndarray): Input keypoints of shape (Frames, K, 2) or (Frames, K, 3).\n",
    "                          Expects [x, y] or [x, y, confidence].\n",
    "        hip_idxs (tuple): Indices for (Left Hip, Right Hip). Default COCO: (11, 12).\n",
    "        shoulder_idxs (tuple): Indices for (Left Shoulder, Right Shoulder). Default COCO: (5, 6).\n",
    "        align_shoulders (bool): If True, rotates poses so the shoulder line is horizontal.\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: Normalized keypoints of the same shape as input.\n",
    "    \"\"\"\n",
    "    # Copy to avoid modifying original data\n",
    "    norm_kps = kps.copy()\n",
    "    \n",
    "    # 1. CENTERING: Subtract Pelvis/Hip Center\n",
    "    # Average of Left and Right Hip (x, y)\n",
    "    # Shape: (Frames, 2)\n",
    "    hip_centers = (kps[:, hip_idxs[0], :2] + kps[:, hip_idxs[1], :2]) / 2.0\n",
    "    \n",
    "    # Broadcast subtraction across all keypoints (N, K, 2) - (N, 1, 2)\n",
    "    norm_kps[:, :, :2] -= hip_centers[:, None, :]\n",
    "\n",
    "    if not align_shoulders:\n",
    "        return norm_kps\n",
    "\n",
    "    # 2. ROTATION: Align Shoulders to Horizontal Axis\n",
    "    # Vector from Left Shoulder to Right Shoulder\n",
    "    # We use the *centered* coordinates to compute this, though vectors are translation-invariant anyway.\n",
    "    left_s = norm_kps[:, shoulder_idxs[0], :2]\n",
    "    right_s = norm_kps[:, shoulder_idxs[1], :2]\n",
    "    \n",
    "    shoulder_vecs = right_s - left_s  # Shape: (Frames, 2)\n",
    "    \n",
    "    # Calculate angle of shoulder vector relative to global X-axis\n",
    "    # theta is the angle we need to rotate *by* to get back to 0 (horizontal)\n",
    "    thetas = np.arctan2(shoulder_vecs[:, 1], shoulder_vecs[:, 0])\n",
    "    \n",
    "    # We want to rotate by -theta to flatten the line.\n",
    "    # Rotation matrix for counter-clockwise rotation by alpha:\n",
    "    # [[cos(alpha), -sin(alpha)],\n",
    "    #  [sin(alpha),  cos(alpha)]]\n",
    "    # Here alpha = -theta.\n",
    "    # cos(-t) = cos(t), sin(-t) = -sin(t)\n",
    "    c, s = np.cos(thetas), np.sin(thetas)\n",
    "    \n",
    "    # Construct rotation matrices: (Frames, 2, 2)\n",
    "    # R = [[c, s], [-s, c]] represents rotation by -theta\n",
    "    R = np.stack([\n",
    "        np.stack([c, s], axis=-1),\n",
    "        np.stack([-s, c], axis=-1)\n",
    "    ], axis=-2)\n",
    "    \n",
    "    # Apply rotation to all keypoints: x_new = R @ x_old\n",
    "    # Einsum explanation:\n",
    "    # n: frames, k: keypoints, i: old coords (x,y), j: new coords (x,y)\n",
    "    # We multiply the rotation matrix (n, j, i) by the keypoint vector (n, k, i)\n",
    "    # Transpose R to match standard multiplication or just map indices correctly.\n",
    "    # Correct mapping for \"matrix R applied to vector v\": v_new = R @ v\n",
    "    # kps shape is (N, K, 2). We want (N, K, 2).\n",
    "    # R shape is (N, 2, 2).\n",
    "    norm_kps[:, :, :2] = np.einsum('nij,nkj->nki', R, norm_kps[:, :, :2])\n",
    "    \n",
    "    return norm_kps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e58011-d76e-4b50-9d55-2606736fef57",
   "metadata": {},
   "source": [
    "#### [4] Signed area / “rotation” type features (points ABC)\n",
    "Signed area + cross product tells us:\n",
    " - How \"curved\" or rotated the triplet is\n",
    " - On which side one point lies relative to a line<br>\n",
    "--> ** Will help when detecting: **\n",
    "- open vs closed shoulders/hips\n",
    "- left vs right tilt etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74b421ed-a269-42f8-83a2-429af962ff75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_signed_area(p1, p2, p3):\n",
    "    \"\"\"\n",
    "    Calculates the signed area of the triangle formed by triplets (p1, p2, p3).\n",
    "    This serves as a proxy for 'rotation' or curvature.\n",
    "    \n",
    "    Mathematical Property:\n",
    "        - Positive (+): p3 is to the LEFT of the line p1->p2 (Counter-Clockwise)\n",
    "        - Negative (-): p3 is to the RIGHT of the line p1->p2 (Clockwise)\n",
    "        - Zero (0): Points are collinear\n",
    "    \n",
    "    Args:\n",
    "        p1, p2, p3 (np.ndarray): Arrays of shape (N, 2) representing (x, y) coordinates.\n",
    "                                 Can also handle shape (2,) for single points.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Signed area values.\n",
    "    \"\"\"\n",
    "    # Ensure inputs are numpy arrays\n",
    "    p1, p2, p3 = map(np.array, (p1, p2, p3))\n",
    "\n",
    "    # Vector A: p1 -> p2\n",
    "    vec_a = p2 - p1\n",
    "    \n",
    "    # Vector B: p1 -> p3\n",
    "    vec_b = p3 - p1\n",
    "    \n",
    "    # 2D Cross Product (Determinant): x1*y2 - x2*y1\n",
    "    # This calculates the z-component of the cross product in 3D space\n",
    "    cross_prod = vec_a[..., 0] * vec_b[..., 1] - vec_a[..., 1] * vec_b[..., 0]\n",
    "    \n",
    "    # Signed Area is 0.5 * Cross Product\n",
    "    return 0.5 * cross_prod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576a21d0-6d7d-402c-accd-3bb79a7ec73d",
   "metadata": {},
   "source": [
    "ELI5 from gemini:\n",
    "Imagine you are holding a clock. <br>\n",
    "The \"signed area\" (or cross product) tells you which way the clock hands are moving and how big the clock is. <br>\n",
    "We have three points: A, B, and C. <br>\n",
    "A is the center of the clock. <br>\n",
    "B is the number 12. <br>\n",
    "C is where the hour hand is pointing. <br>\n",
    "The math checks where C is, compared to the line from A to B.\n",
    "\n",
    "1. The \"Which Way\" (Sign)\n",
    "\n",
    "- Positive (+): The hand moved backwards (Counter-Clockwise). Point C is to the Left.\n",
    "- Negative (-): The hand moved forwards (Clockwise). Point C is to the Right.\n",
    "- Zero (0): The hand is pointing straight at 12 (or 6). All three points are in a straight line.\n",
    "\n",
    "2. The \"How Big\" (Number)\n",
    "- Small Number: The hand is very close to the 12. It's barely a triangle; it's almost a straight line.\n",
    "- Big Number: The hand is far away (like at 3 o'clock or 9 o'clock). The triangle is big and \"open.\"\n",
    "\n",
    "--> Why is this useful for bodies? <br>\n",
    "Imagine A and B are your shoulders (making a line). <br>\n",
    "If C (your hip) is directly underneath them, the number is Zero. You are standing straight. <br>\n",
    "If you twist your hips forward, the number becomes Positive.\n",
    "\n",
    "If you twist your hips backward, the number becomes Negative.\n",
    "\n",
    "It gives you a single number that tells you how much you twisted and which direction you twisted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e77a08-fc2e-4802-b90e-51c6b2d59387",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
