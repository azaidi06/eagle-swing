{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dcf91b1-ebaa-4d58-b43e-24ac6a42528b",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Auto Clipping\"\n",
    "author: \"Ali Zaidi\"\n",
    "date: \"2025-11-13\"\n",
    "categories: [Data Engineering]\n",
    "description: \"End to end clipping and saving of multiswing videos to their component clips\"\n",
    "format:\n",
    "  html:\n",
    "    code-fold: true\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354c2172-5c3c-4f15-8c55-ed62b3abe1ee",
   "metadata": {},
   "source": [
    "## Now that we have some functionality to find each swing in the video, lets clip a longer video\n",
    "\n",
    "### To develop this functionality, we want to utilize:\n",
    "    1) Our auto detection functions from the previous notebook to find each swing\n",
    "    2) Core conditional logic to save and store these individual clips for future use\n",
    "\n",
    "### With this in place, we can generate swing datasets efficiently for modeling + our code should be modular to make tweaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee4f1ae9-e374-4f3d-870c-6c733016c73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "from fastai.vision.all import *\n",
    "from swing_detect import *\n",
    "from swing_data import *\n",
    "from video_utils import *\n",
    "from labeler import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b62d660-87ef-4bb7-aadd-e4a21396fcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "base_path = '../../../data/full_videos'\n",
    "swing_days = ['jun8', 'aug9', 'sep14']\n",
    "files = get_files(f'{base_path}/{swing_days[-1]}', extensions='.MOV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b252cae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('../../../data/full_videos/sep14')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parent_dir = files[0].parent\n",
    "parent_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30c0005b-e043-4f73-a193-0c43d069be6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 250/250 [00:00<00:00, 350.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The video IMG_1090.MOV is in numpy array with shape: (250, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "#| code-fold: true\n",
    "#| echo: false\n",
    "fname = files[0].name.split('.')[0]\n",
    "frames, fps = get_frames(files[0], \n",
    "                         per_second=False, # only grab every fps frame\n",
    "                         #start_idx=600, # start 10 seconds in\n",
    "                         #start_idx=1200, # start 20 seconds in\n",
    "#                         num_frames=1500, # only pull down 25 seconds of video\n",
    "                         #num_frames=None, # Pulls down all of the frames of video\n",
    "                         num_frames=250, # only pull down 4ish seconds of video)\n",
    "                         resize_dim=(256,256),\n",
    "                         show_progress=True\n",
    "                        )\n",
    "save_frames(frames=frames, fps=fps, \n",
    "            parent_dir=f'{parent_dir}/{fname}',\n",
    "            output_filename='full_clip.mp4')\n",
    "print(f'The video {files[0].name} is in numpy array with shape: {frames.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04f591e5-d487-455f-b039-be74d7ad5b85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "# 11:48 seconds for one video (3ish min) -- lets just run once so we don't have to keep dealing with this wait\n",
    "# process_label_video(f'{parent_dir}/{fname}/full_clip.mp4', \n",
    "#                                    out_dir=f'{parent_dir}/{fname}/keypoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1790f7fd-6207-4b61-ba51-98783bbefe83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the highest (first) indexes where both wrists are above elbow and shoulder are:\n",
      "[1750, 3273, 5298, 6901, 8773, 10945]\n",
      "the start end end indexes based on an increment of 90 is:\n",
      "[(1660, 1840), (3183, 3363), (5208, 5388), (6811, 6991), (8683, 8863), (10855, 11035)]\n",
      "Our final combined video has shape: (1080, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "#| code-fold: true\n",
    "kps = KpExtractor(f'keypoints/{fname}_full_clip.pkl').keypoint_data.kps\n",
    "higher_idxs = find_all_higher_wrist_idxs(kps, conf_threshold=0.7)\n",
    "frame_increment = 90 # add 90 frames before and after our first frame with both hands above in backswing\"\n",
    "highest_idxs = find_each_first_higher_wrist(higher_idxs, skip_frames=900) # 900 frames is 15 seconds\n",
    "all_idx_bounds = get_all_idx_bounds(highest_idxs, frame_increment=frame_increment)\n",
    "final_frames = np.vstack([frames[idxs[0]: idxs[1]] for idxs in all_idx_bounds])\n",
    "print(f'the highest (first) indexes where both wrists are above elbow and shoulder are:\\n{highest_idxs}')\n",
    "print(f'the start end end indexes based on an increment of {frame_increment} is:\\n{all_idx_bounds}')\n",
    "print(f'Our final combined video has shape: {final_frames.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7432318-18a9-4fef-b321-8152cffd01fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "save_frames(fname='final_frames.mp4', frames=final_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a63c70-c18f-47a0-af52-45055b1e6082",
   "metadata": {},
   "source": [
    "### Each swing isolated, with about 1.5 seconds before and after the first point when the hands become visible over the shoulders in the backswing\n",
    "\n",
    "{{< video final_frames.mp4 width=\"400\" height=\"300\" >}}\n",
    "\n",
    " - We can extend the number of frames to 120 (2 seconds) before and after if we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3da358a6-9bc1-4659-8e26-be6aad334bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 6 total swings from our original video IMG_1090\n"
     ]
    }
   ],
   "source": [
    "#| echo: false\n",
    "print(f'We have {len(all_idx_bounds)} total swings from our original video {fname}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852ff336-8fc9-43dd-bd45-f1a4a86aaad8",
   "metadata": {},
   "source": [
    "### Some functions to walk through generated keypoints to find all swing start and end indexes\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e745ac6-17fb-4b52-9926-76f7b8937787",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "def save_idx_df(fname, all_idx_bounds, out_dir):\n",
    "    start_idxs = [idxs[0] for idxs in all_idx_bounds]\n",
    "    end_idxs = [idxs[1] for idxs in all_idx_bounds]\n",
    "    swing_idxs = [x for x in range(len(all_idx_bounds))]\n",
    "    df = pd.DataFrame([swing_idxs, start_idxs, end_idxs], \n",
    "                 index=['swing_idx', 'start_idx', 'end_idx']).T\n",
    "    df.to_csv(f'{out_dir}/{fname}.csv', index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8198785a-116f-4c3a-b5c1-cffc72926a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "def get_swing_idx_df(kps_fpath,\n",
    "                     fname,\n",
    "                     out_dir,\n",
    "                     conf_threshold=0.7, \n",
    "                     frame_increment=90, # add 1.5 seconds before and the found idx\n",
    "                     skip_frames=900, # 900 frames is 15 seconds\n",
    "                     # ^ skips frames between swings\n",
    "                     ):\n",
    "    kps = KpExtractor(kps_fpath).keypoint_data.kps\n",
    "    higher_idxs = find_all_higher_wrist_idxs(kps, conf_threshold=conf_threshold)\n",
    "    highest_idxs = find_each_first_higher_wrist(higher_idxs, skip_frames=skip_frames) # 900 frames is 15 seconds\n",
    "    all_idx_bounds = get_all_idx_bounds(highest_idxs, frame_increment=frame_increment)\n",
    "    df = save_idx_df(fname, all_idx_bounds, out_dir)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93b00f1e-d1e0-4962-a788-4c659ec0a05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "def ensure_out_dir(out_dir_fpath):\n",
    "    if not os.path.isdir(out_dir_fpath):\n",
    "        os.makedirs(out_dir_fpath)\n",
    "\n",
    "def find_each_swing(video_path,\n",
    "                    per_second=False, # only grab every fps frame\n",
    "                    num_frames=None, #1500, # Pulls down all of the frames of video\n",
    "                    start_idx=None, #600, # None starts from 0\n",
    "                    resize_dim=(256,256),\n",
    "                    show_progress=True,\n",
    "                    model_type='vit', \n",
    "                    #out_dir='testing'\n",
    "                   ):\n",
    "    parent_dir = video_path.parent\n",
    "    fname = video_path.name.split('.')[0]\n",
    "    out_dir = f'{parent_dir}/{fname}'\n",
    "    ensure_out_dir(out_dir)                        \n",
    "    fname = video_path.name.split('.')[0]\n",
    "    frames, fps = get_frames(video_path,\n",
    "                             start_idx=start_idx,\n",
    "                             per_second=per_second, # only grab every fps frame\n",
    "                             num_frames=num_frames,#None, # Pulls down all of the frames of video\n",
    "                             resize_dim=resize_dim,\n",
    "                             show_progress=show_progress,\n",
    "                            )\n",
    "    output_filename = 'full_video.mp4'\n",
    "    out_fpath = f'{out_dir}/{output_filename}'\n",
    "    kp_fpath = f'{out_dir}/keypoints/{output_filename.split(\".\")[0]}.pkl'\n",
    "    \n",
    "    save_frames(frames=frames, fps=fps, \n",
    "            parent_dir=f'{parent_dir}/{fname}',\n",
    "            output_filename=output_filename)\n",
    "    #save_frames(frames=frames, fps=fps, fname=out_fpath)\n",
    "                       \n",
    "    process_label_video(out_fpath, out_dir=f'{out_dir}/keypoints')\n",
    "    df = get_swing_idx_df(kps_fpath=kp_fpath, fname=fname, out_dir=out_dir)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f56aa94c-2083-4d71-9058-31b9d1603a97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#fname = files[0].name.split('.')[0]\n",
    "#df = find_each_swing(files[1], start_idx=None, num_frames=1500, )#out_dir=fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172d029e-9524-4a80-ae86-2dd6bfcbd5d0",
   "metadata": {},
   "source": [
    "### Now everything is setup so we can extract all the swing frames with one command\n",
    "- the entire thing is parameterized in order to make small tweaks in how much data we index around the peak\n",
    "- It should make things easier/more reproducible\n",
    "    - Imagine a scenario where we decide to add some processing to videos before doing all of this, now that can be added with a function/line of code into this overall pipeline\n",
    "- Everything should remain organizable\n",
    "- Scaling things up to full frame shouldn't be a problem. we grab the frames and just clip with ffmpeg commands --> label them with the labeler. 7 swings is about 20-25 seconds. This can be done in parallel\n",
    "## Next up:\n",
    "- Process individual swings and apply the analysis framework\n",
    "    - Want to further build out functionality; add x-torque and others\n",
    "- Update plotting functionality to make it more modular and flexible\n",
    "* Ultimately want to be able to point to a folder of videos and output all the plots of interest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "15567ea6-8c60-429c-b05c-ec8e0f9a281c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>swing_idx</th>\n",
       "      <th>start_idx</th>\n",
       "      <th>end_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1369</td>\n",
       "      <td>1549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   swing_idx  start_idx  end_idx\n",
       "0          0       1369     1549"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5ad66147-e187-4e86-8591-7e5d1e277786",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: True\n",
    "import ffmpeg\n",
    "\n",
    "def make_output_filename(fname, swing_idx, score=None):\n",
    "    return f'{fname}_swing_{swing_idx}_score_{score}'\n",
    "\n",
    "def make_clip(input_file_path, \n",
    "              output_folder_path,\n",
    "              row, \n",
    "              #duration_frames=90,  # Changed from time='0:03'\n",
    "              crf='18',\n",
    "              vcodec='libx264'):   # Changed from 'copy' since we need to use filter\n",
    "    fname = input_file_path.name.split('.')[0]\n",
    "    swing_idx, start_frame, end_frame = row.values\n",
    "    output_file_name = make_output_filename(fname, swing_idx)\n",
    "    output_file_path = f'{output_folder_path}/{fname}/{output_file_name}.mp4'\n",
    "    import pdb\n",
    "    #pdb.set_trace()\n",
    "    if os.path.isdir(output_folder_path) is False:\n",
    "        os.mkdir(output_folder_path)\n",
    "        \n",
    "    # Use trim filter for frame-accurate cutting\n",
    "    (\n",
    "        ffmpeg.input(input_file_path)\n",
    "        .trim(start_frame=start_frame, \n",
    "              end_frame=end_frame)\n",
    "        .setpts('PTS-STARTPTS')  # Reset timestamps\n",
    "        .output(output_file_path, \n",
    "                vcodec=vcodec,\n",
    "                crf=crf, \n",
    "                acodec='aac')\n",
    "        .global_args('-movflags', '+faststart')\n",
    "        .overwrite_output()\n",
    "        .run()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cbe8641a-f7e8-4c92-889f-1609c0e83b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in range(len(df)):\n",
    "#     make_clip(input_file_path=files[1], \n",
    "#               output_folder_path=parent_dir,\n",
    "#               row = df.iloc[x]\n",
    "#              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "34fdfb6f-4cd4-4deb-9a93-5db92e7fc2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def end_to_end_detect(fpath, start_idx=None, num_frames=None):\n",
    "    df = find_each_swing(fpath, start_idx=start_idx, num_frames=num_frames,)#1500, )\n",
    "    parent_dir = fpath.parent\n",
    "    for x in range(len(df)):\n",
    "        make_clip(input_file_path=fpath, \n",
    "                  output_folder_path=parent_dir,\n",
    "                  row = df.iloc[x]\n",
    "                 )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6be17d16-b4eb-4989-bcc9-db6db8da40e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from auto_clipper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acb5e6b1-4132-427b-95bc-adea24384da9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#6) [Path('../../../data/full_videos/david/IMG_3857.MOV'),Path('../../../data/full_videos/david/IMG_3853.MOV'),Path('../../../data/full_videos/david/IMG_3854.MOV'),Path('../../../data/full_videos/david/IMG_3855.MOV'),Path('../../../data/full_videos/david/IMG_3856.MOV'),Path('../../../data/full_videos/david/IMG_3858.MOV')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_path = '../../../data/full_videos'\n",
    "#swing_days = ['jun8', 'aug9', 'sep14']\n",
    "files = get_files(f'{base_path}/david', extensions='.MOV')\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "941e11b3-96db-4dcd-b51d-44d5d4c8ce78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_then_label(files):\n",
    "    [end_to_end_detect(file) for file in files]\n",
    "    #[lbl_clips(file) for file in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e706c1ae-b079-4359-995f-61827babf086",
   "metadata": {},
   "outputs": [],
   "source": [
    "#detect_then_label(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58b68573-7e22-48ce-b75a-9c2e4729adc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#end_to_end_detect(files[2])\n",
    "#end_to_end_detect(files[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "611354d6-5c51-407f-89ec-388bd3484dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lbl_clips(fpath):\n",
    "    fname = fpath.name.split('.')[0]\n",
    "    parent_dir = fpath.parent\n",
    "    clips_folder_path = f'{parent_dir}/{fname}'\n",
    "    clipped_videos = [x.name for x in get_files(clips_folder_path, extensions='.mp4') if x.name[:3] == 'IMG']\n",
    "    for video in clipped_videos:\n",
    "        clip_video_path = f'{clips_folder_path}/{video}'\n",
    "        process_label_video(clip_video_path, \n",
    "                    out_dir=f'{clips_folder_path}/keypoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4538b095-b6f9-4e26-9e4d-41a1cda115f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../../data/full_videos/david/IMG_3857'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_output_folder(fpath):\n",
    "    return f'{fpath.parent}/{fpath.name.split(\".\")[0]}'\n",
    "get_output_folder(files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0ed9bcf3-3437-4efc-a05e-849898dbc29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by http backend from path: https://download.openmmlab.com/mmpose/v1/body_2d_keypoint/topdown_heatmap/coco/td-hm_ViTPose-huge_8xb64-210e_coco-256x192-e32adcd4_20230314.pth\n",
      "The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: backbone.cls_token\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/importlib/__init__.py:169: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  _bootstrap._exec(spec, module)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by http backend from path: https://download.openmmlab.com/mmpose/v1/projects/rtmposev1/rtmdet_m_8xb32-100e_coco-obj365-person-235e8209.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/home/azaidi/Desktop/golf/tools/mmdetection/mmdet/models/layers/se_layer.py:158: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "/home/azaidi/Desktop/golf/tools/mmdetection/mmdet/models/backbones/csp_darknet.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "1255it [01:31, 13.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/15 23:06:36 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - the output video has been saved at ../../../data/full_videos/david/IMG_3857/IMG_3857.MOV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1256it [01:31, 13.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by http backend from path: https://download.openmmlab.com/mmpose/v1/body_2d_keypoint/topdown_heatmap/coco/td-hm_ViTPose-huge_8xb64-210e_coco-256x192-e32adcd4_20230314.pth\n",
      "The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: backbone.cls_token\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/importlib/__init__.py:169: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  _bootstrap._exec(spec, module)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by http backend from path: https://download.openmmlab.com/mmpose/v1/projects/rtmposev1/rtmdet_m_8xb32-100e_coco-obj365-person-235e8209.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/home/azaidi/Desktop/golf/tools/mmdetection/mmdet/models/layers/se_layer.py:158: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "/home/azaidi/Desktop/golf/tools/mmdetection/mmdet/models/backbones/csp_darknet.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "879it [01:04, 13.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/15 23:07:45 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - the output video has been saved at ../../../data/full_videos/david/IMG_3853/IMG_3853.MOV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "880it [01:04, 13.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by http backend from path: https://download.openmmlab.com/mmpose/v1/body_2d_keypoint/topdown_heatmap/coco/td-hm_ViTPose-huge_8xb64-210e_coco-256x192-e32adcd4_20230314.pth\n",
      "The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: backbone.cls_token\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/importlib/__init__.py:169: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  _bootstrap._exec(spec, module)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by http backend from path: https://download.openmmlab.com/mmpose/v1/projects/rtmposev1/rtmdet_m_8xb32-100e_coco-obj365-person-235e8209.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/home/azaidi/Desktop/golf/tools/mmdetection/mmdet/models/layers/se_layer.py:158: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "/home/azaidi/Desktop/golf/tools/mmdetection/mmdet/models/backbones/csp_darknet.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "927it [01:12, 13.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/15 23:09:01 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - the output video has been saved at ../../../data/full_videos/david/IMG_3854/IMG_3854.MOV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "927it [01:12, 12.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by http backend from path: https://download.openmmlab.com/mmpose/v1/body_2d_keypoint/topdown_heatmap/coco/td-hm_ViTPose-huge_8xb64-210e_coco-256x192-e32adcd4_20230314.pth\n",
      "The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: backbone.cls_token\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/importlib/__init__.py:169: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  _bootstrap._exec(spec, module)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by http backend from path: https://download.openmmlab.com/mmpose/v1/projects/rtmposev1/rtmdet_m_8xb32-100e_coco-obj365-person-235e8209.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/home/azaidi/Desktop/golf/tools/mmdetection/mmdet/models/layers/se_layer.py:158: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "/home/azaidi/Desktop/golf/tools/mmdetection/mmdet/models/backbones/csp_darknet.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "1017it [01:14, 13.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/15 23:10:19 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - the output video has been saved at ../../../data/full_videos/david/IMG_3855/IMG_3855.MOV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1017it [01:14, 13.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by http backend from path: https://download.openmmlab.com/mmpose/v1/body_2d_keypoint/topdown_heatmap/coco/td-hm_ViTPose-huge_8xb64-210e_coco-256x192-e32adcd4_20230314.pth\n",
      "The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: backbone.cls_token\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/importlib/__init__.py:169: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  _bootstrap._exec(spec, module)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by http backend from path: https://download.openmmlab.com/mmpose/v1/projects/rtmposev1/rtmdet_m_8xb32-100e_coco-obj365-person-235e8209.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/home/azaidi/Desktop/golf/tools/mmdetection/mmdet/models/layers/se_layer.py:158: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "/home/azaidi/Desktop/golf/tools/mmdetection/mmdet/models/backbones/csp_darknet.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "895it [01:05, 13.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/15 23:11:29 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - the output video has been saved at ../../../data/full_videos/david/IMG_3856/IMG_3856.MOV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "895it [01:05, 13.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by http backend from path: https://download.openmmlab.com/mmpose/v1/body_2d_keypoint/topdown_heatmap/coco/td-hm_ViTPose-huge_8xb64-210e_coco-256x192-e32adcd4_20230314.pth\n",
      "The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: backbone.cls_token\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/azaidi/anaconda3/envs/fastdl/lib/python3.10/importlib/__init__.py:169: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  _bootstrap._exec(spec, module)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by http backend from path: https://download.openmmlab.com/mmpose/v1/projects/rtmposev1/rtmdet_m_8xb32-100e_coco-obj365-person-235e8209.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/home/azaidi/Desktop/golf/tools/mmdetection/mmdet/models/layers/se_layer.py:158: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "/home/azaidi/Desktop/golf/tools/mmdetection/mmdet/models/backbones/csp_darknet.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "987it [01:12, 13.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/15 23:12:45 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - the output video has been saved at ../../../data/full_videos/david/IMG_3858/IMG_3858.MOV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "987it [01:12, 13.64it/s]\n"
     ]
    }
   ],
   "source": [
    "for x in range(len(files)):\n",
    "    process_label_video(files[x], out_dir=get_output_folder(files[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611a7675-6a1e-446b-b999-2d145cdc1439",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
