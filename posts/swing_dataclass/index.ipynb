{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "164f4190-8c1e-4833-ba86-eac80c5e351c",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Swing DataClass\"\n",
    "author: \"Ali Zaidi\"\n",
    "date: \"2025-11-17\"\n",
    "categories: [Data Engineering]\n",
    "description: \"Now that we have the resources to find the clipping indexes for a videos, lets expand the capacity by introducing a dataclass that can handle and organize alot of this inforamtion\"\n",
    "format:\n",
    "  html:\n",
    "    code-fold: true\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "251f69cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2908b21b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| include: false\n",
    "base_path = '../../../data/full_videos/ymirza'\n",
    "swing_days = ['jun8', 'aug9', 'sep14']\n",
    "parent_dir = f'{base_path}/{swing_days[-1]}'\n",
    "files = [file for file in get_files(parent_dir, extensions='.pkl') if file.name[:3] == 'IMG']\n",
    "file_names = [file.name.split('.')[0] for file in files]\n",
    "len(file_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2901562e-cea9-4e03-82b5-d53ce47c3456",
   "metadata": {},
   "source": [
    "### We need functionality that stores the keypoints of a swing and computes/stores various components of interest, having these functions stored into a dataclass can help with modeling and plotting things quickly in order to extract useful information of how components evolve as the swing progresses\n",
    "    - The angle of the hips and shoulders\n",
    "    - The angle of joints (wrist, elbow + hand)\n",
    "    - Club head information\n",
    "#### By using abstract functions, we can compute the distance and angles between components and try to extract meaningful information fromm their relationship as the swing progresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc2d679a-cdeb-4e08-9b06-9c58b8bf4f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypeVar, Generic, List, Optional, Callable\n",
    "from dataclasses import dataclass, field\n",
    "import numpy as np\n",
    "import pickle\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "175abc70-3ef0-4489-845a-40536103c36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "class SwingMetaData:\n",
    "    \"\"\"Data Container for a swings video metadata\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 path: str,\n",
    "                 get_swing_idx=False,\n",
    "                 get_score=False,\n",
    "                 ):\n",
    "        \"\"\"\n",
    "        Initialize the swing data and associated metadata\n",
    "        \n",
    "        Args:\n",
    "            path: file_path to data\n",
    "        \"\"\"\n",
    "        self.path = path\n",
    "        self.str_path = self.get_str_path()\n",
    "        self.video_path = f'{self.str_path.split(\".\")[-2]}.mp4'\n",
    "        self.file_name = self.str_path.split('/')[-1].split('.')[0]\n",
    "        if get_swing_idx:\n",
    "            self.swing_idx = int(self.file_name.split('_')[-3])\n",
    "        if get_score:\n",
    "            self.score = self.file_name.split('_')[-1].split('.')[0]\n",
    "\n",
    "    def get_str_path(self):\n",
    "        # Just making sure the path being used is a str + not path object\n",
    "        return str(self.path)\n",
    "\n",
    "    def get_video_name(self):\n",
    "        video = '_'.join(self.str_path.split('/')[1].split('_')[:2])\n",
    "        return video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c628d1fb-4417-4d5e-98d0-39643b1ab2b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/full_videos/ymirza/sep14/IMG_1093/keypoints/IMG_1093_swing_6_score_None'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swing_meta.str_path.split('.')[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a080d17f-6cf3-4a58-a1c6-b73cacf5d6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our meta class can store useful information like the filename \n",
      " ---> IMG_1093_swing_6_score_None\n",
      "Also the swing index \n",
      " ---> 6\n",
      "And the score (when added) \n",
      " ---> None\n",
      "For plotting and output purposes, a path to our labeled video is also available\n"
     ]
    }
   ],
   "source": [
    "swing_meta = SwingMetaData(files[0], get_swing_idx=True, get_score=True)\n",
    "print(f'Our meta class can store useful information like the filename \\n --->\\\n",
    " {swing_meta.file_name}')\n",
    "print(f'Also the swing index \\n --->\\\n",
    " {swing_meta.swing_idx}')\n",
    "print(f'And the score (when added) \\n --->\\\n",
    " {swing_meta.score}')\n",
    "print(f'For plotting and output purposes, a path to our labeled video is also available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a56f6fc1-9707-4031-b3af-8406302aca19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "class SwingKeypointData(SwingMetaData):\n",
    "    \"\"\"\n",
    "    Class to handle keypoint data\n",
    "    Will take a videos metadata and pull down keypoint values and scores\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, video_path):\n",
    "        super().__init__(video_path)\n",
    "        #self.metadata = metadata\n",
    "        self.kp_dicts = self.get_kp_dicts()\n",
    "        self.key_points = self.get_keypoints()\n",
    "        self.scores = self.get_scores()\n",
    "        self.kps = np.concatenate([self.key_points, np.expand_dims(self.scores, -1)], axis=2)\n",
    "\n",
    "\n",
    "    def get_kp_dicts(self):\n",
    "        # Get the frame by frame output dicts from pose estimation models\n",
    "        with open(self.str_path, 'rb') as f:\n",
    "            loaded_dicts = pickle.load(f)\n",
    "        return loaded_dicts\n",
    "\n",
    "        \n",
    "    def get_keypoints(self):\n",
    "        kp_dicts = self.kp_dicts\n",
    "        return np.stack([self.kp_dicts[key]['keypoints'] for key in kp_dicts.keys()])\n",
    "        \n",
    "        \n",
    "    def get_scores(self):\n",
    "        kp_dicts = self.kp_dicts\n",
    "        return np.stack([self.kp_dicts[key]['keypoint_scores'] for key in kp_dicts.keys()])\n",
    "\n",
    "\n",
    "    def get_frame(self, idx):\n",
    "        ''' Just grabs a single frames keypoints and scores\n",
    "        '''\n",
    "        kps = self.key_points[idx]\n",
    "        scores = self.scores[idx]\n",
    "        return np.column_stack((kps, scores))\n",
    "\n",
    "    \n",
    "    def get_frames(self, indexes):\n",
    "        '''\n",
    "        num_idxs = len(Indexes)\n",
    "        Takes a list of indexes and returns an array wof [num_idxs, 17, 3]\n",
    "        [1] 17 keypoint markers\n",
    "        [2] 3 keypoint values/certaintainty (X, Y, Score)\n",
    "        '''\n",
    "        return np.stack([self.get_frame(idx) for idx in indexes])\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.key_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c106789a-d55f-45c2-bc8f-18fbcd38fccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with our SwingKeyPointData class, we can store the raw keypoint values\n",
      "A swings full keypoints/confidence array would have shape: (180, 17, 3)\n",
      "If we want to access just the keypoints we can we can access \n",
      "    the \"key_points\" attribute: (180, 17, 2)\n",
      "If we are interested in seeing just confidence values we can access \n",
      "    the \"scores\" attribute: (180, 17)\n"
     ]
    }
   ],
   "source": [
    "#| echo: false\n",
    "skpdata = SwingKeypointData(files[0])\n",
    "print(f'with our SwingKeyPointData class, we can store the raw keypoint values')\n",
    "print(f'A swings full keypoints/confidence array would have shape: {skpdata.kps.shape}')\n",
    "print(f'If we want to access just the keypoints we can we can access \\n\\\n",
    "    the \"key_points\" attribute: {skpdata.key_points.shape}')\n",
    "print(f'If we are interested in seeing just confidence values we can access \\n\\\n",
    "    the \"scores\" attribute: {skpdata.scores.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ced7bee-d568-4da3-932b-407d59daef2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3f81513-bd11-4eb0-bda8-227180213d05",
   "metadata": {},
   "source": [
    "### Now we are in a position to create a superclass that inherits these components and stores a more rich representation of our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "72491034-33c9-4f11-84a3-82a78935b268",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "class KpExtractor(SwingMetaData):\n",
    "    def __init__(self, \n",
    "                 file_name,\n",
    "                 get_swing_idx=False,\n",
    "                 get_score=False,\n",
    "                 score_threshold=None):\n",
    "        super().__init__(file_name, \n",
    "                         get_swing_idx, \n",
    "                         get_score)\n",
    "        self.keypoint_data = SwingKeypointData(file_name)\n",
    "        self.score_threshold = score_threshold\n",
    "        self.kps = self.threshold_score(self.keypoint_data, score_threshold)\n",
    "\n",
    "        self.coco_idxs = {\"L_SH\":5, \"R_SH\":6, \"L_EL\":7, \"R_EL\":8, \n",
    "             \"L_WR\":9, \"R_WR\":10, \"L_HI\":11, \"R_HI\":12, #HIP\n",
    "             \"L_KN\":13, \"R_KN\":14, \"L_ANK\":15, \"R_ANK\":16}\n",
    "        \n",
    "        # Dynamically create attributes using setattr\n",
    "        for attr_name, coco_key in self.coco_idxs.items():\n",
    "            kp_val = self.kps[:, coco_key, :].astype(float).copy()\n",
    "            setattr(self, attr_name.lower(), kp_val)  # Lowercase only\n",
    "    \n",
    "    def threshold_score(self, kps, threshold_value=0.5):\n",
    "        if threshold_value is None: \n",
    "            return self.keypoint_data.kps.astype(float).copy()\n",
    "        # punch up score values to a threshold\n",
    "        kps = self.keypoint_data.kps.astype(float).copy()\n",
    "        mask = kps[..., 2] < threshold_value\n",
    "        kps[mask, 2] = threshold_value\n",
    "        return kps\n",
    "\n",
    "    # helper function to index specific joints\n",
    "    def __getattr__(self, name):\n",
    "        # Convert requested attribute to lowercase and try to find it\n",
    "        lower_name = name.lower()\n",
    "        try:\n",
    "            return object.__getattribute__(self, lower_name)\n",
    "        except AttributeError:\n",
    "            raise AttributeError(f\"'{type(self).__name__}' object has no attribute '{name}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "da18f8b8-13cf-4ea4-8b2e-e44f5a748b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With our KpExtractor class, we can interrogate our data more effectively\n",
      "A swings full keypoints/confidence can still be found with \".kp\" paradigm \n",
      "    --> here is the shape of the keypoints:(180, 17, 3)\n",
      "If we want to access just keypoints of a single point -- can access this\n",
      "    w/ \".X_YY\" paradigm, here is the array shape of the left shoulder: (180, 3)\n",
      "    where \"X\" represents left or right and \n",
      "    \"YY\" corresponds to a keypoint \"L_WR--> left wrist\n"
     ]
    }
   ],
   "source": [
    "#| echo: false\n",
    "kp_0 = KpExtractor(files[0])\n",
    "print(f'With our KpExtractor class, we can interrogate our data more effectively')\n",
    "print(f'A swings full keypoints/confidence can still be found with \".kp\" paradigm \\n\\\n",
    "    --> here is the shape of the keypoints:{kp_0.kps.shape}')\n",
    "print(f'If we want to access just keypoints of a single point -- can access this\\n\\\n",
    "    w/ \".X_YY\" paradigm, here is the array shape of the left shoulder: {kp_0.L_SH.shape}\\n\\\n",
    "    where \"X\" represents left or right and \\n\\\n",
    "    \"YY\" corresponds to a keypoint \"L_WR--> left wrist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "c002fe76-17ae-47a5-9e6a-3c5e4ec19f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_sh = kp_0.l_sh\n",
    "r_sh = kp_0.r_sh\n",
    "l_wr = kp_0.l_wr\n",
    "r_wr = kp_0.r_wr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "c2baa7df-c7ec-483d-8f7a-86b23952eaae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((180, 3), (180,))"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_sh.shape, l_sh[:, 0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2021239-f28f-41f4-942a-7a59ca7b0488",
   "metadata": {},
   "source": [
    "### Now lets flesh out some functions to derive useful distance and degree relationships\n",
    "\n",
    "*** must keep in mind the following:\n",
    "    - x increases to the right → same as normal.\n",
    "    - y usually increases downwards, opposite of standard Cartesian.\n",
    "    - If we want “upwards” to be positive angle (like in usual math diagrams),\n",
    "         arctan2 angles will be flipped vertically compared to that intuition.\n",
    "    - If we want a more “math-like” angle where up is positive y --> negate dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "acb567f1-d14c-4037-91f9-a037d8f4cf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kp_xy_components(kps):\n",
    "    # [0] index is horizontal value (x) and [1] is vertical (y)\n",
    "    x_component = kps[:, 0]\n",
    "    y_component = kps[:, 1]\n",
    "    return x_component, y_component\n",
    "    \n",
    "def get_angle_degree(first_kps, second_kps):\n",
    "    first_x_arr, first_y_arr = get_kp_xy_components(first_kps)\n",
    "    second_x_arr, second_y_arr = get_kp_xy_components(second_kps)\n",
    "    dx = first_x_arr - second_x_arr\n",
    "    dy = first_y_arr - second_y_arr\n",
    "    angle_radians = np.arctan2(dy, dx)\n",
    "    angle_degree = np.degrees(angle_radians)\n",
    "    return angle_degree\n",
    "\n",
    "def get_kps_distance(first_kps, second_kps):\n",
    "    first_x_arr, first_y_arr = get_kp_xy_components(first_kps)\n",
    "    second_x_arr, second_y_arr = get_kp_xy_components(second_kps)\n",
    "    dx = first_x_arr - second_x_arr\n",
    "    dy = first_y_arr - second_y_arr\n",
    "    distance = np.sqrt(dx**2 + dy**2)\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85085e3a-fa7e-4569-8f35-70b81474402b",
   "metadata": {},
   "source": [
    "From Claude: <br>\n",
    "** Image Coordinate System ** <br>\n",
    "    --> In video/image coordinates, the y-axis increases downward (not upward like mathematical convention). This means: <br>\n",
    "\t•\tAn angle of 0° points right <br>\n",
    "\t•\tAn angle of 90° points down (not up) <br>\n",
    "\t•\tAn angle of -90° points up (not down) <br>\n",
    " \n",
    "** Angle Range ** <br>\n",
    "    --> The function returns angles in [-180, 180], where negative angles represent clockwise rotation from the positive x-axis and positive angles represent counter-clockwise rotation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcc1013-a63c-4ca7-84e7-6b7535a03016",
   "metadata": {},
   "source": [
    "### We need to account for potential perturbations -- such as from the camera orientation and also potenital shake in the camera itself, a simple way to manage this is to normalize the coordinates relative to something within the body\n",
    "    - This way absolute position values won't matter --> if the camera moves up, the height values of the feet will have shifted in the frame, but the player did not move up in the vertical dimension\n",
    "    - Can be done by dividing all keypoint values by a refernce distance that remains anatomically stable frame by frame\n",
    "    - These people tried out a bunch of different normalization techniques and a bunch worked well:\n",
    "        - https://www.mdpi.com/1424-8220/22/11/4245\n",
    "        - Look at the points separated in their own space once normalized on right!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3578b7df-7d5b-4491-bf83-556b091b98d0",
   "metadata": {},
   "source": [
    "![](paper_img.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ff2c8b-f877-43d4-888c-1196d800937d",
   "metadata": {},
   "source": [
    "### Why is this important?\n",
    "\n",
    "#### Camera distance, focal length, and resolution create different pixel-space scales for the same physical movements. Normalization converts absolute pixel distances into scale-invariant relative proportions, making measurements comparable across videos. For example, torso-based normalization maintains consistent body proportions while allowing limb movements to vary naturally"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9811d0-fd51-40ec-9659-81d78ebd6dc5",
   "metadata": {},
   "source": [
    "## After normalization, our get_distance() returns values like 0.99 (99% of torso length) instead of 158 pixels\n",
    "### Enabling direct comparison between different recording setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "33cf9df0-bdae-4758-8ae7-60250987afd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_by_torso_diagonal(kps, l_sh_to_r_hip=True):\n",
    "    if l_sh_to_r_hip: #left shoulder to right hip\n",
    "        shoulder = kps.l_sh\n",
    "        hip = kps.r_hi\n",
    "    else:\n",
    "        shoulder = kps.r_sh\n",
    "        hip = kps.l_hi\n",
    "    \n",
    "    torso_diagonal = np.sqrt(np.sum((shoulder - hip)**2, axis=1))\n",
    "    normalized_kps = kps.kps / torso_diagonal[:, np.newaxis, np.newaxis]\n",
    "    \n",
    "    return normalized_kps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "79167132-4185-46f9-bf3b-3cfeb79f9c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_to_right = normalize_by_torso_diagonal(kp_0, l_sh_to_r_hip=True)\n",
    "#right_to_left = normalize_by_torso_diagonal(kp_0, l_sh_to_r_hip=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "9639d276-15d1-4ea8-ac8f-58f5d5e9cdf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180, 17, 3)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normalize_by_average_torso(kps):\n",
    "    left_shoulder = kps.l_sh\n",
    "    right_shoulder = kps.r_sh\n",
    "    left_hip = kps.l_hi\n",
    "    right_hip = kps.r_hi\n",
    "    \n",
    "    diagonal1 = np.sqrt(np.sum((left_shoulder - right_hip)**2, axis=1))\n",
    "    diagonal2 = np.sqrt(np.sum((right_shoulder - left_hip)**2, axis=1))\n",
    "    avg_torso = (diagonal1 + diagonal2) / 2.0\n",
    "    return kps.kps / avg_torso[:, np.newaxis, np.newaxis]\n",
    "\n",
    "normalize_by_average_torso(kp_0).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693187e7-ad51-4316-a6fe-b0c43e39cf45",
   "metadata": {},
   "source": [
    "### Ok so we have some distance and angle functionality and we also have a way to normalize our keypoints so lets add the potential for some additional geometric relationships\n",
    "1) Vector level features between two points with a unit vector\n",
    "   - tells you where second point is relative to the first <br>\n",
    "   ** Independent of distance\n",
    "2) Angle between segments --> use joint angles ABC to find angle @ B\n",
    "   - elbow angle (shoulder, elbow, wrist)\n",
    "   - wrist cock (forearm - club shaft angle)\n",
    "   - spine angle (hip - shoulder - head)\n",
    "3) Pose relative / frame-relative geormetry\n",
    "   - Instead of absolute coordianates, make everything relative to some anchor <br>\n",
    "     - subtract pelvis/hip center from all key points <br>\n",
    "     - OPTIONALLY: rotate coordinates so shoulders define a horizontal “body x-axis” <br>\n",
    "<b> * Gives us features that are: <b> <br>\n",
    "     - translation-invariant (location in frame irrelevant)<br>\n",
    "     - closer to “true” body pose, especially if the camera jitters <br>\n",
    "\n",
    "4) Signed area / “rotation” type features (points ABC)\n",
    "   - Signed area + cross product tells us:\n",
    "         - How \"curved\" or rotated the triplet is\n",
    "         - On which side one point lies relative to a line\n",
    "   ** Will help when detecting: **\n",
    "   - open vs closed shoulders/hips\n",
    "   - left vs right tilt etc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd0b12c-f662-4959-afb4-507c63edad5e",
   "metadata": {},
   "source": [
    "### All of that is useful but since we're working with sequence data of a video, we can't leave out changes over time of how these keypoints evolve in the swing\n",
    "    - Velocity of distance\n",
    "        - how fast two points are moving apart and closer\n",
    "    - Velocity of angle\n",
    "        - Angular speed of a joint -- is the right elbow hitting 90 degrees faster on a 5 swing that a 1 swing?\n",
    "    - Acceleration of distance and angle:\n",
    "        - the second derivative tells you the rate of change of velocity, could be useful at transition points and much more\n",
    "        --> https://www.perplexity.ai/search/58255efe-03e6-48b0-87c3-0ffdc6c75edf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad83d26-7c6f-466f-9076-038fc17f9956",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
