{
 "cells": [
  {
   "cell_type": "raw",
   "id": "7e846c01-3d6e-4702-80f4-f5baac666b4f",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Initial forays into auto-detect function of longer videos\"\n",
    "description: \"Fleshing out a way to find a consistent point in the swing to use for autodetection of swings\"\n",
    "author: \"Ali Zaidi\"\n",
    "date: \"2025-11-10\"\n",
    "categories: [Data Engineering]\n",
    "format:\n",
    "  html:\n",
    "    code-fold: true\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6e6c02-1287-4fa6-9bed-2e442459babd",
   "metadata": {},
   "source": [
    "## I've been hand labeling the videos and then extracting clips from my own labels, this is not feasible to do in a timely manner and requires alot of manual labor. Lets find a way to \n",
    "\n",
    "### To develop this functionality, we want to utilize:\n",
    "    1) 2d keypoints of a full video\n",
    "    2) Find the most relevant frames that correspond to a swing\n",
    "    3) Crop and extract a corresponding video for each swing\n",
    "\n",
    "### With this in place, all the user/system operator needs to provide is the actual scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1773be13-5b11-4ddb-9bd6-d92c9bbfa6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "from fastai.vision.all import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f22441e-94b6-4796-a4f0-f815125efb54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,\n",
       " Path('../../../data/full_videos/sep14/IMG_1090.MOV'),\n",
       "      input_file  swing_index  score start   end  output_file\n",
       " 0  IMG_1086.MOV            0      2  0:30  0:33          NaN)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| include: false\n",
    "base_path = '../../../data/full_videos'\n",
    "swing_days = ['jun8', 'aug9', 'sep14']\n",
    "files = get_files(f'{base_path}/{swing_days[-1]}', extensions='.MOV')\n",
    "df_sep14 = pd.read_csv(f'{base_path}/{swing_days[2]}/cleaned.csv').reset_index(drop=True)\n",
    "len(files), files[0], df_sep14.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edcf925f-aee3-4495-a53c-dc07c1e09919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The start times of every swing in IMG_1090.MOV are:\n",
      " ['0:28', '0:53', '1:27', '1:54', '2:25', '3:01']\n"
     ]
    }
   ],
   "source": [
    "#| echo: false\n",
    "start_times = df_sep14[df_sep14.input_file == files[0].name].reset_index(drop=True).start.to_list()\n",
    "print(f'The start times of every swing in {files[0].name} are:\\n {start_times}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea6a9e6-d0e6-4dc8-9b3c-9f2e01659cc9",
   "metadata": {},
   "source": [
    "#### Lets pull snippet of a video to see how much of actual video is spent on the swing itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a56debe-9e0d-4375-9527-78ced9ff1f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grabbing a clip from IMG_1090.MOV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1500/1500 [02:34<00:00,  9.68it/s]\n"
     ]
    }
   ],
   "source": [
    "#| code-fold: true\n",
    "print(f'Grabbing a clip from {files[0].name}')\n",
    "frames, fps = get_frames(files[0], \n",
    "                         per_second=False, # only grab every fps frame\n",
    "                         start_idx=600, # start 10 seconds in\n",
    "                         #start_idx=1200, # start 20 seconds in\n",
    "                         num_frames=1500, # only pull down 25 seconds of video\n",
    "                         #num_frames=250, # only pull down 4ish seconds of video)\n",
    "                         resize_dim=(256,256),\n",
    "                         show_progress=True\n",
    "                        )\n",
    "save_frames(frames=frames, fps=fps, fname='useless_frames.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54577e95-ef31-4d69-aeea-76a4b55bceb3",
   "metadata": {},
   "source": [
    "### The start of a swing video:\n",
    "\n",
    "{{< video useless_frames.mp4 width=\"400\" height=\"300\" >}}\n",
    "\n",
    " - First 10 seconds are useless and not included\n",
    " - Only about 3 seconds of the first 35 seconds is relevant\n",
    " - The full video has 6 swings and is over 3 minutes long!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5a7313-485b-4980-892a-640ac54a8b64",
   "metadata": {},
   "source": [
    "### Given this, how can we extract only the useful frames of the video?\n",
    "\n",
    " - I tried a few different approaches that did not work very consistently or well at all\n",
    " - After a few days lets see if a simple approach will get the job done\n",
    " - We only want a close approximation of something in the middle of the swing frames themselves, once we have it, we can just pull 1-2 seconds before and after this middle frame\\\n",
    "   - using our existing physics code to normalize the swings around the peak of the backswing like we've already fleshed out (shown to work)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0418c7dd-76c3-4eab-8ed0-7c2004074298",
   "metadata": {},
   "source": [
    "### The approach\n",
    " - The simple extraction method will be to use a filter on 2d keypoints and say yes to any frame where both hands are above the shoulder\n",
    "     - If both hands are above the shoulders, we know we're inside of a swing frames\n",
    "     - When giving the score, one hand is above the shoulder, so we need BOTH above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62edb8dc-ba4a-44c2-b4a2-59cec8ed46d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "# logger = MMLogger.get_instance('mmpose')\n",
    "# logger.setLevel('ERROR')  # or 'ERROR' for even less output\n",
    "# labeler = get_labeler('vit');\n",
    "# generate_labels(labeler, 'useless_frames.mp4', out_dir='keypoints');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329b3e4a-4ed9-496e-8ec3-5fef46680e55",
   "metadata": {},
   "source": [
    "### The same video labeled:\n",
    "\n",
    "{{< video keypoints/useless_frames.mp4 width=\"400\" height=\"300\" >}}\n",
    "\n",
    " - First\n",
    " - Only \n",
    " - The "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0700c8e3-1a5b-4683-860f-4bdfa1d0c0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "from swing_data import *\n",
    "kps = KpExtractor('keypoints/useless_frames.pkl').keypoint_data.kps\n",
    "kps.shape, kps[0,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ec8ed4a6-e0cc-4b8a-b099-5ac1ffcd4d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "l_shoulder = kps[:, 5, 1] # Left Wrist KP\n",
    "r_shoulder = kps[:, 6, 1] # Right Wrist KP\n",
    "l_elbow = kps[:, 7, 1] # Left Elbow KP\n",
    "r_elbow = kps[:, 8, 1] # Right Elbow KP\n",
    "l_wrist = kps[:, 9, 1] # Left Wrist KP\n",
    "r_wrist = kps[:, 10, 1] # Right Wrist KP\n",
    "# less than is above\n",
    "left_wrist_above_elbow = l_wrist < l_elbow\n",
    "right_wrist_above_elbow = r_wrist < r_elbow\n",
    "left_wrist_above_sh = l_wrist < l_shoulder\n",
    "right_wrist_above_sh = r_wrist < r_shoulder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8f33c7c2-c3c3-4d73-959d-a1ebcc802f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 77 frames with the wrists above the elbow and shoulders\n"
     ]
    }
   ],
   "source": [
    "#| code-fold: true\n",
    "combined_true = left_wrist_above_elbow & right_wrist_above_elbow & left_wrist_above_sh & right_wrist_above_sh\n",
    "higher_idxs = np.where(combined_true)[0]\n",
    "print(f'There are {len(higher_idxs)} frames with the wrists above the elbow and shoulders')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2d1ba259-9dfe-42ab-9cbb-fc59e73cb448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77, 256, 256, 3)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| code-fold: true\n",
    "higher_frames = np.stack([frames[idx] for idx in higher_idxs])\n",
    "save_frames(fname='higher_frames.mp4', frames=higher_frames)\n",
    "higher_frames.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0164db37-9f77-45ec-80b1-3fd428f9d12d",
   "metadata": {},
   "source": [
    "### Just the frames when wrist is above shoulder and elbow:\n",
    "\n",
    "{{< video higher_frames.mp4 width=\"400\" height=\"300\" >}}\n",
    "\n",
    " - ...  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5b8cba54-bf45-46e9-98ee-b754207a8343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1150"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| code-fold: true\n",
    "first_high_idx = higher_idxs[0]\n",
    "first_high_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7a6b6c31-a0da-4f7b-91e7-6b2489b9a80b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1060, 1240)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| code-fold: true\n",
    "# get 1.5 seconds before and after first high index\n",
    "init_idx = first_high_idx - 90\n",
    "final_idx = first_high_idx + 90\n",
    "init_idx, final_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "80e85ecc-7bef-4e0d-8a70-976e99e1f5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "final_frames = frames[init_idx:final_idx]\n",
    "save_frames(fname='final_frames.mp4', frames=final_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe422eb5-2ae4-404d-9aa7-86deef1bb885",
   "metadata": {},
   "source": [
    "### Just the frames when wrist is above shoulder and elbow:\n",
    "\n",
    "{{< video final_frames.mp4 width=\"400\" height=\"300\" >}}\n",
    "\n",
    " - ...  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26e3737-b9d8-4b90-9602-1f6571448d0b",
   "metadata": {},
   "source": [
    "First 90 seconds of video\n",
    "\n",
    "{{< video all_frames.mp4 width=\"400\" height=\"300\" >}}\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39fc8d7-a953-4893-8602-e68ec6375203",
   "metadata": {},
   "source": [
    "First 90 seconds of video clipped!\n",
    "\n",
    "{{< video ninety/final_frames.mp4 width=\"400\" height=\"300\" >}}\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54181225-0e1d-42a9-bdcd-c4e16829dd49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
